{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial time series forecasting: S&P 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simple one step ahead forecasting using a sliding window approach\n",
    "- tested linear reg, naive, svm and nn models. \n",
    "- No hpyerparameter tuning for svm or nn yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Date         Open         High          Low        Close  \\\n",
       "0      1950-01-03    16.660000    16.660000    16.660000    16.660000   \n",
       "1      1950-01-04    16.850000    16.850000    16.850000    16.850000   \n",
       "2      1950-01-05    16.930000    16.930000    16.930000    16.930000   \n",
       "3      1950-01-06    16.980000    16.980000    16.980000    16.980000   \n",
       "4      1950-01-09    17.080000    17.080000    17.080000    17.080000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "17213  2018-05-31  2720.979980  2722.500000  2700.679932  2705.270020   \n",
       "17214  2018-06-01  2718.699951  2736.929932  2718.699951  2734.620117   \n",
       "17215  2018-06-04  2741.669922  2749.159912  2740.540039  2746.870117   \n",
       "17216  2018-06-05  2748.459961  2752.610107  2739.510010  2748.800049   \n",
       "17217  2018-06-06  2753.250000  2772.389893  2748.459961  2772.350098   \n",
       "\n",
       "         Adj Close      Volume  \n",
       "0        16.660000     1260000  \n",
       "1        16.850000     1890000  \n",
       "2        16.930000     2550000  \n",
       "3        16.980000     2010000  \n",
       "4        17.080000     2520000  \n",
       "...            ...         ...  \n",
       "17213  2705.270020  4235370000  \n",
       "17214  2734.620117  3684130000  \n",
       "17215  2746.870117  3376510000  \n",
       "17216  2748.800049  3517790000  \n",
       "17217  2772.350098  3651640000  \n",
       "\n",
       "[17218 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1950-01-03</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>1260000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1950-01-04</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>1890000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1950-01-05</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>2550000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1950-01-06</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>2010000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1950-01-09</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>2520000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17213</th>\n      <td>2018-05-31</td>\n      <td>2720.979980</td>\n      <td>2722.500000</td>\n      <td>2700.679932</td>\n      <td>2705.270020</td>\n      <td>2705.270020</td>\n      <td>4235370000</td>\n    </tr>\n    <tr>\n      <th>17214</th>\n      <td>2018-06-01</td>\n      <td>2718.699951</td>\n      <td>2736.929932</td>\n      <td>2718.699951</td>\n      <td>2734.620117</td>\n      <td>2734.620117</td>\n      <td>3684130000</td>\n    </tr>\n    <tr>\n      <th>17215</th>\n      <td>2018-06-04</td>\n      <td>2741.669922</td>\n      <td>2749.159912</td>\n      <td>2740.540039</td>\n      <td>2746.870117</td>\n      <td>2746.870117</td>\n      <td>3376510000</td>\n    </tr>\n    <tr>\n      <th>17216</th>\n      <td>2018-06-05</td>\n      <td>2748.459961</td>\n      <td>2752.610107</td>\n      <td>2739.510010</td>\n      <td>2748.800049</td>\n      <td>2748.800049</td>\n      <td>3517790000</td>\n    </tr>\n    <tr>\n      <th>17217</th>\n      <td>2018-06-06</td>\n      <td>2753.250000</td>\n      <td>2772.389893</td>\n      <td>2748.459961</td>\n      <td>2772.350098</td>\n      <td>2772.350098</td>\n      <td>3651640000</td>\n    </tr>\n  </tbody>\n</table>\n<p>17218 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# import some shit\n",
    "%matplotlib widget\n",
    "# %matplotlib notebook \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# model evalution metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# %matplotlib inline\n",
    "# import some data\n",
    "sp_500 = pd.read_csv('./test_data/GSPC.csv')\n",
    "sp_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af42164e35134d3680ccf61e66ff42e6"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# plot the data\n",
    "sp_500.plot(x='Date',figsize=(10,10),subplots=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "source": [
    "# Calculate returns on open price as data for prediction tasks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-2-51bb1f54035d>:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  returns['Shift'] = sp_500['Open'].shift(periods=-1) # use pandas shift method to create shift daily open price one time period forward\n<ipython-input-2-51bb1f54035d>:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  returns['returns'] = returns['Shift'] - returns['Open'] # calculates the 24hr return\nC:\\Users\\tristan\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return super().drop(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "             Date         Open        Shift    returns\n0      1950-01-03    16.660000    16.850000   0.190000\n1      1950-01-04    16.850000    16.930000   0.080000\n2      1950-01-05    16.930000    16.980000   0.050000\n3      1950-01-06    16.980000    17.080000   0.100000\n4      1950-01-09    17.080000    17.030001  -0.049999\n...           ...          ...          ...        ...\n17212  2018-05-30  2702.429932  2720.979980  18.550048\n17213  2018-05-31  2720.979980  2718.699951  -2.280029\n17214  2018-06-01  2718.699951  2741.669922  22.969971\n17215  2018-06-04  2741.669922  2748.459961   6.790039\n17216  2018-06-05  2748.459961  2753.250000   4.790039\n\n[17217 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>Shift</th>\n      <th>returns</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1950-01-03</td>\n      <td>16.660000</td>\n      <td>16.850000</td>\n      <td>0.190000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1950-01-04</td>\n      <td>16.850000</td>\n      <td>16.930000</td>\n      <td>0.080000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1950-01-05</td>\n      <td>16.930000</td>\n      <td>16.980000</td>\n      <td>0.050000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1950-01-06</td>\n      <td>16.980000</td>\n      <td>17.080000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1950-01-09</td>\n      <td>17.080000</td>\n      <td>17.030001</td>\n      <td>-0.049999</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17212</th>\n      <td>2018-05-30</td>\n      <td>2702.429932</td>\n      <td>2720.979980</td>\n      <td>18.550048</td>\n    </tr>\n    <tr>\n      <th>17213</th>\n      <td>2018-05-31</td>\n      <td>2720.979980</td>\n      <td>2718.699951</td>\n      <td>-2.280029</td>\n    </tr>\n    <tr>\n      <th>17214</th>\n      <td>2018-06-01</td>\n      <td>2718.699951</td>\n      <td>2741.669922</td>\n      <td>22.969971</td>\n    </tr>\n    <tr>\n      <th>17215</th>\n      <td>2018-06-04</td>\n      <td>2741.669922</td>\n      <td>2748.459961</td>\n      <td>6.790039</td>\n    </tr>\n    <tr>\n      <th>17216</th>\n      <td>2018-06-05</td>\n      <td>2748.459961</td>\n      <td>2753.250000</td>\n      <td>4.790039</td>\n    </tr>\n  </tbody>\n</table>\n<p>17217 rows × 4 columns</p>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1168d4154e7461caa144aff253b6708"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Date'>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# calculate returns on \n",
    "returns = sp_500[['Date','Open']]\n",
    "returns['Shift'] = sp_500['Open'].shift(periods=-1) # use pandas shift method to create shift daily open price one time period forward\n",
    "returns['returns'] = returns['Shift'] - returns['Open'] # calculates the 24hr return\n",
    "returns.drop(labels=returns.index[-1],axis=0,inplace=True) # need to delete last row as the shift value is nan and therefore no return could be calculated\n",
    "display(returns)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "returns.plot(x='Date',y='returns',ax=ax)"
   ]
  },
  {
   "source": [
    "# calculate percentage returns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sp_500['Open'][-2000:]\n",
    "\n",
    "# percentage returns\n",
    "x_pct = x.pct_change().fillna(0)\n",
    "x_pct\n",
    "\n",
    "# create new df hold both\n",
    "df = pd.DataFrame(columns=['Open','pct_change'])\n",
    "df['Open'] =  x\n",
    "df['pct_change'] = x_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 2. 3. 4. 5.]  :  6.0\n[2. 3. 4. 5. 6.]  :  7.0\n[3. 4. 5. 6. 7.]  :  8.0\n[4. 5. 6. 7. 8.]  :  9.0\n[5. 6. 7. 8. 9.]  :  10.0\n"
     ]
    }
   ],
   "source": [
    "# write function to perform sliding window over data: transform time series in supervised learning problem\n",
    "\n",
    "def slide_window(data, slide_step_size): # column of data, integer\n",
    "    # initialize input array\n",
    "    num_rows = len(data) - slide_step_size\n",
    "    array = np.zeros((num_rows, slide_step_size + 1))\n",
    "    \n",
    "    # loop through data and populate array\n",
    "    for i in range(num_rows):\n",
    "        # input features\n",
    "        array[i,0:slide_step_size+1] = data[i:i+slide_step_size+1]\n",
    "        # target feature\n",
    "        array[i,-1] = data[i+slide_step_size]\n",
    "        # show pattern\n",
    "        print(array[i,0:slide_step_size],' : ',array[i,slide_step_size])\n",
    "    return array \n",
    "\n",
    "dummy_data = [1,2,3,4,5,6,7,8,9,10]\n",
    "dummy_result = slide_window(dummy_data,5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preporation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-framing time series data as supervised machine learning problem using a sliding window approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs to select and prepare data\n",
    "column = 'Volume' # which stock price feature to use for prediction\n",
    "window_length = 5 # how many previous time steps is used to set up supvervised learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[4.50182 4.20058 3.88448 4.03451 3.85759]  :  4.40697\n",
      "[4.20058 3.88448 4.03451 3.85759 4.40697]  :  4.1682\n",
      "[3.88448 4.03451 3.85759 4.40697 4.1682 ]  :  5.92034\n",
      "[4.03451 3.85759 4.40697 4.1682  5.92034]  :  3.24837\n",
      "[3.85759 4.40697 4.1682  5.92034 3.24837]  :  3.29878\n",
      "[4.40697 4.1682  5.92034 3.24837 3.29878]  :  2.85223\n",
      "[4.1682  5.92034 3.24837 3.29878 2.85223]  :  2.87632\n",
      "[5.92034 3.24837 3.29878 2.85223 2.87632]  :  2.02055\n",
      "[3.24837 3.29878 2.85223 2.87632 2.02055]  :  1.98708\n",
      "[3.29878 2.85223 2.87632 2.02055 1.98708]  :  2.39236\n",
      "[2.85223 2.87632 2.02055 1.98708 2.39236]  :  2.33637\n",
      "[2.87632 2.02055 1.98708 2.39236 2.33637]  :  2.6709\n",
      "[2.02055 1.98708 2.39236 2.33637 2.6709 ]  :  3.77053\n",
      "[1.98708 2.39236 2.33637 2.6709  3.77053]  :  3.76489\n",
      "[2.39236 2.33637 2.6709  3.77053 3.76489]  :  3.76182\n",
      "[2.33637 2.6709  3.77053 3.76489 3.76182]  :  3.33989\n",
      "[2.6709  3.77053 3.76489 3.76182 3.33989]  :  3.21761\n",
      "[3.77053 3.76489 3.76182 3.33989 3.21761]  :  3.63879\n",
      "[3.76489 3.76182 3.33989 3.21761 3.63879]  :  3.62041\n",
      "[3.76182 3.33989 3.21761 3.63879 3.62041]  :  3.46213\n",
      "[3.33989 3.21761 3.63879 3.62041 3.46213]  :  3.08127\n",
      "[3.21761 3.63879 3.62041 3.46213 3.08127]  :  3.58499\n",
      "[3.63879 3.62041 3.46213 3.08127 3.58499]  :  3.31525\n",
      "[3.62041 3.46213 3.08127 3.58499 3.31525]  :  3.16597\n",
      "[3.46213 3.08127 3.58499 3.31525 3.16597]  :  3.52497\n",
      "[3.08127 3.58499 3.31525 3.16597 3.52497]  :  3.15271\n",
      "[3.58499 3.31525 3.16597 3.52497 3.15271]  :  3.81096\n",
      "[3.31525 3.16597 3.52497 3.15271 3.81096]  :  3.84602\n",
      "[3.16597 3.52497 3.15271 3.81096 3.84602]  :  3.61036\n",
      "[3.52497 3.15271 3.81096 3.84602 3.61036]  :  3.13589\n",
      "[3.15271 3.81096 3.84602 3.61036 3.13589]  :  3.59127\n",
      "[3.81096 3.84602 3.61036 3.13589 3.59127]  :  4.08745\n",
      "[3.84602 3.61036 3.13589 3.59127 4.08745]  :  3.91661\n",
      "[3.61036 3.13589 3.59127 4.08745 3.91661]  :  3.80771\n",
      "[3.13589 3.59127 4.08745 3.91661 3.80771]  :  3.59797\n",
      "[3.59127 4.08745 3.91661 3.80771 3.59797]  :  3.10905\n",
      "[4.08745 3.91661 3.80771 3.59797 3.10905]  :  3.44869\n",
      "[3.91661 3.80771 3.59797 3.10905 3.44869]  :  3.60974\n",
      "[3.80771 3.59797 3.10905 3.44869 3.60974]  :  3.67794\n",
      "[3.59797 3.10905 3.44869 3.60974 3.67794]  :  3.47502\n",
      "[3.10905 3.44869 3.60974 3.67794 3.47502]  :  3.34973\n",
      "[3.44869 3.60974 3.67794 3.47502 3.34973]  :  3.52091\n",
      "[3.60974 3.67794 3.47502 3.34973 3.52091]  :  3.77559\n",
      "[3.67794 3.47502 3.34973 3.52091 3.77559]  :  3.67237\n",
      "[3.47502 3.34973 3.52091 3.77559 3.67237]  :  3.51306\n",
      "[3.34973 3.52091 3.77559 3.67237 3.51306]  :  3.57978\n",
      "[3.52091 3.77559 3.67237 3.51306 3.57978]  :  3.46867\n",
      "[3.77559 3.67237 3.51306 3.57978 3.46867]  :  4.01526\n",
      "[3.67237 3.51306 3.57978 3.46867 4.01526]  :  3.83157\n",
      "[3.51306 3.57978 3.46867 4.01526 3.83157]  :  3.58261\n",
      "[3.57978 3.46867 4.01526 3.83157 3.58261]  :  4.21014\n",
      "[3.46867 4.01526 3.83157 3.58261 4.21014]  :  4.34518\n",
      "[4.01526 3.83157 3.58261 4.21014 4.34518]  :  3.82132\n",
      "[3.83157 3.58261 4.21014 4.34518 3.82132]  :  3.55526\n",
      "[3.58261 4.21014 4.34518 3.82132 3.55526]  :  3.2327\n",
      "[4.21014 4.34518 3.82132 3.55526 3.2327 ]  :  3.51839\n",
      "[4.34518 3.82132 3.55526 3.2327  3.51839]  :  3.8121\n",
      "[3.82132 3.55526 3.2327  3.51839 3.8121 ]  :  3.71634\n",
      "[3.55526 3.2327  3.51839 3.8121  3.71634]  :  3.43295\n",
      "[3.2327  3.51839 3.8121  3.71634 3.43295]  :  3.1339\n",
      "[3.51839 3.8121  3.71634 3.43295 3.1339 ]  :  3.17263\n",
      "[3.8121  3.71634 3.43295 3.1339  3.17263]  :  3.90684\n",
      "[3.71634 3.43295 3.1339  3.17263 3.90684]  :  3.36566\n",
      "[3.43295 3.1339  3.17263 3.90684 3.36566]  :  5.17804\n",
      "[3.1339  3.17263 3.90684 3.36566 5.17804]  :  3.05493\n",
      "[3.17263 3.90684 3.36566 5.17804 3.05493]  :  4.26559\n",
      "[3.90684 3.36566 5.17804 3.05493 4.26559]  :  3.57273\n",
      "[3.36566 5.17804 3.05493 4.26559 3.57273]  :  3.2606\n",
      "[5.17804 3.05493 4.26559 3.57273 3.2606 ]  :  2.97513\n",
      "[3.05493 4.26559 3.57273 3.2606  2.97513]  :  3.24023\n",
      "[4.26559 3.57273 3.2606  2.97513 3.24023]  :  3.36778\n",
      "[3.57273 3.2606  2.97513 3.24023 3.36778]  :  3.10694\n",
      "[3.2606  2.97513 3.24023 3.36778 3.10694]  :  3.15842\n",
      "[2.97513 3.24023 3.36778 3.10694 3.15842]  :  3.35411\n",
      "[3.24023 3.36778 3.10694 3.15842 3.35411]  :  3.4164\n",
      "[3.36778 3.10694 3.15842 3.35411 3.4164 ]  :  3.20624\n",
      "[3.10694 3.15842 3.35411 3.4164  3.20624]  :  3.77052\n",
      "[3.15842 3.35411 3.4164  3.20624 3.77052]  :  3.20192\n",
      "[3.35411 3.4164  3.20624 3.77052 3.20192]  :  3.05315\n",
      "[3.4164  3.20624 3.77052 3.20192 3.05315]  :  2.78541\n",
      "[3.20624 3.77052 3.20192 3.05315 2.78541]  :  3.11742\n",
      "[3.77052 3.20192 3.05315 2.78541 3.11742]  :  3.19695\n",
      "[3.20192 3.05315 2.78541 3.11742 3.19695]  :  3.14389\n",
      "[3.05315 2.78541 3.11742 3.19695 3.14389]  :  2.82471\n",
      "[2.78541 3.11742 3.19695 3.14389 2.82471]  :  3.26984\n",
      "[3.11742 3.19695 3.14389 2.82471 3.26984]  :  3.5199\n",
      "[3.19695 3.14389 2.82471 3.26984 3.5199 ]  :  3.64742\n",
      "[3.14389 2.82471 3.26984 3.5199  3.64742]  :  3.50336\n",
      "[2.82471 3.26984 3.5199  3.64742 3.50336]  :  3.69065\n",
      "[3.26984 3.5199  3.64742 3.50336 3.69065]  :  3.99524\n",
      "[3.5199  3.64742 3.50336 3.69065 3.99524]  :  4.10592\n",
      "[3.64742 3.50336 3.69065 3.99524 4.10592]  :  4.09846\n",
      "[3.50336 3.69065 3.99524 4.10592 4.09846]  :  3.71827\n",
      "[3.69065 3.99524 4.10592 4.09846 3.71827]  :  3.19924\n",
      "[3.99524 4.10592 4.09846 3.71827 3.19924]  :  3.81368\n",
      "[4.10592 4.09846 3.71827 3.19924 3.81368]  :  3.89399\n",
      "[4.09846 3.71827 3.19924 3.81368 3.89399]  :  4.36254\n",
      "[3.71827 3.19924 3.81368 3.89399 4.36254]  :  3.54014\n",
      "[3.19924 3.81368 3.89399 4.36254 3.54014]  :  3.42944\n",
      "[3.81368 3.89399 4.36254 3.54014 3.42944]  :  3.65359\n",
      "[3.89399 4.36254 3.54014 3.42944 3.65359]  :  3.64353\n",
      "[4.36254 3.54014 3.42944 3.65359 3.64353]  :  3.72742\n",
      "[3.54014 3.42944 3.65359 3.64353 3.72742]  :  3.30563\n",
      "[3.42944 3.65359 3.64353 3.72742 3.30563]  :  3.4736\n",
      "[3.65359 3.64353 3.72742 3.30563 3.4736 ]  :  3.42079\n",
      "[3.64353 3.72742 3.30563 3.4736  3.42079]  :  4.163\n",
      "[3.72742 3.30563 3.4736  3.42079 4.163  ]  :  4.31942\n",
      "[3.30563 3.4736  3.42079 4.163   4.31942]  :  3.82516\n",
      "[3.4736  3.42079 4.163   4.31942 3.82516]  :  3.17283\n",
      "[3.42079 4.163   4.31942 3.82516 3.17283]  :  3.21357\n",
      "[4.163   4.31942 3.82516 3.17283 3.21357]  :  3.3899\n",
      "[4.31942 3.82516 3.17283 3.21357 3.3899 ]  :  3.53539\n",
      "[3.82516 3.17283 3.21357 3.3899  3.53539]  :  2.80504\n",
      "[3.17283 3.21357 3.3899  3.53539 2.80504]  :  3.20316\n",
      "[3.21357 3.3899  3.53539 2.80504 3.20316]  :  4.51611\n",
      "[3.3899  3.53539 2.80504 3.20316 4.51611]  :  3.85714\n",
      "[3.53539 2.80504 3.20316 4.51611 3.85714]  :  3.46168\n",
      "[2.80504 3.20316 4.51611 3.85714 3.46168]  :  2.9126\n",
      "[3.20316 4.51611 3.85714 3.46168 2.9126 ]  :  3.35784\n",
      "[4.51611 3.85714 3.46168 2.9126  3.35784]  :  3.5723\n",
      "[3.85714 3.46168 2.9126  3.35784 3.5723 ]  :  3.72886\n",
      "[3.46168 2.9126  3.35784 3.5723  3.72886]  :  4.02734\n",
      "[2.9126  3.35784 3.5723  3.72886 4.02734]  :  4.02775\n",
      "[3.35784 3.5723  3.72886 4.02734 4.02775]  :  3.2755\n",
      "[3.5723  3.72886 4.02734 4.02775 3.2755 ]  :  3.55559\n",
      "[3.72886 4.02734 4.02775 3.2755  3.55559]  :  3.35305\n",
      "[4.02734 4.02775 3.2755  3.55559 3.35305]  :  5.28472\n",
      "[4.02775 3.2755  3.55559 3.35305 5.28472]  :  3.2647\n",
      "[3.2755  3.55559 3.35305 5.28472 3.2647 ]  :  3.41651\n",
      "[3.55559 3.35305 5.28472 3.2647  3.41651]  :  3.59482\n",
      "[3.35305 5.28472 3.2647  3.41651 3.59482]  :  3.46821\n",
      "[5.28472 3.2647  3.41651 3.59482 3.46821]  :  5.27833\n",
      "[3.2647  3.41651 3.59482 3.46821 5.27833]  :  3.23897\n",
      "[3.41651 3.59482 3.46821 5.27833 3.23897]  :  3.56391\n",
      "[3.59482 3.46821 5.27833 3.23897 3.56391]  :  3.5008\n",
      "[3.46821 5.27833 3.23897 3.56391 3.5008 ]  :  3.90028\n",
      "[5.27833 3.23897 3.56391 3.5008  3.90028]  :  3.36159\n",
      "[3.23897 3.56391 3.5008  3.90028 3.36159]  :  1.96229\n",
      "[3.56391 3.5008  3.90028 3.36159 1.96229]  :  3.36722\n",
      "[3.5008  3.90028 3.36159 1.96229 3.36722]  :  3.36452\n",
      "[3.90028 3.36159 1.96229 3.36722 3.36452]  :  2.90133\n",
      "[3.36159 1.96229 3.36722 3.36452 2.90133]  :  2.99913\n",
      "[1.96229 3.36722 3.36452 2.90133 2.99913]  :  3.10675\n",
      "[3.36722 3.36452 2.90133 2.99913 3.10675]  :  3.17162\n",
      "[3.36452 2.90133 2.99913 3.10675 3.17162]  :  3.06767\n",
      "[2.90133 2.99913 3.10675 3.17162 3.06767]  :  2.73664\n",
      "[2.99913 3.10675 3.17162 3.06767 2.73664]  :  2.79317\n",
      "[3.10675 3.17162 3.06767 2.73664 2.79317]  :  2.96213\n",
      "[3.17162 3.06767 2.73664 2.79317 2.96213]  :  3.05976\n",
      "[3.06767 2.73664 2.79317 2.96213 3.05976]  :  3.18278\n",
      "[2.73664 2.79317 2.96213 3.05976 3.18278]  :  3.05957\n",
      "[2.79317 2.96213 3.05976 3.18278 3.05957]  :  3.01024\n",
      "[2.96213 3.05976 3.18278 3.05957 3.01024]  :  4.10806\n",
      "[3.05976 3.18278 3.05957 3.01024 4.10806]  :  3.55702\n",
      "[3.18278 3.05957 3.01024 4.10806 3.55702]  :  3.99552\n",
      "[3.05957 3.01024 4.10806 3.55702 3.99552]  :  3.29477\n",
      "[3.01024 4.10806 3.55702 3.99552 3.29477]  :  3.46921\n",
      "[4.10806 3.55702 3.99552 3.29477 3.46921]  :  3.46086\n",
      "[3.55702 3.99552 3.29477 3.46921 3.46086]  :  3.47858\n",
      "[3.99552 3.29477 3.46921 3.46086 3.47858]  :  3.64502\n",
      "[3.29477 3.46921 3.46086 3.47858 3.64502]  :  3.23514\n",
      "[3.46921 3.46086 3.47858 3.64502 3.23514]  :  2.93178\n",
      "[3.46086 3.47858 3.64502 3.23514 2.93178]  :  3.34464\n",
      "[3.47858 3.64502 3.23514 2.93178 3.34464]  :  3.30806\n",
      "[3.64502 3.23514 2.93178 3.34464 3.30806]  :  3.62107\n",
      "[3.23514 2.93178 3.34464 3.30806 3.62107]  :  3.15993\n",
      "[2.93178 3.34464 3.30806 3.62107 3.15993]  :  2.82255\n",
      "[3.34464 3.30806 3.62107 3.15993 2.82255]  :  2.9131\n",
      "[3.30806 3.62107 3.15993 2.82255 2.9131 ]  :  2.95365\n",
      "[3.62107 3.15993 2.82255 2.9131  2.95365]  :  3.14262\n",
      "[3.15993 2.82255 2.9131  2.95365 3.14262]  :  3.41568\n",
      "[2.82255 2.9131  2.95365 3.14262 3.41568]  :  2.78815\n",
      "[2.9131  2.95365 3.14262 3.41568 2.78815]  :  2.77749\n",
      "[2.95365 3.14262 3.41568 2.78815 2.77749]  :  2.78529\n",
      "[3.14262 3.41568 2.78815 2.77749 2.78529]  :  2.84659\n",
      "[3.41568 2.78815 2.77749 2.78529 2.84659]  :  2.58878\n",
      "[2.78815 2.77749 2.78529 2.84659 2.58878]  :  2.6777\n",
      "[2.77749 2.78529 2.84659 2.58878 2.6777 ]  :  2.73758\n",
      "[2.78529 2.84659 2.58878 2.6777  2.73758]  :  2.63366\n",
      "[2.84659 2.58878 2.6777  2.73758 2.63366]  :  3.34811\n",
      "[2.58878 2.6777  2.73758 2.63366 3.34811]  :  2.71073\n",
      "[2.6777  2.73758 2.63366 3.34811 2.71073]  :  3.49026\n",
      "[2.73758 2.63366 3.34811 2.71073 3.49026]  :  3.37441\n",
      "[2.63366 3.34811 2.71073 3.49026 3.37441]  :  3.35393\n",
      "[3.34811 2.71073 3.49026 3.37441 3.35393]  :  3.30249\n",
      "[2.71073 3.49026 3.37441 3.35393 3.30249]  :  3.29176\n",
      "[3.49026 3.37441 3.35393 3.30249 3.29176]  :  3.23092\n",
      "[3.37441 3.35393 3.30249 3.29176 3.23092]  :  3.36805\n",
      "[3.35393 3.30249 3.29176 3.23092 3.36805]  :  3.41446\n",
      "[3.30249 3.29176 3.23092 3.36805 3.41446]  :  4.85317\n",
      "[3.29176 3.23092 3.36805 3.41446 4.85317]  :  3.1943\n",
      "[3.23092 3.36805 3.41446 4.85317 3.1943 ]  :  3.2491\n",
      "[3.36805 3.41446 4.85317 3.1943  3.2491 ]  :  3.53001\n",
      "[3.41446 4.85317 3.1943  3.2491  3.53001]  :  2.93086\n",
      "[4.85317 3.1943  3.2491  3.53001 2.93086]  :  2.86596\n",
      "[3.1943  3.2491  3.53001 2.93086 2.86596]  :  3.29789\n",
      "[3.2491  3.53001 2.93086 2.86596 3.29789]  :  3.04311\n",
      "[3.53001 2.93086 2.86596 3.29789 3.04311]  :  3.45603\n",
      "[2.93086 2.86596 3.29789 3.04311 3.45603]  :  3.16862\n",
      "[2.86596 3.29789 3.04311 3.45603 3.16862]  :  3.21192\n",
      "[3.29789 3.04311 3.45603 3.16862 3.21192]  :  3.19973\n",
      "[3.04311 3.45603 3.16862 3.21192 3.19973]  :  3.06885\n",
      "[3.45603 3.16862 3.21192 3.19973 3.06885]  :  3.01712\n",
      "[3.16862 3.21192 3.19973 3.06885 3.01712]  :  3.04512\n",
      "[3.21192 3.19973 3.06885 3.01712 3.04512]  :  2.88457\n",
      "[3.19973 3.06885 3.01712 3.04512 2.88457]  :  2.48397\n",
      "[3.06885 3.01712 3.04512 2.88457 2.48397]  :  2.9605\n",
      "[3.01712 3.04512 2.88457 2.48397 2.9605 ]  :  2.97609\n",
      "[3.04512 2.88457 2.48397 2.9605  2.97609]  :  3.15151\n",
      "[2.88457 2.48397 2.9605  2.97609 3.15151]  :  3.14944\n",
      "[2.48397 2.9605  2.97609 3.15151 3.14944]  :  2.91602\n",
      "[2.9605  2.97609 3.15151 3.14944 2.91602]  :  2.88939\n",
      "[2.97609 3.15151 3.14944 2.91602 2.88939]  :  2.99809\n",
      "[3.15151 3.14944 2.91602 2.88939 2.99809]  :  2.99071\n",
      "[3.14944 2.91602 2.88939 2.99809 2.99071]  :  3.38465\n",
      "[2.91602 2.88939 2.99809 2.99071 3.38465]  :  3.21171\n",
      "[2.88939 2.99809 2.99071 3.38465 3.21171]  :  3.42733\n",
      "[2.99809 2.99071 3.38465 3.21171 3.42733]  :  3.87451\n",
      "[2.99071 3.38465 3.21171 3.42733 3.87451]  :  3.86905\n",
      "[3.38465 3.21171 3.42733 3.87451 3.86905]  :  3.88711\n",
      "[3.21171 3.42733 3.87451 3.86905 3.88711]  :  3.65887\n",
      "[3.42733 3.87451 3.86905 3.88711 3.65887]  :  3.82723\n",
      "[3.87451 3.86905 3.88711 3.65887 3.82723]  :  3.81318\n",
      "[3.86905 3.88711 3.65887 3.82723 3.81318]  :  4.04827\n",
      "[3.88711 3.65887 3.82723 3.81318 4.04827]  :  3.56771\n",
      "[3.65887 3.82723 3.81318 4.04827 3.56771]  :  3.53908\n",
      "[3.82723 3.81318 4.04827 3.56771 3.53908]  :  3.80965\n",
      "[3.81318 4.04827 3.56771 3.53908 3.80965]  :  3.89936\n",
      "[4.04827 3.56771 3.53908 3.80965 3.89936]  :  3.83161\n",
      "[3.56771 3.53908 3.80965 3.89936 3.83161]  :  3.48691\n",
      "[3.53908 3.80965 3.89936 3.83161 3.48691]  :  3.40293\n",
      "[3.80965 3.89936 3.83161 3.48691 3.40293]  :  3.64176\n",
      "[3.89936 3.83161 3.48691 3.40293 3.64176]  :  3.55889\n",
      "[3.83161 3.48691 3.40293 3.64176 3.55889]  :  3.31271\n",
      "[3.48691 3.40293 3.64176 3.55889 3.31271]  :  3.30016\n",
      "[3.40293 3.64176 3.55889 3.31271 3.30016]  :  3.00354\n",
      "[3.64176 3.55889 3.31271 3.30016 3.00354]  :  3.33272\n",
      "[3.55889 3.31271 3.30016 3.00354 3.33272]  :  2.76295\n",
      "[3.31271 3.30016 3.00354 3.33272 2.76295]  :  1.34978\n",
      "[3.30016 3.00354 3.33272 2.76295 1.34978]  :  3.00686\n",
      "[3.00354 3.33272 2.76295 1.34978 3.00686]  :  3.48842\n",
      "[3.33272 2.76295 1.34978 3.00686 3.48842]  :  4.07828\n",
      "[2.76295 1.34978 3.00686 3.48842 4.07828]  :  4.93849\n",
      "[1.34978 3.00686 3.48842 4.07828 4.93849]  :  3.94232\n",
      "[3.00686 3.48842 4.07828 4.93849 3.94232]  :  4.02315\n",
      "[3.48842 4.07828 4.93849 3.94232 4.02315]  :  3.53904\n",
      "[4.07828 4.93849 3.94232 4.02315 3.53904]  :  3.229\n",
      "[4.93849 3.94232 4.02315 3.53904 3.229  ]  :  3.2924\n",
      "[3.94232 4.02315 3.53904 3.229   3.2924 ]  :  3.10615\n",
      "[4.02315 3.53904 3.229   3.2924  3.10615]  :  3.09195\n",
      "[3.53904 3.229   3.2924  3.10615 3.09195]  :  3.55568\n",
      "[3.229   3.2924  3.10615 3.09195 3.55568]  :  3.54237\n",
      "[3.2924  3.10615 3.09195 3.55568 3.54237]  :  3.43003\n",
      "[3.10615 3.09195 3.55568 3.54237 3.43003]  :  5.72392\n",
      "[3.09195 3.55568 3.54237 3.43003 5.72392]  :  3.72466\n",
      "[3.55568 3.54237 3.43003 5.72392 3.72466]  :  3.36859\n",
      "[3.54237 3.43003 5.72392 3.72466 3.36859]  :  3.24103\n",
      "[3.43003 5.72392 3.72466 3.36859 3.24103]  :  3.27339\n",
      "[5.72392 3.72466 3.36859 3.24103 3.27339]  :  2.39983\n",
      "[3.72466 3.36859 3.24103 3.27339 2.39983]  :  1.96878\n",
      "[3.36859 3.24103 3.27339 2.39983 1.96878]  :  2.20208\n",
      "[3.24103 3.27339 2.39983 1.96878 2.20208]  :  2.15333\n",
      "[3.27339 2.39983 1.96878 2.20208 2.15333]  :  2.44349\n",
      "[2.39983 1.96878 2.20208 2.15333 2.44349]  :  3.36725\n",
      "[1.96878 2.20208 2.15333 2.44349 3.36725]  :  3.53866\n",
      "[2.20208 2.15333 2.44349 3.36725 3.53866]  :  3.69526\n",
      "[2.15333 2.44349 3.36725 3.53866 3.69526]  :  3.23662\n",
      "[2.44349 3.36725 3.53866 3.69526 3.23662]  :  3.24265\n",
      "[3.36725 3.53866 3.69526 3.23662 3.24265]  :  3.45348\n",
      "[3.53866 3.69526 3.23662 3.24265 3.45348]  :  3.57635\n",
      "[3.69526 3.23662 3.24265 3.45348 3.57635]  :  3.64132\n",
      "[3.23662 3.24265 3.45348 3.57635 3.64132]  :  3.57397\n",
      "[3.24265 3.45348 3.57635 3.64132 3.57397]  :  4.32597\n",
      "[3.45348 3.57635 3.64132 3.57397 4.32597]  :  3.77805\n",
      "[3.57635 3.64132 3.57397 4.32597 3.77805]  :  3.68147\n",
      "[3.64132 3.57397 4.32597 3.77805 3.68147]  :  3.63943\n",
      "[3.57397 4.32597 3.77805 3.68147 3.63943]  :  3.47178\n",
      "[4.32597 3.77805 3.68147 3.63943 3.47178]  :  3.51965\n",
      "[3.77805 3.68147 3.63943 3.47178 3.51965]  :  4.01407\n",
      "[3.68147 3.63943 3.47178 3.51965 4.01407]  :  3.83515\n",
      "[3.63943 3.47178 3.51965 4.01407 3.83515]  :  3.44323\n",
      "[3.47178 3.51965 4.01407 3.83515 3.44323]  :  3.57383\n",
      "[3.51965 4.01407 3.83515 3.44323 3.57383]  :  3.99065\n",
      "[4.01407 3.83515 3.44323 3.57383 3.99065]  :  4.26128\n",
      "[3.83515 3.44323 3.57383 3.99065 4.26128]  :  3.93845\n",
      "[3.44323 3.57383 3.99065 4.26128 3.93845]  :  4.30113\n",
      "[3.57383 3.99065 4.26128 3.93845 4.30113]  :  5.28346\n",
      "[3.99065 4.26128 3.93845 4.30113 5.28346]  :  5.89166\n",
      "[4.26128 3.93845 4.30113 5.28346 5.89166]  :  4.62657\n",
      "[3.93845 4.30113 5.28346 5.89166 4.62657]  :  5.30544\n",
      "[4.30113 5.28346 5.89166 4.62657 5.30544]  :  5.68007\n",
      "[5.28346 5.89166 4.62657 5.30544 5.68007]  :  4.05579\n",
      "[5.89166 4.62657 5.30544 5.68007 4.05579]  :  3.47287\n",
      "[4.62657 5.30544 5.68007 4.05579 3.47287]  :  4.00374\n",
      "[5.30544 5.68007 4.05579 3.47287 4.00374]  :  3.68491\n",
      "[5.68007 4.05579 3.47287 4.00374 3.68491]  :  3.63746\n",
      "[4.05579 3.47287 4.00374 3.68491 3.63746]  :  3.62761\n",
      "[3.47287 4.00374 3.68491 3.63746 3.62761]  :  3.7794\n",
      "[4.00374 3.68491 3.63746 3.62761 3.7794 ]  :  3.70127\n",
      "[3.68491 3.63746 3.62761 3.7794  3.70127]  :  3.18919\n",
      "[3.63746 3.62761 3.7794  3.70127 3.18919]  :  3.42465\n",
      "[3.62761 3.7794  3.70127 3.18919 3.42465]  :  3.74508\n",
      "[3.7794  3.70127 3.18919 3.42465 3.74508]  :  4.23066\n",
      "[3.70127 3.18919 3.42465 3.74508 4.23066]  :  4.50397\n",
      "[3.18919 3.42465 3.74508 4.23066 4.50397]  :  3.88245\n",
      "[3.42465 3.74508 4.23066 4.50397 3.88245]  :  3.71081\n",
      "[3.74508 4.23066 4.50397 3.88245 3.71081]  :  3.37069\n",
      "[4.23066 4.50397 3.88245 3.71081 3.37069]  :  3.39327\n",
      "[4.50397 3.88245 3.71081 3.37069 3.39327]  :  3.21232\n",
      "[3.88245 3.71081 3.37069 3.39327 3.21232]  :  3.3641\n",
      "[3.71081 3.37069 3.39327 3.21232 3.3641 ]  :  3.18502\n",
      "[3.37069 3.39327 3.21232 3.3641  3.18502]  :  3.30165\n",
      "[3.39327 3.21232 3.3641  3.18502 3.30165]  :  3.39136\n",
      "[3.21232 3.3641  3.18502 3.30165 3.39136]  :  3.50033\n",
      "[3.3641  3.18502 3.30165 3.39136 3.50033]  :  5.37234\n",
      "[3.18502 3.30165 3.39136 3.50033 5.37234]  :  3.28213\n",
      "[3.30165 3.39136 3.50033 5.37234 3.28213]  :  3.26103\n",
      "[3.39136 3.50033 5.37234 3.28213 3.26103]  :  3.41551\n",
      "[3.50033 5.37234 3.28213 3.26103 3.41551]  :  3.7398\n",
      "[5.37234 3.28213 3.26103 3.41551 3.7398 ]  :  3.81508\n",
      "[3.28213 3.26103 3.41551 3.7398  3.81508]  :  3.5111\n",
      "[3.26103 3.41551 3.7398  3.81508 3.5111 ]  :  3.70635\n",
      "[3.41551 3.7398  3.81508 3.5111  3.70635]  :  3.8645\n",
      "[3.7398  3.81508 3.5111  3.70635 3.8645 ]  :  3.56599\n",
      "[3.81508 3.5111  3.70635 3.8645  3.56599]  :  3.59852\n",
      "[3.5111  3.70635 3.8645  3.56599 3.59852]  :  3.39281\n",
      "[3.70635 3.8645  3.56599 3.59852 3.39281]  :  3.35034\n",
      "[3.8645  3.56599 3.59852 3.39281 3.35034]  :  3.17897\n",
      "[3.56599 3.59852 3.39281 3.35034 3.17897]  :  3.2997\n",
      "[3.59852 3.39281 3.35034 3.17897 3.2997 ]  :  3.06296\n",
      "[3.39281 3.35034 3.17897 3.2997  3.06296]  :  3.54393\n",
      "[3.35034 3.17897 3.2997  3.06296 3.54393]  :  3.02076\n",
      "[3.17897 3.2997  3.06296 3.54393 3.02076]  :  3.02132\n",
      "[3.2997  3.06296 3.54393 3.02076 3.02132]  :  2.96091\n",
      "[3.06296 3.54393 3.02076 3.02132 2.96091]  :  3.0197\n",
      "[3.54393 3.02076 3.02132 2.96091 3.0197 ]  :  3.23436\n",
      "[3.02076 3.02132 2.96091 3.0197  3.23436]  :  3.38341\n",
      "[3.02132 2.96091 3.0197  3.23436 3.38341]  :  3.34937\n",
      "[2.96091 3.0197  3.23436 3.38341 3.34937]  :  3.38859\n",
      "[3.0197  3.23436 3.38341 3.34937 3.38859]  :  3.01748\n",
      "[3.23436 3.38341 3.34937 3.38859 3.01748]  :  3.70674\n",
      "[3.38341 3.34937 3.38859 3.01748 3.70674]  :  3.49944\n",
      "[3.34937 3.38859 3.01748 3.70674 3.49944]  :  3.66572\n",
      "[3.38859 3.01748 3.70674 3.49944 3.66572]  :  3.21903\n",
      "[3.01748 3.70674 3.49944 3.66572 3.21903]  :  3.73453\n",
      "[3.70674 3.49944 3.66572 3.21903 3.73453]  :  3.55985\n",
      "[3.49944 3.66572 3.21903 3.73453 3.55985]  :  4.01077\n",
      "[3.66572 3.21903 3.73453 3.55985 4.01077]  :  3.85147\n",
      "[3.21903 3.73453 3.55985 4.01077 3.85147]  :  3.32722\n",
      "[3.73453 3.55985 4.01077 3.85147 3.32722]  :  3.23796\n",
      "[3.55985 4.01077 3.85147 3.32722 3.23796]  :  3.71757\n",
      "[4.01077 3.85147 3.32722 3.23796 3.71757]  :  3.9095\n",
      "[3.85147 3.32722 3.23796 3.71757 3.9095 ]  :  3.33305\n",
      "[3.32722 3.23796 3.71757 3.9095  3.33305]  :  2.8627\n",
      "[3.23796 3.71757 3.9095  3.33305 2.8627 ]  :  2.97266\n",
      "[3.71757 3.9095  3.33305 2.8627  2.97266]  :  3.29068\n",
      "[3.9095  3.33305 2.8627  2.97266 3.29068]  :  3.20267\n",
      "[3.33305 2.8627  2.97266 3.29068 3.20267]  :  3.4754\n",
      "[2.8627  2.97266 3.29068 3.20267 3.4754 ]  :  3.36869\n",
      "[2.97266 3.29068 3.20267 3.4754  3.36869]  :  3.01989\n",
      "[3.29068 3.20267 3.4754  3.36869 3.01989]  :  3.36631\n",
      "[3.20267 3.4754  3.36869 3.01989 3.36631]  :  3.32629\n",
      "[3.4754  3.36869 3.01989 3.36631 3.32629]  :  3.25603\n",
      "[3.36869 3.01989 3.36631 3.32629 3.25603]  :  2.99526\n",
      "[3.01989 3.36631 3.32629 3.25603 2.99526]  :  3.73689\n",
      "[3.36631 3.32629 3.25603 2.99526 3.73689]  :  3.56105\n",
      "[3.32629 3.25603 2.99526 3.73689 3.56105]  :  4.23537\n",
      "[3.25603 2.99526 3.73689 3.56105 4.23537]  :  3.68413\n",
      "[2.99526 3.73689 3.56105 4.23537 3.68413]  :  3.37651\n",
      "[3.73689 3.56105 4.23537 3.68413 3.37651]  :  3.51779\n",
      "[3.56105 4.23537 3.68413 3.37651 3.51779]  :  3.65164\n"
     ]
    }
   ],
   "source": [
    "# testing training data split - comment / uncomment what to try use\n",
    "\n",
    "# training_data = slide_window(list(sp_500[column][-2000:-500]),window_length)\n",
    "# print('\\n*************************************************************************************************\\n')\n",
    "# test_data = slide_window(list(sp_500[column][-500:]),window_length)\n",
    "\n",
    "# rather use volume data\n",
    "training_data = slide_window(list(sp_500[column][-2000:-500]/1e9),window_length)\n",
    "print('\\n*************************************************************************************************\\n')\n",
    "test_data = slide_window(list(sp_500[column][-500:]/1e9),window_length)\n",
    "\n",
    "# rather use % returns\n",
    "# training_data = slide_window(list(df[column][-2000:-500]),window_length)\n",
    "# print('\\n*************************************************************************************************\\n')\n",
    "# test_data = slide_window(list(df[column][-500:]),window_length)\n",
    "\n",
    "# fourier filtered results\n",
    "# inverse_transform_filtered_real = np.real(inverse_transform_filtered) # only take real part, this comes from taking the inverse fourier transform after filtering out low psd frequencies\n",
    "\n",
    "# training_data = slide_window(inverse_transform_filtered_real[-2000:-500],window_length)\n",
    "# print('\\n*************************************************************************************************\\n')\n",
    "# test_data = slide_window(inverse_transform_filtered_real[-500:],window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1495, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(495, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training data\n",
    "scaler = StandardScaler()\n",
    "training_data = scaler.fit_transform(training_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6661407bcfd84823b67794abff99e48a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x205aa4c3460>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# plot training and testing data\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "sp_500[column][-2000:-500].plot(ax=ax,style='k-',label='Training data') # replace returns with sp_500 for other data plotting\n",
    "sp_500[column][-500:].plot(ax=ax,style='r-',label='test data')\n",
    "# plt.plot(df[column][-500+window_length:].index,test_data[:,-1],'o',label='test data') # important to match time by start 5 (length of time window) after where segmented our testing and training data\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predictive modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train three models:\n",
    "- baseline model: naive model which says tomorrow's price is today's price.\n",
    "- multivariate regression\n",
    "- support vector regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.0929564 , 0.02141084, 0.04769785, 0.15121291, 0.44486063])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Train simple linear regression model and lets see what we get\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# data\n",
    "X = training_data[:,0:-1]\n",
    "Y = training_data[:,-1]\n",
    "\n",
    "# model\n",
    "reg_model = LinearRegression().fit(X,Y)\n",
    "\n",
    "# view trained model parameters\n",
    "reg_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Look at linear regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-0.10353962754299864\n-0.014555365013421882\n-0.07379247225137642\n0.030382735834152123\n-0.010669098418476786\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(reg_model.coef_)):\n",
    "    print(reg_model.coef_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For non-stationary data, eg only using Open price:\n",
    "- The weights of the previous time step is extremely strong / large, relative to previous time steps / features. ie this model is saying the best predictor for tomorrow is today. Essentially, predict tomorrow's price as todays price.\n",
    "\n",
    "For stationary data, eg using returns:\n",
    "- all weights are more similar in magnitude. This means that the model is not simply relying on X_t-1 to predict X_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Test model on test data, ie last 500 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           0        1        2        3        4        5\n",
       "0    3.39203  3.75977  3.54472  3.62828  4.95263  3.46744\n",
       "1    3.75977  3.54472  3.62828  4.95263  3.46744  3.23288\n",
       "2    3.54472  3.62828  4.95263  3.46744  3.23288  3.16816\n",
       "3    3.62828  4.95263  3.46744  3.23288  3.16816  3.29794\n",
       "4    4.95263  3.46744  3.23288  3.16816  3.29794  7.59745\n",
       "..       ...      ...      ...      ...      ...      ...\n",
       "490  3.32629  3.25603  2.99526  3.73689  3.56105  4.23537\n",
       "491  3.25603  2.99526  3.73689  3.56105  4.23537  3.68413\n",
       "492  2.99526  3.73689  3.56105  4.23537  3.68413  3.37651\n",
       "493  3.73689  3.56105  4.23537  3.68413  3.37651  3.51779\n",
       "494  3.56105  4.23537  3.68413  3.37651  3.51779  3.65164\n",
       "\n",
       "[495 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.39203</td>\n      <td>3.75977</td>\n      <td>3.54472</td>\n      <td>3.62828</td>\n      <td>4.95263</td>\n      <td>3.46744</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.75977</td>\n      <td>3.54472</td>\n      <td>3.62828</td>\n      <td>4.95263</td>\n      <td>3.46744</td>\n      <td>3.23288</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.54472</td>\n      <td>3.62828</td>\n      <td>4.95263</td>\n      <td>3.46744</td>\n      <td>3.23288</td>\n      <td>3.16816</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.62828</td>\n      <td>4.95263</td>\n      <td>3.46744</td>\n      <td>3.23288</td>\n      <td>3.16816</td>\n      <td>3.29794</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.95263</td>\n      <td>3.46744</td>\n      <td>3.23288</td>\n      <td>3.16816</td>\n      <td>3.29794</td>\n      <td>7.59745</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>490</th>\n      <td>3.32629</td>\n      <td>3.25603</td>\n      <td>2.99526</td>\n      <td>3.73689</td>\n      <td>3.56105</td>\n      <td>4.23537</td>\n    </tr>\n    <tr>\n      <th>491</th>\n      <td>3.25603</td>\n      <td>2.99526</td>\n      <td>3.73689</td>\n      <td>3.56105</td>\n      <td>4.23537</td>\n      <td>3.68413</td>\n    </tr>\n    <tr>\n      <th>492</th>\n      <td>2.99526</td>\n      <td>3.73689</td>\n      <td>3.56105</td>\n      <td>4.23537</td>\n      <td>3.68413</td>\n      <td>3.37651</td>\n    </tr>\n    <tr>\n      <th>493</th>\n      <td>3.73689</td>\n      <td>3.56105</td>\n      <td>4.23537</td>\n      <td>3.68413</td>\n      <td>3.37651</td>\n      <td>3.51779</td>\n    </tr>\n    <tr>\n      <th>494</th>\n      <td>3.56105</td>\n      <td>4.23537</td>\n      <td>3.68413</td>\n      <td>3.37651</td>\n      <td>3.51779</td>\n      <td>3.65164</td>\n    </tr>\n  </tbody>\n</table>\n<p>495 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df_test_data = pd.DataFrame(data=test_data)\n",
    "df_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction\tReal values\n[4.2101394] \t 3.46744\n[3.78326068] \t 3.23288\n[3.49930172] \t 3.16816\n[3.40032435] \t 3.29794\n[3.52839151] \t 7.59745\n[5.3145316] \t 5.43122\n[4.98400325] \t 4.38581\n[4.39321949] \t 4.24174\n[4.17184441] \t 4.62282\n[4.62300902] \t 3.45889\n[3.93222673] \t 3.65838\n[3.76288521] \t 3.90938\n[3.84396075] \t 3.60455\n[3.76632668] \t 3.6075\n[3.62959345] \t 3.25334\n[3.48186595] \t 4.09782\n[3.82093439] \t 3.50232\n[3.63855075] \t 3.46561\n[3.56514387] \t 3.1226\n[3.36375671] \t 3.00931\n[3.32548959] \t 2.96834\n[3.21763037] \t 3.21186\n[3.30360739] \t 3.4389\n[3.40516713] \t 3.02328\n[3.25481268] \t 3.05724\n[3.2193079] \t 3.44235\n[3.40343705] \t 3.9955\n[3.72157118] \t 3.66424\n[3.63831156] \t 4.03884\n[3.79265195] \t 3.50599\n[3.64409378] \t 3.84875\n[3.7781943] \t 3.78653\n[3.75415677] \t 3.7092\n[3.75010885] \t 3.66307\n[3.67273334] \t 3.32755\n[3.54333932] \t 3.3343\n[3.48596743] \t 3.25495\n[3.42750884] \t 3.42316\n[3.47919022] \t 3.00066\n[3.2818431] \t 3.07853\n[3.2595487] \t 3.1964\n[3.29983246] \t 3.38891\n[3.41360039] \t 3.30057\n[3.37142673] \t 3.0848\n[3.28102553] \t 2.77755\n[3.12257983] \t 3.04149\n[3.19924802] \t 3.14828\n[3.25917907] \t 2.96931\n[3.18166408] \t 3.34234\n[3.30273184] \t 2.65478\n[3.07155531] \t 3.0068\n[3.14807484] \t 3.76639\n[3.49777184] \t 3.39212\n[3.48287856] \t 3.09112\n[3.2722358] \t 3.44765\n[3.41646097] \t 3.31942\n[3.4615667] \t 3.72784\n[3.59963691] \t 4.23396\n[3.86008558] \t 4.01048\n[3.88707699] \t 4.14167\n[3.93261085] \t 3.6641\n[3.77813857] \t 3.37372\n[3.62526487] \t 5.01436\n[4.27046774] \t 3.163\n[3.68307579] \t 3.14073\n[3.42086374] \t 3.71209\n[3.5915007] \t 3.55283\n[3.7188558] \t 3.31719\n[3.44462673] \t 3.21617\n[3.3666219] \t 3.43777\n[3.48838964] \t 3.89146\n[3.69905932] \t 4.24922\n[3.91331912] \t 4.17334\n[3.95065525] \t 3.13755\n[3.52577643] \t 3.75089\n[3.68821644] \t 3.90655\n[3.83243485] \t 3.46155\n[3.658034] \t 3.61989\n[3.58545695] \t 2.91655\n[3.33563287] \t 3.43827\n[3.47386572] \t 2.9771\n[3.27607693] \t 3.58045\n[3.49929328] \t 3.22815\n[3.35759688] \t 2.83039\n[3.19477848] \t 3.17\n[3.23895672] \t 3.36267\n[3.40559135] \t 3.33717\n[3.39831534] \t 3.44885\n[3.42362839] \t 3.35732\n[3.43427561] \t 3.75134\n[3.61840991] \t 3.7752\n[3.68426018] \t 4.20483\n[3.90620914] \t 4.01951\n[3.88979924] \t 3.9224\n[3.87620602] \t 4.53216\n[4.13535726] \t 4.24858\n[4.13274433] \t 3.88674\n[3.93867336] \t 3.83786\n[3.85271601] \t 3.73606\n[3.83338833] \t 3.91693\n[3.86201746] \t 6.26415\n[4.89401556] \t 6.45164\n[5.33425623] \t 4.98805\n[4.81788053] \t 5.3672\n[4.84124757] \t 4.54386\n[4.68470174] \t 3.83059\n[4.2470727] \t 3.80916\n[3.96248002] \t 3.5724\n[3.8375089] \t 3.60701\n[3.72427576] \t 3.95794\n[3.80756939] \t 3.41864\n[3.61531074] \t 1.5846\n[2.7133407] \t 3.50565\n[3.27561716] \t 3.70656\n[3.58907624] \t 5.53398\n[4.43463388] \t 5.06374\n[4.38200062] \t 3.7795\n[4.00962599] \t 3.89523\n[3.90228907] \t 3.85532\n[4.00058122] \t 4.50182\n[4.21646031] \t 4.20058\n[4.06140557] \t 3.88448\n[3.91597374] \t 4.03451\n[3.9306815] \t 3.85759\n[3.91323245] \t 4.40697\n[4.10326335] \t 4.1682\n[4.04550738] \t 5.92034\n[4.82522286] \t 3.24837\n[3.88544282] \t 3.29878\n[3.63336131] \t 2.85223\n[3.3302038] \t 2.87632\n[3.38146432] \t 2.02055\n[2.7358118] \t 1.98708\n[2.5877928] \t 2.39236\n[2.68121254] \t 2.33637\n[2.69990848] \t 2.6709\n[2.77932636] \t 3.77053\n[3.32198925] \t 3.76489\n[3.53818943] \t 3.76182\n[3.59037879] \t 3.33989\n[3.4565862] \t 3.21761\n[3.44033784] \t 3.63879\n[3.58849876] \t 3.62041\n[3.62885834] \t 3.46213\n[3.53391667] \t 3.08127\n[3.33732749] \t 3.58499\n[3.53502997] \t 3.31525\n[3.46793858] \t 3.16597\n[3.36190031] \t 3.52497\n[3.46154789] \t 3.15271\n[3.38415781] \t 3.81096\n[3.60955006] \t 3.84602\n[3.70073673] \t 3.61036\n[3.65800045] \t 3.13589\n[3.39245462] \t 3.59127\n[3.573988] \t 4.08745\n[3.83916046] \t 3.91661\n[3.82784503] \t 3.80771\n[3.74287826] \t 3.59797\n[3.67791152] \t 3.10905\n[3.46596585] \t 3.44869\n[3.51491083] \t 3.60974\n[3.5999795] \t 3.67794\n[3.64090707] \t 3.47502\n[3.53045414] \t 3.34973\n[3.48230635] \t 3.52091\n[3.54626413] \t 3.77559\n[3.68146474] \t 3.67237\n[3.66067677] \t 3.51306\n[3.57836411] \t 3.57978\n[3.6003973] \t 3.46867\n[3.57492313] \t 4.01526\n[3.79145471] \t 3.83157\n[3.77370967] \t 3.58261\n[3.66507512] \t 4.21014\n[3.8992055] \t 4.34518\n[4.08917134] \t 3.82132\n[3.88407267] \t 3.55526\n[3.68323329] \t 3.2327\n[3.53574459] \t 3.51839\n[3.60270765] \t 3.8121\n[3.70678956] \t 3.71634\n[3.69059099] \t 3.43295\n[3.54018396] \t 3.1339\n[3.39257391] \t 3.17263\n[3.37631797] \t 3.90684\n[3.67956241] \t 3.36566\n[3.51893627] \t 5.17804\n[4.25141025] \t 3.05493\n[3.57448458] \t 4.26559\n[3.93512694] \t 3.57273\n[3.69719887] \t 3.2606\n[3.63433578] \t 2.97513\n[3.25565998] \t 3.24023\n[3.41324174] \t 3.36778\n[3.42536521] \t 3.10694\n[3.30613304] \t 3.15842\n[3.2748157] \t 3.35411\n[3.3845871] \t 3.4164\n[3.4506156] \t 3.20624\n[3.35273221] \t 3.77052\n[3.58392565] \t 3.20192\n[3.42580445] \t 3.05315\n[3.30184837] \t 2.78541\n[3.12567043] \t 3.11742\n[3.26606609] \t 3.19695\n[3.28283914] \t 3.14389\n[3.2675353] \t 2.82471\n[3.1035352] \t 3.26984\n[3.28332628] \t 3.5199\n[3.4529101] \t 3.64742\n[3.5569166] \t 3.50336\n[3.50390075] \t 3.69065\n[3.61824907] \t 3.99524\n[3.80117347] \t 4.10592\n[3.91417127] \t 4.09846\n[3.93273588] \t 3.71827\n[3.7916868] \t 3.19924\n[3.53362866] \t 3.81368\n[3.72047924] \t 3.89399\n[3.815527] \t 4.36254\n[4.01896386] \t 3.54014\n[3.69270042] \t 3.42944\n[3.60028131] \t 3.65359\n[3.66152822] \t 3.64353\n[3.71161359] \t 3.72742\n[3.6792857] \t 3.30563\n[3.49836231] \t 3.4736\n[3.53392761] \t 3.42079\n[3.51657629] \t 4.163\n[3.84554979] \t 4.31942\n[3.989236] \t 3.82516\n[3.84289691] \t 3.17283\n[3.49640569] \t 3.21357\n[3.4646557] \t 3.3899\n[3.52210137] \t 3.53539\n[3.55551917] \t 2.80504\n[3.20125977] \t 3.20316\n[3.28243131] \t 4.51611\n[3.9113819] \t 3.85714\n[3.83364337] \t 3.46168\n[3.56133228] \t 2.9126\n[3.29095725] \t 3.35784\n[3.49507443] \t 3.5723\n[3.56189273] \t 3.72886\n[3.63668943] \t 4.02734\n[3.76186706] \t 4.02775\n[3.86063074] \t 3.2755\n[3.56357069] \t 3.55559\n[3.5953853] \t 3.35305\n[3.53951015] \t 5.28472\n[4.36549893] \t 3.2647\n[3.68537479] \t 3.41651\n[3.56129208] \t 3.59482\n[3.58975149] \t 3.46821\n[3.70394224] \t 5.27833\n[4.3140299] \t 3.23897\n[3.69240289] \t 3.56391\n[3.6287814] \t 3.5008\n[3.57955526] \t 3.90028\n[3.88782191] \t 3.36159\n[3.52296193] \t 1.96229\n[2.86691992] \t 3.36722\n[3.2573181] \t 3.36452\n[3.42741735] \t 2.90133\n[3.20793136] \t 2.99913\n[3.08127647] \t 3.10675\n[3.25238725] \t 3.17162\n[3.29201548] \t 3.06767\n[3.21975214] \t 2.73664\n[3.07126088] \t 2.79317\n[3.05278753] \t 2.96213\n[3.12451426] \t 3.05976\n[3.17944085] \t 3.18278\n[3.22742855] \t 3.05957\n[3.20474862] \t 3.01024\n[3.18783675] \t 4.10806\n[3.67458675] \t 3.55702\n[3.60189984] \t 3.99552\n[3.75350116] \t 3.29477\n[3.50070822] \t 3.46921\n[3.58351394] \t 3.46086\n[3.53091862] \t 3.47858\n[3.57161707] \t 3.64502\n[3.5865366] \t 3.23514\n[3.44624674] \t 2.93178\n[3.25685672] \t 3.34464\n[3.38031034] \t 3.30806\n[3.41869327] \t 3.62107\n[3.5275041] \t 3.15993\n[3.34858786] \t 2.82255\n[3.18129514] \t 2.9131\n[3.15186713] \t 2.95365\n[3.18672914] \t 3.14262\n[3.23115568] \t 3.41568\n[3.3537153] \t 2.78815\n[3.13414098] \t 2.77749\n[3.05534789] \t 2.78529\n[3.05068645] \t 2.84659\n[3.09057414] \t 2.58878\n[2.92696485] \t 2.6777\n[2.92963762] \t 2.73758\n[2.95946229] \t 2.63366\n[2.9267066] \t 3.34811\n[3.20961814] \t 2.71073\n[3.03869794] \t 3.49026\n[3.326519] \t 3.37441\n[3.36809219] \t 3.35393\n[3.43141119] \t 3.30249\n[3.35734676] \t 3.29176\n[3.41380002] \t 3.23092\n[3.37145112] \t 3.36805\n[3.41973814] \t 3.41446\n[3.4532066] \t 4.85317\n[4.10449058] \t 3.1943\n[3.58357041] \t 3.2491\n[3.43947037] \t 3.53001\n[3.5287162] \t 2.93086\n[3.40548852] \t 2.86596\n[3.14638738] \t 3.29789\n[3.31125268] \t 3.04311\n[3.27341297] \t 3.45603\n[3.38209653] \t 3.16862\n[3.30774063] \t 3.21192\n[3.33793399] \t 3.19973\n[3.31050735] \t 3.06885\n[3.28473589] \t 3.01712\n[3.21556156] \t 3.04512\n[3.21771673] \t 2.88457\n[3.14412552] \t 2.48397\n[2.92969894] \t 2.9605\n[3.06924547] \t 2.97609\n[3.12829585] \t 3.15151\n[3.20791883] \t 3.14944\n[3.20723192] \t 2.91602\n[3.15607701] \t 2.88939\n[3.11404059] \t 2.99809\n[3.1634986] \t 2.99071\n[3.17019205] \t 3.38465\n[3.32724119] \t 3.21171\n[3.30937573] \t 3.42733\n[3.40788226] \t 3.87451\n[3.63891926] \t 3.86905\n[3.74731078] \t 3.88711\n[3.76438959] \t 3.65887\n[3.69494283] \t 3.82723\n[3.77763949] \t 3.81318\n[3.78583999] \t 4.04827\n[3.89312013] \t 3.56771\n[3.69660475] \t 3.53908\n[3.63776412] \t 3.80965\n[3.73460659] \t 3.89936\n[3.82562705] \t 3.83161\n[3.77667454] \t 3.48691\n[3.62049717] \t 3.40293\n[3.55485514] \t 3.64176\n[3.63884943] \t 3.55889\n[3.62041423] \t 3.31271\n[3.47591895] \t 3.30016\n[3.4264647] \t 3.00354\n[3.30129662] \t 3.33272\n[3.38931025] \t 2.76295\n[3.14831742] \t 1.34978\n[2.44168084] \t 3.00686\n[2.91745943] \t 3.48842\n[3.33325337] \t 4.07828\n[3.66429519] \t 4.93849\n[4.06324885] \t 3.94232\n[3.94264874] \t 4.02315\n[3.92639671] \t 3.53904\n[3.74899168] \t 3.229\n[3.60035201] \t 3.2924\n[3.46771338] \t 3.10615\n[3.37680521] \t 3.09195\n[3.29370949] \t 3.55568\n[3.46151101] \t 3.54237\n[3.52694023] \t 3.43003\n[3.47945371] \t 5.72392\n[4.49090181] \t 3.72466\n[3.98583885] \t 3.36859\n[3.63089447] \t 3.24103\n[3.46361665] \t 3.27339\n[3.61216577] \t 2.39983\n[3.02889446] \t 1.96878\n[2.67075709] \t 2.20208\n[2.65653115] \t 2.15333\n[2.63386643] \t 2.44349\n[2.67627133] \t 3.36725\n[3.09369275] \t 3.53866\n[3.34411371] \t 3.69526\n[3.4854406] \t 3.23662\n[3.36001625] \t 3.24265\n[3.39035539] \t 3.45348\n[3.48246762] \t 3.57635\n[3.57403259] \t 3.64132\n[3.58906644] \t 3.57397\n[3.57986459] \t 4.32597\n[3.92954327] \t 3.77805\n[3.80910751] \t 3.68147\n[3.72375643] \t 3.63943\n[3.67415607] \t 3.47178\n[3.64678333] \t 3.51965\n[3.58772221] \t 4.01407\n[3.79703438] \t 3.83515\n[3.78698849] \t 3.44323\n[3.59460727] \t 3.57383\n[3.59994437] \t 3.99065\n[3.82855452] \t 4.26128\n[3.99318196] \t 3.93845\n[3.87673656] \t 4.30113\n[4.02323558] \t 5.28346\n[4.54421963] \t 5.89166\n[4.99886863] \t 4.62657\n[4.55265879] \t 5.30544\n[4.74711915] \t 5.68007\n[5.06042506] \t 4.05579\n[4.45632581] \t 3.47287\n[3.86620155] \t 4.00374\n[4.00787147] \t 3.68491\n[3.91855399] \t 3.63746\n[3.71108747] \t 3.62761\n[3.64150326] \t 3.7794\n[3.74779729] \t 3.70127\n[3.70486988] \t 3.18919\n[3.46786976] \t 3.42465\n[3.49379123] \t 3.74508\n[3.65995443] \t 4.23066\n[3.9174272] \t 4.50397\n[4.08516213] \t 3.88245\n[3.90190966] \t 3.71081\n[3.78479092] \t 3.37069\n[3.62887514] \t 3.39327\n[3.59140135] \t 3.21232\n[3.43664599] \t 3.3641\n[3.45464469] \t 3.18502\n[3.35816634] \t 3.30165\n[3.38843548] \t 3.39136\n[3.42386743] \t 3.50033\n[3.50174687] \t 5.37234\n[4.34113758] \t 3.28213\n[3.71231743] \t 3.26103\n[3.48682724] \t 3.41551\n[3.50287096] \t 3.7398\n[3.79874992] \t 3.81508\n[3.69389406] \t 3.5111\n[3.58686274] \t 3.70635\n[3.65264999] \t 3.8645\n[3.76978647] \t 3.56599\n[3.67070774] \t 3.59852\n[3.62350749] \t 3.39281\n[3.54421174] \t 3.35034\n[3.50407382] \t 3.17897\n[3.38455219] \t 3.2997\n[3.40894058] \t 3.06296\n[3.29367485] \t 3.54393\n[3.46998285] \t 3.02076\n[3.28533699] \t 3.02132\n[3.23557111] \t 2.96091\n[3.17211915] \t 3.0197\n[3.22267218] \t 3.23436\n[3.27555433] \t 3.38341\n[3.37588296] \t 3.34937\n[3.38916025] \t 3.38859\n[3.41863072] \t 3.01748\n[3.28099073] \t 3.70674\n[3.54649578] \t 3.49944\n[3.53847553] \t 3.66572\n[3.60967672] \t 3.21903\n[3.40647843] \t 3.73453\n[3.63582264] \t 3.55985\n[3.59904883] \t 4.01077\n[3.80371253] \t 3.85147\n[3.76221389] \t 3.32722\n[3.57059438] \t 3.23796\n[3.43743144] \t 3.71757\n[3.65079334] \t 3.9095\n[3.77840857] \t 3.33305\n[3.52322379] \t 2.8627\n[3.23794312] \t 2.97266\n[3.23693378] \t 3.29068\n[3.37809989] \t 3.20267\n[3.32862599] \t 3.4754\n[3.41044574] \t 3.36869\n[3.41704764] \t 3.01989\n[3.28643058] \t 3.36631\n[3.38036458] \t 3.32629\n[3.42137468] \t 3.25603\n[3.38320324] \t 2.99526\n[3.22965779] \t 3.73689\n[3.54814184] \t 3.56105\n[3.56439897] \t 4.23537\n[3.86104784] \t 3.68413\n[3.70104025] \t 3.37651\n[3.5781756] \t 3.51779\n[3.56630874] \t 3.65164\n"
     ]
    }
   ],
   "source": [
    "# use trained model to predict\n",
    "\n",
    "# loop through each test data pattern and predict result\n",
    "predicted_results = []\n",
    "print('Prediction\\tReal values')\n",
    "for i in range(500-window_length):\n",
    "    X_test = test_data[i,0:-1]\n",
    "    prediction = reg_model.predict(X_test.reshape(1,-1))\n",
    "    predicted_results.append(prediction)\n",
    "    print(prediction,'\\t',test_data[i,-1])\n",
    "    \n",
    "# full prediction\n",
    "predictions = reg_model.predict(test_data[:,0:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE:  0.5274190796271083\nMAE:  0.3469516668079319\n"
     ]
    }
   ],
   "source": [
    "# use sklearn metric methods to calc rmse and mae\n",
    "mse = mean_squared_error(test_data[:,-1],predictions)\n",
    "mae = mean_absolute_error(test_data[:,-1],predictions)\n",
    "\n",
    "print('RMSE: ',np.sqrt(mse))\n",
    "print('MAE: ',mae)"
   ]
  },
  {
   "source": [
    "Results without filtering:\n",
    "- RMSE:  0.40624498456287134\n",
    "- MAE:  0.33153581191446285\n",
    "\n",
    "Results with filtering:\n",
    "- RMSE:  0.3814258615492118\n",
    "- MAE:  0.3079928467008209"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  a naive time series predictive model predicts the next results as the current ie x[i+1] = x[i]\n",
    "# ie this model will return n-1 values for n time stamps\n",
    "def naive_model(data):\n",
    "    preds = np.zeros(len(data))\n",
    "    preds[1:] = data[0:-1]\n",
    "    return  preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE:  0.6034655013934639\nMAE:  0.3807898380566802\n"
     ]
    }
   ],
   "source": [
    "# call naive model function\n",
    "naive_predictions = naive_model(test_data[:,-1])\n",
    "\n",
    "# evaluate predictions\n",
    "mse = mean_squared_error(test_data[1:,-1],naive_predictions[1:])\n",
    "mae = mean_absolute_error(test_data[1:,-1],naive_predictions[1:])\n",
    "\n",
    "print('RMSE: ',np.sqrt(mse))\n",
    "print('MAE: ',mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:    1.6s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# hyper parameter tuning grid of options to explore\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear','rbf','sigmoid'],'epsilon':[0.1,1,10,100]},\n",
    "  {'C': [1, 10, 100, 1000], 'degree': [2,3,4,5], 'kernel': ['poly'],'epsilon':[0.1,1,10,100]},\n",
    " ]\n",
    "\n",
    "# training on various hyperparameters\n",
    "svr_regres_hyper_params = GridSearchCV(SVR(),param_grid,n_jobs=-1,verbose=3).fit(training_data[:,0:-1],training_data[:,-1])\n",
    "\n",
    "# # predict\n",
    "# svm_predictions = svm_regres.predict(test_data[:,0:-1])\n",
    "\n",
    "# # evaluate\n",
    "# mse = mean_squared_error(test_data[:,-1],svm_predictions[:])\n",
    "# mae = mean_absolute_error(test_data[:,-1],svm_predictions[:])\n",
    "\n",
    "# print('RMSE: ',np.sqrt(mse))\n",
    "# print('MAE: ',mae)"
   ]
  },
  {
   "source": [
    "Results without filtering:\n",
    "- RMSE:  0.4054163757214758\n",
    "- MAE:  0.3283511990590936\n",
    "\n",
    "Results with filtering:\n",
    "- RMSE:  0.3816363957338525\n",
    "- MAE:  0.30785723389532904"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Multilayer perceptron neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 1, loss = 0.50127382\n",
      "Iteration 2, loss = 0.48466974\n",
      "Iteration 3, loss = 0.47285301\n",
      "Iteration 4, loss = 0.46699023\n",
      "Iteration 5, loss = 0.45994447\n",
      "Iteration 6, loss = 0.45405823\n",
      "Iteration 7, loss = 0.44829753\n",
      "Iteration 8, loss = 0.44316593\n",
      "Iteration 9, loss = 0.43771742\n",
      "Iteration 10, loss = 0.43288245\n",
      "Iteration 11, loss = 0.42774143\n",
      "Iteration 12, loss = 0.42285743\n",
      "Iteration 13, loss = 0.41778041\n",
      "Iteration 14, loss = 0.41254968\n",
      "Iteration 15, loss = 0.40780563\n",
      "Iteration 16, loss = 0.40261588\n",
      "Iteration 17, loss = 0.39727584\n",
      "Iteration 18, loss = 0.39294127\n",
      "Iteration 19, loss = 0.38736155\n",
      "Iteration 20, loss = 0.38279962\n",
      "Iteration 21, loss = 0.37664075\n",
      "Iteration 22, loss = 0.37223338\n",
      "Iteration 23, loss = 0.36662231\n",
      "Iteration 24, loss = 0.36215051\n",
      "Iteration 25, loss = 0.35623299\n",
      "Iteration 26, loss = 0.35191138\n",
      "Iteration 27, loss = 0.34678255\n",
      "Iteration 28, loss = 0.34262295\n",
      "Iteration 29, loss = 0.34310989\n",
      "Iteration 30, loss = 0.33918352\n",
      "Iteration 31, loss = 0.34578986\n",
      "Iteration 32, loss = 0.34146511\n",
      "Iteration 33, loss = 0.33707792\n",
      "Iteration 34, loss = 0.32225427\n",
      "Iteration 35, loss = 0.31685000\n",
      "Iteration 36, loss = 0.31187106\n",
      "Iteration 37, loss = 0.30709711\n",
      "Iteration 38, loss = 0.30666507\n",
      "Iteration 39, loss = 0.31002263\n",
      "Iteration 40, loss = 0.30413195\n",
      "Iteration 41, loss = 0.29714216\n",
      "Iteration 42, loss = 0.30372840\n",
      "Iteration 43, loss = 0.30066730\n",
      "Iteration 44, loss = 0.29373704\n",
      "Iteration 45, loss = 0.31218623\n",
      "Iteration 46, loss = 0.29988630\n",
      "Iteration 47, loss = 0.29980272\n",
      "Iteration 48, loss = 0.29208111\n",
      "Iteration 49, loss = 0.29816693\n",
      "Iteration 50, loss = 0.29374913\n",
      "Iteration 51, loss = 0.29078670\n",
      "Iteration 52, loss = 0.28073391\n",
      "Iteration 53, loss = 0.28509760\n",
      "Iteration 54, loss = 0.27464047\n",
      "Iteration 55, loss = 0.27088310\n",
      "Iteration 56, loss = 0.26769449\n",
      "Iteration 57, loss = 0.26936155\n",
      "Iteration 58, loss = 0.26216503\n",
      "Iteration 59, loss = 0.25888092\n",
      "Iteration 60, loss = 0.26067248\n",
      "Iteration 61, loss = 0.26153025\n",
      "Iteration 62, loss = 0.25789876\n",
      "Iteration 63, loss = 0.25373278\n",
      "Iteration 64, loss = 0.25955179\n",
      "Iteration 65, loss = 0.25542037\n",
      "Iteration 66, loss = 0.25738837\n",
      "Iteration 67, loss = 0.25579602\n",
      "Iteration 68, loss = 0.25999935\n",
      "Iteration 69, loss = 0.25456082\n",
      "Iteration 70, loss = 0.25553727\n",
      "Iteration 71, loss = 0.25196670\n",
      "Iteration 72, loss = 0.24822788\n",
      "Iteration 73, loss = 0.24214707\n",
      "Iteration 74, loss = 0.24337835\n",
      "Iteration 75, loss = 0.24309632\n",
      "Iteration 76, loss = 0.24818096\n",
      "Iteration 77, loss = 0.24766608\n",
      "Iteration 78, loss = 0.25398807\n",
      "Iteration 79, loss = 0.24397240\n",
      "Iteration 80, loss = 0.23720527\n",
      "Iteration 81, loss = 0.22434942\n",
      "Iteration 82, loss = 0.21707550\n",
      "Iteration 83, loss = 0.21237242\n",
      "Iteration 84, loss = 0.20892692\n",
      "Iteration 85, loss = 0.20788169\n",
      "Iteration 86, loss = 0.20576287\n",
      "Iteration 87, loss = 0.20545626\n",
      "Iteration 88, loss = 0.20298555\n",
      "Iteration 89, loss = 0.20177032\n",
      "Iteration 90, loss = 0.20075378\n",
      "Iteration 91, loss = 0.20207929\n",
      "Iteration 92, loss = 0.20171514\n",
      "Iteration 93, loss = 0.20604265\n",
      "Iteration 94, loss = 0.20950097\n",
      "Iteration 95, loss = 0.22999690\n",
      "Iteration 96, loss = 0.24529630\n",
      "Iteration 97, loss = 0.26735113\n",
      "Iteration 98, loss = 0.24802675\n",
      "Iteration 99, loss = 0.23784785\n",
      "Iteration 100, loss = 0.21857153\n",
      "Iteration 101, loss = 0.20442375\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "RMSE:  0.7993183394927919\n",
      "MAE:  0.5199959937539457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# train neural network\n",
    "nn_regres = MLPRegressor(hidden_layer_sizes=(100,100,100),shuffle=False,random_state=1, \n",
    "                         max_iter=1000,verbose=1).fit(training_data[:,0:-1],training_data[:,-1])\n",
    "\n",
    "# make predictions\n",
    "nn_predictions = nn_regres.predict(test_data[:,0:-1])\n",
    "\n",
    "# evaluate\n",
    "mse = mean_squared_error(test_data[:,-1],nn_predictions[:])\n",
    "mae = mean_absolute_error(test_data[:,-1],nn_predictions[:])\n",
    "\n",
    "print('RMSE: ',np.sqrt(mse))\n",
    "print('MAE: ',mae)"
   ]
  },
  {
   "source": [
    "Results without filtering:\n",
    "- RMSE:  0.5356554382964639\n",
    "- MAE:  0.4010986581137097\n",
    "\n",
    "Results with filtering:\n",
    "- RMSE:  0.47539037753112584\n",
    "- MAE:  0.35201690512468486"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plot results of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function computes the error between two vectors / arrays, give the one is a vector of predicted values and the other is of real values\n",
    "def error(real_data,predicted_data):\n",
    "    error = np.zeros(len(real_data))\n",
    "    error = (real_data - predicted_data) / real_data\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0373d75a9a6043679c8c27cb3e866261"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-10.0, 10.0)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# plot prediction against actual + training data\n",
    "fig, ax = plt.subplots(2,1,figsize=(9,10),sharex=True)\n",
    "\n",
    "# test and real y values data\n",
    "# returns[column][-500:].plot(ax=ax[0],style='o-',linewidth=3,label='real values',markersize=5) # for plotting unormalized values\n",
    "ax[0].plot(df[column][-500+window_length:].index,test_data[:,-1],'o-',linewidth=3,label='real values',markersize=5) # plotting normalized training data\n",
    "# predict y values\n",
    "ax[0].plot(df[column][-500+window_length:].index,predicted_results[:],'o-',label='linear regression prediction',markersize=5)\n",
    "# ax[0].plot(df[column][-500+window_length+1:].index,naive_predictions[1:],'.--',label='naive prediction',markersize=5)\n",
    "ax[0].plot(df[column][-500+window_length:].index,svm_predictions[:],'.--',label='svm prediction',markersize=5)\n",
    "ax[0].plot(df[column][-500+window_length:].index,nn_predictions[:],'.--',label='nn prediction',markersize=5)\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Real values vs model predictions')\n",
    "\n",
    "# plot error plot\n",
    "error_linreg = error(np.array(test_data[:,-1]),predictions)\n",
    "error_naive = error(np.array(test_data[:,-1]),naive_predictions)\n",
    "error_svm = error(np.array(test_data[:,-1]),svm_predictions)\n",
    "error_nn = error(np.array(test_data[:,-1]),nn_predictions)\n",
    "\n",
    "ax[1].plot(df[column][-500+window_length:].index,error_linreg,'r-',label='linear reg error')\n",
    "ax[1].plot(df[column][-500+window_length+1:].index,error_naive[1:],'-',label='naive error')\n",
    "ax[1].plot(df[column][-500+window_length:].index,error_svm[:],'-',label='svm error')\n",
    "ax[1].plot(df[column][-500+window_length:].index,error_nn[:],'-',label='nn error')\n",
    "ax[1].set_title('Error signal for predictive models')\n",
    "ax[1].set_xlabel('Days since 1950 for s&p500')\n",
    "ax[1].legend()\n",
    "ax[1].set_ylim([-10,10])\n",
    "\n",
    "\n",
    "# titles and save figures\n",
    "# title_string = 'S&P500 predictions _ y is '+str(column)+'_ window len is '+ str(window_length)\n",
    "# fig.suptitle(title_string)\n",
    "# plt.tight_layout()\n",
    "# fig_name = '../results/univariate_single_step_ahead/'+title_string+'.png'\n",
    "# plt.savefig(fig_name,facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Discussion of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from the graph above we can see that our suspiciouns have been confirmed: the linear regression is essentially saying the next value is the previous. This can be seen as the predicted results is almost just the actual results shift forward.\n",
    "- another validation of the above hypothesis is the fact that the naive model performs near identically to linear regression\n",
    "- if you zoom in you can see all models seem to favour yesterday's result as the best for today. \n",
    "- as you expand and contract the slide window, the linear reg and svm models perform very similary. The neural network however smoothens the results a lot more the longer the sliding window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising data using FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy fft functions\n",
    "from scipy.fft import fft, ifft, fftfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  2.400024,  -6.400024, -30.539917, ...,  22.969971,   6.790039,\n",
       "         4.790039])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# dataframe to np array\n",
    "length_of_time = -2000\n",
    "signal = np.array(returns['returns'][length_of_time:])\n",
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8186ef8ad11a46f1b871193b5586158f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21409a63400>]"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# plot original signal\n",
    "fig,ax = plt.subplots(figsize=(12,5))\n",
    "ax.plot(returns['returns'][length_of_time:].index,signal,'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1678.150024    -0.j        ,  145.60226937 +12.50087687j,\n",
       "        183.89946634+709.8176786j , ..., -105.58107383 +34.61480548j,\n",
       "        183.89946634-709.8176786j ,  145.60226937 -12.50087687j])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "# apply discrete fourier transform\n",
    "fft_coefficients = fft(signal)\n",
    "fft_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b329a00aac048c0a8d6045c83209e5e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Frequencies')"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "# plot amplitude vs frequency \n",
    "n = len(signal)\n",
    "\n",
    "# get frequencies and psd\n",
    "freqs = fftfreq(signal.shape[0])\n",
    "psd = np.abs(fft_coefficients)/n # psd is amplitude/N\n",
    "\n",
    "# plot psd\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(freqs[0:int(n/2)],psd[0:int(n/2)])\n",
    "ax.set_ylabel('Power spectrum')\n",
    "ax.set_xlabel('Frequencies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Volume data: we can see there is a low frequency component that is very large and many low amplitude frequency components.\n",
    "- Returns data: looks very much like a random process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "15218    3896410000\n",
       "15219    6136700000\n",
       "15220    5067080000\n",
       "15221    6435770000\n",
       "15222    3968500000\n",
       "            ...    \n",
       "17213    4235370000\n",
       "17214    3684130000\n",
       "17215    3376510000\n",
       "17216    3517790000\n",
       "17217    3651640000\n",
       "Name: Volume, Length: 2000, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "sp_500['Volume'][length_of_time:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80d0815af81b4aac9eb84be512c05796"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# plot inverse fourier transform as sanity check\n",
    "inverse_fft = ifft(fft_coefficients)\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(returns['returns'][length_of_time:].index,inverse_fft,'-',label='Inverse fourier')\n",
    "ax.plot(returns['returns'][length_of_time:].index,returns['returns'][length_of_time:],'.',label='Real data')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoise by removing frequencies with low amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9556c44aa8ce47fd9021d9109c25c08c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# try denoise data\n",
    "psd_indices = psd > 0.6 # mask\n",
    "fft_filtered = fft_coefficients*psd_indices\n",
    "\n",
    "inverse_transform_filtered = ifft(fft_filtered)\n",
    "\n",
    "# plot this\n",
    "fig,ax = plt.subplots(figsize=(12,5))\n",
    "ax.plot(returns['returns'][length_of_time:].index,returns['returns'][length_of_time:],'-',label='Real data')\n",
    "ax.plot(returns['returns'][length_of_time:].index,inverse_transform_filtered,'-',label='Inverse fourier filtered')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The Fourier transform is only able to char-\n",
    "acterize truly periodic and stationary signals, as time is stripped out via the\n",
    "integration in (2.18a). For a signal with non-stationary frequency content, such\n",
    "as a musical composition, it is important to simultaneously characterize the\n",
    "frequency content and its evolution in time.\" - Steve Burton text book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0275\n0.052000000000000005\n0.07200000000000001\n0.0935\n0.10350000000000001\n0.1075\n0.11800000000000001\n0.121\n0.132\n0.146\n0.1555\n0.1695\n0.1715\n0.17550000000000002\n0.176\n0.1845\n0.1875\n0.1925\n0.2085\n0.2565\n0.275\n0.28250000000000003\n0.2915\n0.2985\n0.3005\n0.303\n0.309\n0.314\n0.3325\n0.3355\n0.3375\n0.34500000000000003\n0.363\n0.3795\n0.386\n0.4045\n0.41600000000000004\n0.4225\n0.445\n-0.445\n-0.4225\n-0.41600000000000004\n-0.4045\n-0.386\n-0.3795\n-0.363\n-0.34500000000000003\n-0.3375\n-0.3355\n-0.3325\n-0.314\n-0.309\n-0.303\n-0.3005\n-0.2985\n-0.2915\n-0.28250000000000003\n-0.275\n-0.2565\n-0.2085\n-0.1925\n-0.1875\n-0.1845\n-0.176\n-0.17550000000000002\n-0.1715\n-0.1695\n-0.1555\n-0.146\n-0.132\n-0.121\n-0.11800000000000001\n-0.1075\n-0.10350000000000001\n-0.0935\n-0.07200000000000001\n-0.052000000000000005\n-0.0275\n"
     ]
    }
   ],
   "source": [
    "# see which frequencies are left over\n",
    "blah = freqs*psd_indices\n",
    "\n",
    "for i in range(len(blah)):\n",
    "    if np.abs(blah[i]) > 0:\n",
    "        print(blah[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed81dd55059d4c979191b7c3e54f0d03"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "from scipy import signal\n",
    "\n",
    "f, t, Sxx = signal.spectrogram(sp_500['Volume'][-2000:], fs=1,noverlap=49,nperseg=50)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.pcolormesh(t, f, Sxx, shading='gouraud')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [days]')\n",
    "plt.ylim([0,0.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5.63692933e+16, 1.32385057e+17, 4.26608158e+16, ...,\n",
       "        6.73891146e+16, 4.24321582e+16, 4.41197199e+16],\n",
       "       [3.93966393e+18, 3.72354054e+18, 3.66739112e+18, ...,\n",
       "        8.57639685e+16, 1.08110694e+17, 1.21823104e+17],\n",
       "       [1.55935367e+16, 7.92197875e+16, 3.17023750e+17, ...,\n",
       "        1.50629460e+18, 1.49136756e+18, 1.53511289e+18],\n",
       "       ...,\n",
       "       [1.07690148e+17, 1.70599939e+17, 2.31434011e+17, ...,\n",
       "        9.53720439e+16, 1.18116493e+17, 1.33473627e+17],\n",
       "       [4.12520827e+17, 2.54366254e+17, 1.73914317e+17, ...,\n",
       "        3.25827455e+16, 2.49922579e+16, 2.07734163e+16],\n",
       "       [6.72550316e+16, 2.19158849e+16, 5.25357651e+15, ...,\n",
       "        2.62991654e+17, 2.73245010e+17, 2.73310669e+17]])"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "Sxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi resolution analysis: wavelet transfroms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "maximum level is 7\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d845318082f64000896b5f1038a4f052"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba00332ba1604b579fb8cb892172d02d"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "data = sp_500['Volume'][-2000:]/1e9\n",
    "index = sp_500['Volume'][-2000:].index\n",
    "\n",
    "# Create wavelet object and define parameters\n",
    "w = pywt.Wavelet('sym5')\n",
    "maxlev = pywt.dwt_max_level(len(data), w.dec_len) # max level of decomposition ie scale, is determined by length of signal and discrete wavelet\n",
    "# maxlev = 2 # Override if desired\n",
    "print(\"maximum level is \" + str(maxlev))\n",
    "threshold = 0.25 # Threshold for filtering\n",
    "\n",
    "# Decompose into wavelet components, to the level selected:\n",
    "coeffs = pywt.wavedec(data, 'sym5', level=maxlev)\n",
    "\n",
    "#cA = pywt.threshold(cA, threshold*max(cA))\n",
    "plt.figure(figsize=(10,15))\n",
    "for i in range(1, len(coeffs)):\n",
    "    plt.subplot(maxlev, 1, i)\n",
    "    plt.plot(coeffs[i],label='Wavelet convolution result')\n",
    "    coeffs[i] = pywt.threshold(coeffs[i], threshold*max(coeffs[i]))\n",
    "    plt.plot(coeffs[i],label='Wavelet convolution after threshold applied')\n",
    "    plt.legend()\n",
    "    plt.title('Scale '+str(len(coeffs)-i))\n",
    "\n",
    "# inverse transfer: filtered wavelet decomposition back to time-domain signal \n",
    "datarec = pywt.waverec(coeffs, 'sym5')\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(index[:], data[:])\n",
    "plt.title(\"Raw signal\")\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(index[:], datarec[:])\n",
    "plt.title(\"De-noised signal using wavelet techniques\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.85932648, -0.75737687,  0.76355347, -0.34913312, -0.16279403,\n",
       "       -0.76114776,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.12235676,  0.26248507, -0.06482176,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.63698799,  0.        ,  0.        ,  0.38769524,\n",
       "       -0.56960617,  0.        , -0.10405331,  0.        ,  0.07282566,\n",
       "        0.89455122,  0.16268321, -0.        ,  0.42022552, -0.32984069,\n",
       "       -0.13124772,  0.212767  , -0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.04108364,  0.43650019, -0.25840387,\n",
       "        1.35908357,  0.78448203,  0.        ,  0.72527156, -0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.46010958, -0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.37279977, -0.        , -0.        ,  0.        ,\n",
       "        0.20408491, -0.07739027, -0.        , -0.00717482,  0.13746286,\n",
       "       -0.77915396,  0.        , -0.39344671,  0.        ,  0.        ,\n",
       "        0.14089513,  0.39031006, -0.        ,  0.        ,  0.16871636,\n",
       "       -0.        ,  0.06545919, -0.        , -0.        , -0.54845177,\n",
       "        0.        ,  0.        ,  0.11835064,  1.08238489, -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.05774897,  0.31376082,\n",
       "        0.        ,  0.        , -0.18527275, -0.19927195,  0.        ,\n",
       "        0.02923763,  0.        ,  0.        , -0.        , -0.12935568,\n",
       "       -0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.19667934, -0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.21286516, -0.30346883,\n",
       "       -0.26233738, -0.        ,  0.12855266,  0.        , -0.99324642,\n",
       "       -0.        , -0.        , -0.07946782,  0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.61510657,  0.24025994,  0.13644765,\n",
       "       -0.        ,  0.        , -0.19156712, -0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.86062633, -0.        ,  0.35376696,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.75431488,  0.07813185, -0.09353884, -0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.60776525, -0.        ,\n",
       "        0.        , -0.02334604,  0.        , -0.        ,  0.        ,\n",
       "       -0.08764678, -0.13876864,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.21479145,  0.        , -0.        ,  0.21968674,\n",
       "       -1.03802044, -0.        ,  0.86433804,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.08557192, -0.09799275,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.29158493,\n",
       "       -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.36067229,  0.        , -0.        ,  0.53745336,  0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.77480871,  0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.32199254, -0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.20817743, -0.58515768, -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.28216616,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        , -0.42674734,\n",
       "        0.08510636,  0.        , -0.1312328 ,  0.        ,  0.00429425,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.25166397,\n",
       "        0.        ,  0.33263124, -0.        , -0.56200652,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.10241625,  0.        ,  0.        , -0.03024712,\n",
       "        1.24377327, -0.53846205, -0.43046421,  0.        ,  0.        ,\n",
       "       -0.        , -0.16602397,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.13119929,\n",
       "        0.        ,  0.        ,  0.        , -0.04797285, -0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.71181426, -0.29300121,  0.        ,  0.35285899,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.57892174,  0.74774642, -0.        , -0.        ,\n",
       "        0.0116974 , -0.22295926, -0.        ,  0.        ,  0.06544686,\n",
       "       -0.        , -0.        ,  0.        , -0.        , -1.16825699,\n",
       "        0.        ,  0.        , -0.        ,  0.81686007, -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.55415834, -0.        ,\n",
       "       -0.15982741,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.17761163, -0.        , -0.        ,  1.5518865 ,  0.        ,\n",
       "        0.        ,  0.0058538 ,  0.        , -0.2525387 ,  0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.07209133,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        ,  0.98161264,\n",
       "        0.69261987,  0.        ,  0.        ,  0.0112879 , -0.        ,\n",
       "       -0.02121316,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.14359954, -0.        , -0.        ,\n",
       "       -0.03593099, -0.02018245,  0.07400589,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.20022049, -0.        ,\n",
       "        0.        ,  0.        , -1.7427469 ,  0.        ,  0.150522  ,\n",
       "       -0.44130183, -0.        , -0.        ,  0.        , -0.00954868,\n",
       "       -0.        , -0.        ,  0.        ,  0.03723675, -0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.12399215,  0.        ,\n",
       "       -0.06465932,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.17362767,\n",
       "        0.        , -0.22356612, -0.        , -0.29825384,  0.        ,\n",
       "        0.        , -0.53597279, -0.04288836,  0.00535072,  0.02398773,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.0663516 , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        ,  0.76382402,\n",
       "       -0.19481421,  0.        , -0.        , -0.17766031, -0.        ,\n",
       "       -0.        ,  0.06891677, -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        , -0.18041501, -0.        ,\n",
       "       -0.30915685,  0.        ,  0.        , -0.42497474, -0.01578933,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.07909861,  0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "coeffs[6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0e1d4880ad13fa2099fc93eba0cb791232af4f1a31a1c632661aaef6a29f2ead6",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}