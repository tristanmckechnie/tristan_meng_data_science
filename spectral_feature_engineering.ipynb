{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral denoising as feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we investigate the use of Fourier and Wavelet tranforms as a denosing pre-processing step prior to time series forecasting. This approach can be summarised as:\n",
    "- step 1: Spectral tranforms of time series data, a transform from the time to frequency domain\n",
    "- step 2: filter out high frequency noise components.\n",
    "- step 3: inverses tranforms the frequency signal back to the time domain.\n",
    "- step 4: forecasting the denoised signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bespoke modules\n",
    "from one_dimensional_time_series_forecasting import time_series_prediction, hit_rate, invert_first_difference,invert_first_difference_2,invert_scaling, invert_first_difference_with_log_2, invert_scaling,inverted_conclusion\n",
    "from walkforward_validation import walk_forward_val, series_to_supervised\n",
    "from spectral_denoising import automatic_fourier_denoising, automatic_fourier_denoising_wf, automatic_wavelet_denoising, automatic_wavelet_denoising_wf\n",
    "\n",
    "# model evalution metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# interactive figures\n",
    "%matplotlib widget \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fourier methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_assets = ['CrudeOil','S&P500','Apple','EurUsd'] # AirPassengers',\n",
    "feat_engineering = 'fourier'\n",
    "column_to_predict = 'Close' #'#Passengers' \n",
    "\n",
    "for financial_asset in financial_assets:\n",
    "    ###################################################################################################\n",
    "    # import some data\n",
    "    ###################################################################################################\n",
    "\n",
    "    df = pd.read_csv(f'./test_data/{financial_asset}_yfinance.csv') # sp_500 = GSPC.csv, # airplaine = AirPassengers.csv\n",
    "    df = df.iloc[-2000:,:].reset_index(drop=True) # only look at last 2000 days\n",
    "    # df['Date'] = df['Month']\n",
    "    df.plot(x='Date',y=f'{column_to_predict}',figsize=(10,5),legend=True,xlabel='Month',subplots=True)\n",
    "    plt.tight_layout()\n",
    "    display(df)\n",
    "\n",
    "    # some forecasting parameters\n",
    "    window_length = 10\n",
    "    split = 500 # 44 for AirPlane\n",
    "\n",
    "    ###################################################################################################\n",
    "    # feature engineering\n",
    "    ###################################################################################################\n",
    "\n",
    "    # fft the testing data\n",
    "    signal = np.array(df[f'{column_to_predict}'][-2000:-split]) # data\n",
    "    denoised_signal = automatic_fourier_denoising(signal,df, split,verbose=False)\n",
    "\n",
    "    ###################################################################################################\n",
    "    # single out of sample validation results\n",
    "    ###################################################################################################\n",
    "\n",
    "    # input data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_training_data = scaler.fit_transform(denoised_signal.reshape(-1, 1)).flatten()\n",
    "    scaled_test_data = scaler.transform(df[f'{column_to_predict}'][-split:].to_numpy().reshape(-1,1)).flatten()\n",
    "    scaled_input_data = np.append(scaled_training_data,scaled_test_data)\n",
    "\n",
    "    # initialize class object\n",
    "    blah = time_series_prediction(financial_asset,feat_engineering,df['Date'],scaled_input_data,window_length,1)#time_series_prediction(sp_500['Date'][-4000:],sp_500['Volume'][-4000:]/1e9,5,1) # pass: ime series dates, univariate time series, lag window length, a number of steps ahead to predict\n",
    "    blah.sliding_window_1(verbose=0) # time series to supervised ML problem\n",
    "    blah.train_test_split(split=split) # testing and training dataset split\n",
    "    blah.test_train_plot(ylabel='Close price')    # visualize training split\n",
    "\n",
    "    # perform some prediction tasks\n",
    "    blah.linear_regression()\n",
    "    blah.support_vector_machine(model_tunning=True,C= 0.1, kernel= 'linear',epsilon=0.1)\n",
    "    blah.neural_net_mlp(model_tunning=True,\n",
    "                        activation= 'relu', \n",
    "                        hidden_layer_sizes= (100, 100, 100), \n",
    "                        learning_rate= 'invscaling', \n",
    "                        learning_rate_init= 0.001,\n",
    "                        solver='adam')\n",
    "    blah.lstm(model_tunning=True,n_batch=64)\n",
    "    blah.naive_model()\n",
    "\n",
    "    # tabulate results nicely\n",
    "    blah.collect_results()\n",
    "\n",
    "    # visualize results\n",
    "    blah.vis_results_time_series(ylabel='Close price',second_plot='error')\n",
    "\n",
    "    # view final results\n",
    "    blah.conclusion()\n",
    "\n",
    "    ###################################################################################################\n",
    "    # invert feature engineering (if possible)\n",
    "    ###################################################################################################\n",
    "\n",
    "    # invert scaling\n",
    "    inverted_predictions_linear, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.linear_reg_predictions)\n",
    "    inverted_predictions_svm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.svm_predictions)\n",
    "    inverted_predictions_nn, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.neural_net_predictions)\n",
    "    inverted_predictions_lstm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.lstm_predictions)\n",
    "\n",
    "    # collect inverted results\n",
    "\n",
    "    df_inverted_results = pd.DataFrame(columns=['Date','Value','Linear','SVM','NN','LSTM'])\n",
    "    df_inverted_results['Date'] = df['Date']\n",
    "    df_inverted_results['Value'] = df[f'{column_to_predict}']\n",
    "    df_inverted_results['Linear'].iloc[-split:] = inverted_predictions_linear.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['SVM'].iloc[-split:] = inverted_predictions_svm.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['NN'].iloc[-split:] =  inverted_predictions_nn.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['LSTM'].iloc[-split:] = inverted_predictions_lstm.flatten()#['invert_pred_value'].astype(float)\n",
    "\n",
    "    # plot invert results\n",
    "    ax = df_inverted_results.plot(figsize=(10,4), x='Date', fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(rotation=30, labelsize=12)    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_inverted.png')\n",
    "\n",
    "    # store results\n",
    "    inverted_conclusion(dates=df['Date'].iloc[-split:],\n",
    "                        original_values=df[f'{column_to_predict}'].iloc[-split:], \n",
    "                        linear_preds=inverted_predictions_linear, \n",
    "                        svm_pred=inverted_predictions_svm, \n",
    "                        nn_preds=inverted_predictions_nn, \n",
    "                        lstm_preds=inverted_predictions_lstm,\n",
    "                        financial_asset=financial_asset,\n",
    "                        feat_engineer=feat_engineering)\n",
    "\n",
    "    ###################################################################################################\n",
    "    # walk forward validation results\n",
    "    ###################################################################################################\n",
    "    mapping = {'LinearReg':blah.linear_regression_model,\n",
    "                'svr':blah.svr_model,\n",
    "                'MLP':blah.mlp_model,\n",
    "                'LSTM':blah.lstm_model}\n",
    "\n",
    "    # store evaulation results for different models\n",
    "    model_results = []\n",
    "    inverted_results = []\n",
    "    model_pred_results = {'Original Values':None,\n",
    "                'LinearReg':None,\n",
    "                'svr':None,\n",
    "                'MLP':None,\n",
    "                'LSTM':None,\n",
    "                }\n",
    "\n",
    "    # unfeature engineered data for walkforward\n",
    "    walk_forward_input = scaler.transform(df[f'{column_to_predict}'][-2000:].to_numpy().reshape(-1,1)).flatten()\n",
    "\n",
    "    # apply walkforward for all models\n",
    "    for model_name in mapping.keys():\n",
    "\n",
    "        # retrieve model\n",
    "        model = mapping[model_name]\n",
    "\n",
    "        # apply walk forward and save results\n",
    "        train_len = 225 # 48 for Airplane\n",
    "        test_len = 25   # 12 for Airplane\n",
    "        df_walk_forward, df_hit_rate, mse,mae,mape,accuracy = walk_forward_val(model_name,model,\n",
    "                                                                                    original_series = walk_forward_input,\n",
    "                                                                                    time_series_dates=df['Date'].iloc[-2000:],\n",
    "                                                                                    lag_window_length=window_length,\n",
    "                                                                                    train_len=train_len,\n",
    "                                                                                    test_len=test_len,\n",
    "                                                                                    train_frequency=10,\n",
    "                                                                                    transformer=automatic_fourier_denoising_wf,\n",
    "                                                                                    only_training=True,\n",
    "                                                                                    verbose=False,\n",
    "                                                                                    threshold_override=False,\n",
    "                                                                                    threshold=0.05\n",
    "                                                                                    )\n",
    "        # wrangle results\n",
    "\n",
    "        # tables \n",
    "        model_results.append({'model':model_name,'mse':mse,'mae':mae,'mape':mape,'accuracy':accuracy})\n",
    "\n",
    "        # invert results for different models\n",
    "\n",
    "        # invert scaling\n",
    "        inverted_predictions, inverted_testing_data = invert_scaling(scaler,scaled_input_data[train_len:],df_walk_forward['prediction'].to_numpy())\n",
    "\n",
    "        invert_mse = np.sqrt(mean_squared_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions))\n",
    "        invert_mae = mean_absolute_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions)\n",
    "        invert_mape = mean_absolute_percentage_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions)\n",
    "        df_hit_rate, invert_accuracy = hit_rate(dates=df['Date'].iloc[train_len:],\n",
    "                                        original_values=df[f'{column_to_predict}'].iloc[train_len:],\n",
    "                                        predictions=inverted_predictions)\n",
    "\n",
    "        inverted_results.append({'model':model_name,'mse':invert_mse,'mae':invert_mae,'mape':invert_mape,'accuracy':invert_accuracy})\n",
    "\n",
    "\n",
    "        # save prediction so we can view inverted walk forward results too\n",
    "        model_pred_results['Original Values'] = df[f'{column_to_predict}'].iloc[train_len:]\n",
    "        model_pred_results[model_name] = inverted_predictions.flatten()\n",
    "\n",
    "        # plots\n",
    "        df_walk_forward['error'] = abs((df_walk_forward['real_value'] - df_walk_forward['prediction']) / df_walk_forward['real_value'])\n",
    "        \n",
    "        fig, ax = plt.subplots(2,1, figsize=(10,8),sharex=True)\n",
    "        ax[0].plot(df['Date'].iloc[train_len:],df[f'{column_to_predict}'].iloc[train_len:])\n",
    "        ax[0].set_ylabel('Close')\n",
    "\n",
    "        ax[1].plot(df['Date'].iloc[train_len:],df_walk_forward['error'],color='tab:orange')\n",
    "        ax[1].set_title('Walk forward error through time')\n",
    "        ax[1].set_xlabel('Dates')\n",
    "        ax[1].legend()\n",
    "        ax[1].set_ylim([0,1])\n",
    "\n",
    "        max = df_walk_forward.shape[0]\n",
    "        ax[1].set_xticks([df_walk_forward['date'].iloc[x] for x in range(0,max,150)])\n",
    "        ax[1].tick_params(rotation=30)\n",
    "        ax[1].set_ylabel('Error')\n",
    "        ax[1].set_xlabel('Date')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_{model_name}_wf.png',facecolor='w')\n",
    "        plt.close()\n",
    "        \n",
    "    # place wf results into df, save to csv and latex table\n",
    "    df_conclusion_wf = pd.DataFrame.from_records(model_results)\n",
    "    df_conclusion_wf.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_wf.csv')\n",
    "    \n",
    "    df_conclusion_wf_inverted = pd.DataFrame.from_records(inverted_results)\n",
    "    df_conclusion_wf_inverted.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_inverted_wf.csv')\n",
    "    \n",
    "    \n",
    "    latex_table = tabulate(df_conclusion_wf, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    latex_table = tabulate(df_conclusion_wf_inverted, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_inverted_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    # plot wf prediction results through time\n",
    "    for model in model_pred_results.keys():\n",
    "        model_pred_results[model] = model_pred_results[model].astype(float)\n",
    "\n",
    "    model_pred_results['Date'] = df['Date'].iloc[train_len:]\n",
    "    df_wf_results = pd.DataFrame.from_dict(model_pred_results)\n",
    "    ax = df_wf_results.plot(figsize=(10,4), x='Date',fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(labelsize=12,rotation=30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_wf_results_inverted.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wavelet methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_assets = ['CrudeOil','S&P500','Apple','EurUsd'] # AirPassengers',\n",
    "feat_engineering = 'wavelet'\n",
    "column_to_predict = 'Close' #'#Passengers' \n",
    "\n",
    "\n",
    "for financial_asset in financial_assets:\n",
    "    ###################################################################################################\n",
    "    # import some data\n",
    "    ###################################################################################################\n",
    "\n",
    "    df = pd.read_csv(f'./test_data/{financial_asset}_yfinance.csv') # sp_500 = GSPC.csv, # airplaine = AirPassengers.csv\n",
    "    df = df.iloc[-2000:,:].reset_index(drop=True) # only look at last 2000 days\n",
    "    # df['Date'] = df['Month']\n",
    "    df.plot(x='Date',y=f'{column_to_predict}',figsize=(10,5),legend=True,xlabel='Month',subplots=True)\n",
    "    plt.tight_layout()\n",
    "    display(df)\n",
    "\n",
    "    # some forecasting parameters\n",
    "    window_length = 10\n",
    "    split = 500 # 44 for AirPlane\n",
    "\n",
    "    ###################################################################################################\n",
    "    # feature engineering\n",
    "    ###################################################################################################\n",
    "\n",
    "    # fft the testing data\n",
    "    signal = np.array(df[f'{column_to_predict}'][-2000:-split]) # data\n",
    "    denoised_signal = automatic_wavelet_denoising(signal,df, split,\n",
    "                                                    verbose=True,\n",
    "                                                    wavelet='sym8',\n",
    "                                                    threshold_override=False, \n",
    "                                                    threshold=0.4)\n",
    "\n",
    "    ###################################################################################################\n",
    "    # single out of sample validation results\n",
    "    ###################################################################################################\n",
    "\n",
    "    # input data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_training_data = scaler.fit_transform(denoised_signal.reshape(-1, 1)).flatten()\n",
    "    scaled_test_data = scaler.transform(df[f'{column_to_predict}'][-split:].to_numpy().reshape(-1,1)).flatten()\n",
    "    scaled_input_data = np.append(scaled_training_data,scaled_test_data)\n",
    "\n",
    "    # initialize class object\n",
    "    blah = time_series_prediction(financial_asset,feat_engineering,df['Date'],scaled_input_data,window_length,1)#time_series_prediction(sp_500['Date'][-4000:],sp_500['Volume'][-4000:]/1e9,5,1) # pass: ime series dates, univariate time series, lag window length, a number of steps ahead to predict\n",
    "    blah.sliding_window_1(verbose=0) # time series to supervised ML problem\n",
    "    blah.train_test_split(split=split) # testing and training dataset split\n",
    "    blah.test_train_plot(ylabel='Close price')    # visualize training split\n",
    "\n",
    "    # perform some prediction tasks\n",
    "    blah.linear_regression()\n",
    "    blah.support_vector_machine(model_tunning=True,C= 0.1, kernel= 'linear',epsilon=0.1)\n",
    "    blah.neural_net_mlp(model_tunning=True,\n",
    "                        activation= 'relu', \n",
    "                        hidden_layer_sizes= (100, 100, 100), \n",
    "                        learning_rate= 'invscaling', \n",
    "                        learning_rate_init= 0.001,\n",
    "                        solver='adam')\n",
    "    blah.lstm(model_tunning=True,n_batch=64)\n",
    "    blah.naive_model()\n",
    "\n",
    "    # tabulate results nicely\n",
    "    blah.collect_results()\n",
    "\n",
    "    # visualize results\n",
    "    blah.vis_results_time_series(ylabel='Close price',second_plot='error')\n",
    "\n",
    "    # view final results\n",
    "    blah.conclusion()\n",
    "\n",
    "    ###################################################################################################\n",
    "    # invert feature engineering (if possible)\n",
    "    ###################################################################################################\n",
    "\n",
    "    # invert scaling\n",
    "    inverted_predictions_linear, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.linear_reg_predictions)\n",
    "    inverted_predictions_svm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.svm_predictions)\n",
    "    inverted_predictions_nn, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.neural_net_predictions)\n",
    "    inverted_predictions_lstm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.lstm_predictions)\n",
    "\n",
    "    # collect inverted results\n",
    "\n",
    "    df_inverted_results = pd.DataFrame(columns=['Date','Value','Linear','SVM','NN','LSTM'])\n",
    "    df_inverted_results['Date'] = df['Date']\n",
    "    df_inverted_results['Value'] = df[f'{column_to_predict}']\n",
    "    df_inverted_results['Linear'].iloc[-split:] = inverted_predictions_linear.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['SVM'].iloc[-split:] = inverted_predictions_svm.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['NN'].iloc[-split:] =  inverted_predictions_nn.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['LSTM'].iloc[-split:] = inverted_predictions_lstm.flatten()#['invert_pred_value'].astype(float)\n",
    "\n",
    "    # plot invert results\n",
    "    ax = df_inverted_results.plot(figsize=(10,4), x='Date', fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(rotation=30, labelsize=12)    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_inverted.png')\n",
    "\n",
    "    # store results\n",
    "    inverted_conclusion(dates=df['Date'].iloc[-split:],\n",
    "                        original_values=df[f'{column_to_predict}'].iloc[-split:], \n",
    "                        linear_preds=inverted_predictions_linear, \n",
    "                        svm_pred=inverted_predictions_svm, \n",
    "                        nn_preds=inverted_predictions_nn, \n",
    "                        lstm_preds=inverted_predictions_lstm,\n",
    "                        financial_asset=financial_asset,\n",
    "                        feat_engineer=feat_engineering)\n",
    "\n",
    "    ###################################################################################################\n",
    "    # walk forward validation results\n",
    "    ###################################################################################################\n",
    "    mapping = {'LinearReg':blah.linear_regression_model,\n",
    "                'svr':blah.svr_model,\n",
    "                'MLP':blah.mlp_model,\n",
    "                'LSTM':blah.lstm_model\n",
    "                }\n",
    "\n",
    "    # store evaulation results for different models\n",
    "    model_results = []\n",
    "    inverted_results = []\n",
    "    model_pred_results = {'Original Values':None,\n",
    "                'LinearReg':None,\n",
    "                'svr':None,\n",
    "                'MLP':None,\n",
    "                'LSTM':None,\n",
    "                }\n",
    "\n",
    "    # unfeature engineered data for walkforward\n",
    "    walk_forward_input = scaler.transform(df[f'{column_to_predict}'][-2000:].to_numpy().reshape(-1,1)).flatten()\n",
    "\n",
    "    # apply walkforward for all models\n",
    "    for model_name in mapping.keys():\n",
    "\n",
    "        # retrieve model\n",
    "        model = mapping[model_name]\n",
    "\n",
    "        # apply walk forward and save results\n",
    "        train_len = 225 # 48 for Airplane\n",
    "        test_len = 25   # 12 for Airplane\n",
    "        df_walk_forward, df_hit_rate, mse,mae,mape,accuracy = walk_forward_val(model_name,model,\n",
    "                                                                                    original_series = walk_forward_input,\n",
    "                                                                                    time_series_dates = df['Date'].iloc[-2000:],\n",
    "                                                                                    lag_window_length=window_length,\n",
    "                                                                                    train_len=train_len,\n",
    "                                                                                    test_len=test_len,\n",
    "                                                                                    train_frequency=10,\n",
    "                                                                                    transformer=automatic_wavelet_denoising_wf,\n",
    "                                                                                    only_training=True,\n",
    "                                                                                    verbose=False,\n",
    "                                                                                    wavelet='sym8',\n",
    "                                                                                    threshold_override=False)\n",
    "        # wrangle results\n",
    "\n",
    "        # tables \n",
    "        model_results.append({'model':model_name,'mse':mse,'mae':mae,'mape':mape,'accuracy':accuracy})\n",
    "\n",
    "        # invert results for different models\n",
    "\n",
    "        # invert scaling\n",
    "        inverted_predictions, inverted_testing_data = invert_scaling(scaler,scaled_input_data[train_len:],df_walk_forward['prediction'].to_numpy())\n",
    "\n",
    "        invert_mse = np.sqrt(mean_squared_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions))\n",
    "        invert_mae = mean_absolute_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions)\n",
    "        invert_mape = mean_absolute_percentage_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions)\n",
    "        df_hit_rate, invert_accuracy = hit_rate(dates=df['Date'].iloc[train_len:],\n",
    "                                        original_values=df[f'{column_to_predict}'].iloc[train_len:],\n",
    "                                        predictions=inverted_predictions)\n",
    "\n",
    "        inverted_results.append({'model':model_name,'mse':invert_mse,'mae':invert_mae,'mape':invert_mape,'accuracy':invert_accuracy})\n",
    "\n",
    "\n",
    "        # save prediction so we can view inverted walk forward results too\n",
    "        model_pred_results['Original Values'] = df[f'{column_to_predict}'].iloc[train_len:]\n",
    "        model_pred_results[model_name] = inverted_predictions.flatten()\n",
    "\n",
    "        # plots\n",
    "        df_walk_forward['error'] = abs((df_walk_forward['real_value'] - df_walk_forward['prediction']) / df_walk_forward['real_value'])\n",
    "        \n",
    "        fig, ax = plt.subplots(2,1, figsize=(10,8),sharex=True)\n",
    "        ax[0].plot(df['Date'].iloc[train_len:],df[f'{column_to_predict}'].iloc[train_len:])\n",
    "        ax[0].set_ylabel('Close')\n",
    "\n",
    "        ax[1].plot(df['Date'].iloc[train_len:],df_walk_forward['error'],color='tab:orange')\n",
    "        ax[1].set_title('Walk forward error through time')\n",
    "        ax[1].set_xlabel('Dates')\n",
    "        ax[1].legend()\n",
    "        ax[1].set_ylim([0,1])\n",
    "\n",
    "        max = df_walk_forward.shape[0]\n",
    "        ax[1].set_xticks([df_walk_forward['date'].iloc[x] for x in range(0,max,150)])\n",
    "        ax[1].tick_params(rotation=30)\n",
    "        ax[1].set_ylabel('Error')\n",
    "        ax[1].set_xlabel('Date')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_{model_name}_wf.png',facecolor='w')\n",
    "        plt.close()\n",
    "        \n",
    "    # place wf results into df, save to csv and latex table\n",
    "    df_conclusion_wf = pd.DataFrame.from_records(model_results)\n",
    "    df_conclusion_wf.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_wf.csv')\n",
    "    \n",
    "    df_conclusion_wf_inverted = pd.DataFrame.from_records(inverted_results)\n",
    "    df_conclusion_wf_inverted.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_inverted_wf.csv')\n",
    "    \n",
    "    \n",
    "    latex_table = tabulate(df_conclusion_wf, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    latex_table = tabulate(df_conclusion_wf_inverted, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_inverted_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    # plot wf prediction results through time\n",
    "    for model in model_pred_results.keys():\n",
    "        model_pred_results[model] = model_pred_results[model].astype(float)\n",
    "\n",
    "    model_pred_results['Date'] = df['Date'].iloc[train_len:]\n",
    "    df_wf_results = pd.DataFrame.from_dict(model_pred_results)\n",
    "    ax = df_wf_results.plot(figsize=(10,4), x='Date',fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(labelsize=12,rotation=30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_wf_results_inverted.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Moving averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving average function for feature engineering during walk forward validation\n",
    "def moving_average_wf(signal,moving_average):\n",
    "    # numpy array to pandas series\n",
    "    series = pd.Series(signal)\n",
    "\n",
    "    # smoothen\n",
    "    series_smooth = series.rolling(moving_average,min_periods=1).mean().to_numpy()\n",
    "\n",
    "    return series_smooth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "financial_assets = ['CrudeOil','S&P500','Apple','EurUsd'] # AirPassengers',\n",
    "feat_engineering = 'moving_average_10'\n",
    "column_to_predict = 'Close' #'#Passengers' \n",
    "\n",
    "\n",
    "for financial_asset in financial_assets:\n",
    "    ###################################################################################################\n",
    "    # import some data\n",
    "    ###################################################################################################\n",
    "\n",
    "    df = pd.read_csv(f'./test_data/{financial_asset}_yfinance.csv') # sp_500 = GSPC.csv, # airplaine = AirPassengers.csv\n",
    "    df = df.iloc[-2000:,:].reset_index(drop=True) # only look at last 2000 days\n",
    "    # df['Date'] = df['Month']\n",
    "    df.plot(x='Date',y=f'{column_to_predict}',figsize=(10,5),legend=True,xlabel='Month',subplots=True)\n",
    "    plt.tight_layout()\n",
    "    display(df)\n",
    "\n",
    "    # some forecasting parameters\n",
    "    window_length = 10\n",
    "    split = 500 # 44 for AirPlane\n",
    "\n",
    "    ###################################################################################################\n",
    "    # feature engineering\n",
    "    ###################################################################################################\n",
    "\n",
    "    # smoothen data\n",
    "    moving_average = 10\n",
    "    signal = copy.deepcopy(df[f'{column_to_predict}'][-2000:-split]) # data\n",
    "    denoised_signal = signal.rolling(moving_average,min_periods=1).mean().to_numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.plot(df['Date'][:-split], df[f'{column_to_predict}'][:-split],label='Raw signal')\n",
    "    ax.plot(df['Date'][:-split], denoised_signal,label=f\"MA_{moving_average}\")\n",
    "    max = df.iloc[:-split,:].shape[0]\n",
    "    relevant_dates = df['Date'][:-split]\n",
    "    ax.set_xticks([relevant_dates.iloc[x] for x in range(0,max,150)])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    display(df)\n",
    "\n",
    "    ###################################################################################################\n",
    "    # single out of sample validation results\n",
    "    ###################################################################################################\n",
    "\n",
    "    # input data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_training_data = scaler.fit_transform(denoised_signal.reshape(-1, 1)).flatten()\n",
    "    scaled_test_data = scaler.transform(df[f'{column_to_predict}'][-split:].to_numpy().reshape(-1,1)).flatten()\n",
    "    scaled_input_data = np.append(scaled_training_data,scaled_test_data)\n",
    "\n",
    "    # initialize class object\n",
    "    blah = time_series_prediction(financial_asset,feat_engineering,df['Date'],scaled_input_data,window_length,1)#time_series_prediction(sp_500['Date'][-4000:],sp_500['Volume'][-4000:]/1e9,5,1) # pass: ime series dates, univariate time series, lag window length, a number of steps ahead to predict\n",
    "    blah.sliding_window_1(verbose=0) # time series to supervised ML problem\n",
    "    blah.train_test_split(split=split) # testing and training dataset split\n",
    "    blah.test_train_plot(ylabel='Close price')    # visualize training split\n",
    "\n",
    "    # perform some prediction tasks\n",
    "    blah.linear_regression()\n",
    "    blah.support_vector_machine(model_tunning=True,C= 0.1, kernel= 'linear',epsilon=0.1)\n",
    "    blah.neural_net_mlp(model_tunning=True,\n",
    "                        activation= 'relu', \n",
    "                        hidden_layer_sizes= (100, 100, 100), \n",
    "                        learning_rate= 'invscaling', \n",
    "                        learning_rate_init= 0.001,\n",
    "                        solver='adam')\n",
    "    blah.lstm(model_tunning=True,n_batch=64)\n",
    "    blah.naive_model()\n",
    "\n",
    "    # tabulate results nicely\n",
    "    blah.collect_results()\n",
    "\n",
    "    # visualize results\n",
    "    blah.vis_results_time_series(ylabel='Close price',second_plot='error')\n",
    "\n",
    "    # view final results\n",
    "    blah.conclusion()\n",
    "\n",
    "    ###################################################################################################\n",
    "    # invert feature engineering (if possible)\n",
    "    ###################################################################################################\n",
    "\n",
    "    # invert scaling\n",
    "    inverted_predictions_linear, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.linear_reg_predictions)\n",
    "    inverted_predictions_svm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.svm_predictions)\n",
    "    inverted_predictions_nn, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.neural_net_predictions)\n",
    "    inverted_predictions_lstm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.lstm_predictions)\n",
    "\n",
    "    # collect inverted results\n",
    "\n",
    "    df_inverted_results = pd.DataFrame(columns=['Date','Value','Linear','SVM','NN','LSTM'])\n",
    "    df_inverted_results['Date'] = df['Date']\n",
    "    df_inverted_results['Value'] = df[f'{column_to_predict}']\n",
    "    df_inverted_results['Linear'].iloc[-split:] = inverted_predictions_linear.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['SVM'].iloc[-split:] = inverted_predictions_svm.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['NN'].iloc[-split:] =  inverted_predictions_nn.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['LSTM'].iloc[-split:] = inverted_predictions_lstm.flatten()#['invert_pred_value'].astype(float)\n",
    "\n",
    "    # plot invert results\n",
    "    ax = df_inverted_results.plot(figsize=(10,4), x='Date', fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(rotation=30, labelsize=12)    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_inverted.png')\n",
    "\n",
    "    # store results\n",
    "    inverted_conclusion(dates=df['Date'].iloc[-split:],\n",
    "                        original_values=df[f'{column_to_predict}'].iloc[-split:], \n",
    "                        linear_preds=inverted_predictions_linear, \n",
    "                        svm_pred=inverted_predictions_svm, \n",
    "                        nn_preds=inverted_predictions_nn, \n",
    "                        lstm_preds=inverted_predictions_lstm,\n",
    "                        financial_asset=financial_asset,\n",
    "                        feat_engineer=feat_engineering)\n",
    "\n",
    "    ###################################################################################################\n",
    "    # walk forward validation results\n",
    "    ###################################################################################################\n",
    "    mapping = {'LinearReg':blah.linear_regression_model,\n",
    "                'svr':blah.svr_model,\n",
    "                'MLP':blah.mlp_model,\n",
    "                'LSTM':blah.lstm_model\n",
    "                }\n",
    "\n",
    "    # store evaulation results for different models\n",
    "    model_results = []\n",
    "    inverted_results = []\n",
    "    model_pred_results = {'Original Values':None,\n",
    "                'LinearReg':None,\n",
    "                'svr':None,\n",
    "                'MLP':None,\n",
    "                'LSTM':None,\n",
    "                }\n",
    "\n",
    "    # unfeature engineered data for walkforward\n",
    "    walk_forward_input = scaler.transform(df[f'{column_to_predict}'][-2000:].to_numpy().reshape(-1,1)).flatten()\n",
    "\n",
    "    # apply walkforward for all models\n",
    "    for model_name in mapping.keys():\n",
    "\n",
    "        # retrieve model\n",
    "        model = mapping[model_name]\n",
    "\n",
    "        # apply walk forward and save results\n",
    "        train_len = 225 # 48 for Airplane\n",
    "        test_len = 25   # 12 for Airplane\n",
    "        df_walk_forward, df_hit_rate, mse,mae,mape,accuracy = walk_forward_val(model_name,\n",
    "                                                                            model=model,\n",
    "                                                                            original_series = walk_forward_input,\n",
    "                                                                            time_series_dates = df[f'Date'].iloc[-2000:],\n",
    "                                                                            lag_window_length= 10,\n",
    "                                                                            train_len=225,\n",
    "                                                                            test_len=25,\n",
    "                                                                            train_frequency=10,\n",
    "                                                                            transformer=moving_average_wf,\n",
    "                                                                            only_training=True,\n",
    "                                                                            moving_average=moving_average,\n",
    "                                                                            )\n",
    "        # wrangle results\n",
    "\n",
    "        # tables \n",
    "        model_results.append({'model':model_name,'mse':mse,'mae':mae,'mape':mape,'accuracy':accuracy})\n",
    "\n",
    "        # invert results for different models\n",
    "\n",
    "        # invert scaling\n",
    "        inverted_predictions, inverted_testing_data = invert_scaling(scaler,scaled_input_data[train_len:],df_walk_forward['prediction'].to_numpy())\n",
    "\n",
    "        invert_mse = np.sqrt(mean_squared_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions))\n",
    "        invert_mae = mean_absolute_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions)\n",
    "        invert_mape = mean_absolute_percentage_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions)\n",
    "        df_hit_rate, invert_accuracy = hit_rate(dates=df['Date'].iloc[train_len:],\n",
    "                                        original_values=df[f'{column_to_predict}'].iloc[train_len:],\n",
    "                                        predictions=inverted_predictions)\n",
    "\n",
    "        inverted_results.append({'model':model_name,'mse':invert_mse,'mae':invert_mae,'mape':invert_mape,'accuracy':invert_accuracy})\n",
    "\n",
    "\n",
    "        # save prediction so we can view inverted walk forward results too\n",
    "        model_pred_results['Original Values'] = df[f'{column_to_predict}'].iloc[train_len:]\n",
    "        model_pred_results[model_name] = inverted_predictions.flatten()\n",
    "\n",
    "        # plots\n",
    "        df_walk_forward['error'] = abs((df_walk_forward['real_value'] - df_walk_forward['prediction']) / df_walk_forward['real_value'])\n",
    "        \n",
    "        fig, ax = plt.subplots(2,1, figsize=(10,8),sharex=True)\n",
    "        ax[0].plot(df['Date'].iloc[train_len:],df[f'{column_to_predict}'].iloc[train_len:])\n",
    "        ax[0].set_ylabel('Close')\n",
    "\n",
    "        ax[1].plot(df['Date'].iloc[train_len:],df_walk_forward['error'],color='tab:orange')\n",
    "        ax[1].set_title('Walk forward error through time')\n",
    "        ax[1].set_xlabel('Dates')\n",
    "        ax[1].legend()\n",
    "        ax[1].set_ylim([0,1])\n",
    "\n",
    "        max = df_walk_forward.shape[0]\n",
    "        ax[1].set_xticks([df_walk_forward['date'].iloc[x] for x in range(0,max,150)])\n",
    "        ax[1].tick_params(rotation=30)\n",
    "        ax[1].set_ylabel('Error')\n",
    "        ax[1].set_xlabel('Date')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_{model_name}_wf.png',facecolor='w')\n",
    "        plt.close()\n",
    "        \n",
    "    # place wf results into df, save to csv and latex table\n",
    "    df_conclusion_wf = pd.DataFrame.from_records(model_results)\n",
    "    df_conclusion_wf.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_wf.csv')\n",
    "    \n",
    "    df_conclusion_wf_inverted = pd.DataFrame.from_records(inverted_results)\n",
    "    df_conclusion_wf_inverted.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_inverted_wf.csv')\n",
    "    \n",
    "    \n",
    "    latex_table = tabulate(df_conclusion_wf, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    latex_table = tabulate(df_conclusion_wf_inverted, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_inverted_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    # plot wf prediction results through time\n",
    "    for model in model_pred_results.keys():\n",
    "        model_pred_results[model] = model_pred_results[model].astype(float)\n",
    "\n",
    "    model_pred_results['Date'] = df['Date'].iloc[train_len:]\n",
    "    df_wf_results = pd.DataFrame.from_dict(model_pred_results)\n",
    "    ax = df_wf_results.plot(figsize=(10,4), x='Date',fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(labelsize=12,rotation=30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_wf_results_inverted.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exponentially weighted moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving average function for feature engineering during walk forward validation\n",
    "def ewma_wf(signal,alpha):\n",
    "    # numpy array to pandas series\n",
    "    series = pd.Series(signal)\n",
    "\n",
    "    # smoothen\n",
    "    series_smooth = series.ewm(alpha=alpha).mean().to_numpy()\n",
    "\n",
    "    return series_smooth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_asset = ['CrudeOil','S&P500','Apple','EurUsd'] # AirPassengers',\n",
    "feat_engineering = 'ewma_0.5'\n",
    "column_to_predict = 'Close' #'#Passengers' \n",
    "\n",
    "for financial_asset in financial_assets:\n",
    "    ###################################################################################################\n",
    "    # import some data\n",
    "    ###################################################################################################\n",
    "\n",
    "    df = pd.read_csv(f'./test_data/{financial_asset}_yfinance.csv') # sp_500 = GSPC.csv, # airplaine = AirPassengers.csv\n",
    "    df = df.iloc[-2000:,:].reset_index(drop=True) # only look at last 2000 days\n",
    "    # df['Date'] = df['Month']\n",
    "    df.plot(x='Date',y=f'{column_to_predict}',figsize=(10,5),legend=True,xlabel='Month',subplots=True)\n",
    "    plt.tight_layout()\n",
    "    display(df)\n",
    "\n",
    "    # some forecasting parameters\n",
    "    window_length = 10\n",
    "    split = 500 # 44 for AirPlane\n",
    "\n",
    "    ###################################################################################################\n",
    "    # feature engineering\n",
    "    ###################################################################################################\n",
    "\n",
    "    # smoothen data\n",
    "    alpha = 0.5 # smoothing parameter\n",
    "    signal = df[f'{column_to_predict}'][-2000:-split] # data\n",
    "    denoised_signal = signal.ewm(alpha=alpha).mean().to_numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax.plot(df['Date'][:-split], df[f'{column_to_predict}'][:-split],label='Raw signal')\n",
    "    ax.plot(df['Date'][:-split], denoised_signal,label=f\"EWMA_{alpha}\")\n",
    "    max = df.iloc[:-split,:].shape[0]\n",
    "    relevant_dates = df['Date'][:-split]\n",
    "    ax.set_xticks([relevant_dates.iloc[x] for x in range(0,max,150)])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    display(df)\n",
    "\n",
    "    ###################################################################################################\n",
    "    # single out of sample validation results\n",
    "    ###################################################################################################\n",
    "\n",
    "    # input data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_training_data = scaler.fit_transform(denoised_signal.reshape(-1, 1)).flatten()\n",
    "    scaled_test_data = scaler.transform(df[f'{column_to_predict}'][-split:].to_numpy().reshape(-1,1)).flatten()\n",
    "    scaled_input_data = np.append(scaled_training_data,scaled_test_data)\n",
    "\n",
    "    # initialize class object\n",
    "    blah = time_series_prediction(financial_asset,feat_engineering,df['Date'],scaled_input_data,window_length,1)#time_series_prediction(sp_500['Date'][-4000:],sp_500['Volume'][-4000:]/1e9,5,1) # pass: ime series dates, univariate time series, lag window length, a number of steps ahead to predict\n",
    "    blah.sliding_window_1(verbose=0) # time series to supervised ML problem\n",
    "    blah.train_test_split(split=split) # testing and training dataset split\n",
    "    blah.test_train_plot(ylabel='Close price')    # visualize training split\n",
    "\n",
    "    # perform some prediction tasks\n",
    "    blah.linear_regression()\n",
    "    blah.support_vector_machine(model_tunning=True,C= 0.1, kernel= 'linear',epsilon=0.1)\n",
    "    blah.neural_net_mlp(model_tunning=True,\n",
    "                        activation= 'relu', \n",
    "                        hidden_layer_sizes= (100, 100, 100), \n",
    "                        learning_rate= 'invscaling', \n",
    "                        learning_rate_init= 0.001,\n",
    "                        solver='adam')\n",
    "    blah.lstm(model_tunning=True,n_batch=64)\n",
    "    blah.naive_model()\n",
    "\n",
    "    # tabulate results nicely\n",
    "    blah.collect_results()\n",
    "\n",
    "    # visualize results\n",
    "    blah.vis_results_time_series(ylabel='Close price',second_plot='error')\n",
    "\n",
    "    # view final results\n",
    "    blah.conclusion()\n",
    "\n",
    "    ###################################################################################################\n",
    "    # invert feature engineering (if possible)\n",
    "    ###################################################################################################\n",
    "\n",
    "    # invert scaling\n",
    "    inverted_predictions_linear, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.linear_reg_predictions)\n",
    "    inverted_predictions_svm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.svm_predictions)\n",
    "    inverted_predictions_nn, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.neural_net_predictions)\n",
    "    inverted_predictions_lstm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.lstm_predictions)\n",
    "\n",
    "    # collect inverted results\n",
    "\n",
    "    df_inverted_results = pd.DataFrame(columns=['Date','Value','Linear','SVM','NN','LSTM'])\n",
    "    df_inverted_results['Date'] = df['Date']\n",
    "    df_inverted_results['Value'] = df[f'{column_to_predict}']\n",
    "    df_inverted_results['Linear'].iloc[-split:] = inverted_predictions_linear.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['SVM'].iloc[-split:] = inverted_predictions_svm.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['NN'].iloc[-split:] =  inverted_predictions_nn.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['LSTM'].iloc[-split:] = inverted_predictions_lstm.flatten()#['invert_pred_value'].astype(float)\n",
    "\n",
    "    # plot invert results\n",
    "    ax = df_inverted_results.plot(figsize=(10,4), x='Date', fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(rotation=30, labelsize=12)    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_inverted.png')\n",
    "\n",
    "    # store results\n",
    "    inverted_conclusion(dates=df['Date'].iloc[-split:],\n",
    "                        original_values=df[f'{column_to_predict}'].iloc[-split:], \n",
    "                        linear_preds=inverted_predictions_linear, \n",
    "                        svm_pred=inverted_predictions_svm, \n",
    "                        nn_preds=inverted_predictions_nn, \n",
    "                        lstm_preds=inverted_predictions_lstm,\n",
    "                        financial_asset=financial_asset,\n",
    "                        feat_engineer=feat_engineering)\n",
    "\n",
    "    ###################################################################################################\n",
    "    # walk forward validation results\n",
    "    ###################################################################################################\n",
    "    mapping = {'LinearReg':blah.linear_regression_model,\n",
    "                'svr':blah.svr_model,\n",
    "                'MLP':blah.mlp_model,\n",
    "                'LSTM':blah.lstm_model\n",
    "                }\n",
    "\n",
    "    # store evaulation results for different models\n",
    "    model_results = []\n",
    "    inverted_results = []\n",
    "    model_pred_results = {'Original Values':None,\n",
    "                'LinearReg':None,\n",
    "                'svr':None,\n",
    "                'MLP':None,\n",
    "                'LSTM':None,\n",
    "                }\n",
    "\n",
    "    # unfeature engineered data for walkforward\n",
    "    walk_forward_input = scaler.transform(df[f'{column_to_predict}'][-2000:].to_numpy().reshape(-1,1)).flatten()\n",
    "\n",
    "    # apply walkforward for all models\n",
    "    for model_name in mapping.keys():\n",
    "\n",
    "        # retrieve model\n",
    "        model = mapping[model_name]\n",
    "\n",
    "        # apply walk forward and save results\n",
    "        train_len = 225 # 48 for Airplane\n",
    "        test_len = 25   # 12 for Airplane\n",
    "        df_walk_forward, df_hit_rate, mse,mae,mape,accuracy = walk_forward_val(model_name,\n",
    "                                                                            model=model,\n",
    "                                                                            original_series = walk_forward_input,\n",
    "                                                                            time_series_dates = df[f'Date'].iloc[-2000:],\n",
    "                                                                            lag_window_length= 10,\n",
    "                                                                            train_len=225,\n",
    "                                                                            test_len=25,\n",
    "                                                                            train_frequency=10,\n",
    "                                                                            transformer=ewma_wf,\n",
    "                                                                            only_training=True,\n",
    "                                                                            alpha = alpha,\n",
    "                                                                            )\n",
    "        # wrangle results\n",
    "\n",
    "        # tables \n",
    "        model_results.append({'model':model_name,'mse':mse,'mae':mae,'mape':mape,'accuracy':accuracy})\n",
    "\n",
    "        # invert results for different models\n",
    "\n",
    "        # invert scaling\n",
    "        inverted_predictions, inverted_testing_data = invert_scaling(scaler,scaled_input_data[train_len:],df_walk_forward['prediction'].to_numpy())\n",
    "\n",
    "        invert_mse = np.sqrt(mean_squared_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions))\n",
    "        invert_mae = mean_absolute_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions)\n",
    "        invert_mape = mean_absolute_percentage_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions)\n",
    "        df_hit_rate, invert_accuracy = hit_rate(dates=df['Date'].iloc[train_len:],\n",
    "                                        original_values=df[f'{column_to_predict}'].iloc[train_len:],\n",
    "                                        predictions=inverted_predictions)\n",
    "\n",
    "        inverted_results.append({'model':model_name,'mse':invert_mse,'mae':invert_mae,'mape':invert_mape,'accuracy':invert_accuracy})\n",
    "\n",
    "\n",
    "        # save prediction so we can view inverted walk forward results too\n",
    "        model_pred_results['Original Values'] = df[f'{column_to_predict}'].iloc[train_len:]\n",
    "        model_pred_results[model_name] = inverted_predictions.flatten()\n",
    "\n",
    "        # plots\n",
    "        df_walk_forward['error'] = abs((df_walk_forward['real_value'] - df_walk_forward['prediction']) / df_walk_forward['real_value'])\n",
    "        \n",
    "        fig, ax = plt.subplots(2,1, figsize=(10,8),sharex=True)\n",
    "        ax[0].plot(df['Date'].iloc[train_len:],df[f'{column_to_predict}'].iloc[train_len:])\n",
    "        ax[0].set_ylabel('Close')\n",
    "\n",
    "        ax[1].plot(df['Date'].iloc[train_len:],df_walk_forward['error'],color='tab:orange')\n",
    "        ax[1].set_title('Walk forward error through time')\n",
    "        ax[1].set_xlabel('Dates')\n",
    "        ax[1].legend()\n",
    "        ax[1].set_ylim([0,1])\n",
    "\n",
    "        max = df_walk_forward.shape[0]\n",
    "        ax[1].set_xticks([df_walk_forward['date'].iloc[x] for x in range(0,max,150)])\n",
    "        ax[1].tick_params(rotation=30)\n",
    "        ax[1].set_ylabel('Error')\n",
    "        ax[1].set_xlabel('Date')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_{model_name}_wf.png',facecolor='w')\n",
    "        plt.close()\n",
    "        \n",
    "    # place wf results into df, save to csv and latex table\n",
    "    df_conclusion_wf = pd.DataFrame.from_records(model_results)\n",
    "    df_conclusion_wf.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_wf.csv')\n",
    "    \n",
    "    df_conclusion_wf_inverted = pd.DataFrame.from_records(inverted_results)\n",
    "    df_conclusion_wf_inverted.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_inverted_wf.csv')\n",
    "    \n",
    "    \n",
    "    latex_table = tabulate(df_conclusion_wf, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    latex_table = tabulate(df_conclusion_wf_inverted, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_inverted_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    # plot wf prediction results through time\n",
    "    for model in model_pred_results.keys():\n",
    "        model_pred_results[model] = model_pred_results[model].astype(float)\n",
    "\n",
    "    model_pred_results['Date'] = df['Date'].iloc[train_len:]\n",
    "    df_wf_results = pd.DataFrame.from_dict(model_pred_results)\n",
    "    ax = df_wf_results.plot(figsize=(10,4), x='Date',fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(labelsize=12,rotation=30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_wf_results_inverted.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08b5fb967e39b85ed312f435313aa6146aa74881f34f4caa25b9abbeb84a46f5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('meng-data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
