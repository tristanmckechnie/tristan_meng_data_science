{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e1d4880ad13fa2099fc93eba0cb791232af4f1a31a1c632661aaef6a29f2ead6",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Develop lstm model for time series prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class time_series_prediction():\n",
    "\n",
    "    def __init__(self,dates,one_d_time_series,lag_window_length,n_ahead_prediction):\n",
    "\n",
    "        # raw input data + settings for time series -> supervised learning ML problem\n",
    "        self.one_d_time_series = np.array(one_d_time_series)      # time series array, to array ensure index works as expected for class methods\n",
    "        self.time_series_dates = np.array(dates)                  # time stamp / date for each data point\n",
    "        self.lag_window_length = lag_window_length                # length of lag window\n",
    "        self.n_ahead_prediction = n_ahead_prediction              # time ahead to predict\n",
    "\n",
    "        # transfromed data: set after calling .sliding_window_1()\n",
    "        self.input_data = None\n",
    "        self.target_data = None\n",
    "\n",
    "        # testing and training data: set after calling .train_test_split()\n",
    "        self.training_split = None\n",
    "        self.X_test = None\n",
    "        self.X_train = None\n",
    "        self.y_test = None\n",
    "        self.y_train = None\n",
    "\n",
    "        # predictions from various models - set after calling each models training\n",
    "        self.linear_reg_predictions = None\n",
    "        self.svm_predictions = None\n",
    "        self.neural_net_predictions = None\n",
    "        self.naive_predictions = None\n",
    "\n",
    "        # cumprod results from predictions - set after calling .vis_results_time_series()\n",
    "        self.real_vals_cumprod = None\n",
    "        self.linear_reg_predictions_cumprod = None\n",
    "        self.svm_predictions_cumprod = None\n",
    "        self.neural_net_predictions_cumprod = None\n",
    "        self.lstm_predictions = None\n",
    "\n",
    "# ****************************************************************************************************************\n",
    "    # data wrangling\n",
    "# ****************************************************************************************************************\n",
    "\n",
    "    # method to transfroms 1-D time series to supervised ML problem: one step ahead forecasting   \n",
    "    def sliding_window_1(self,verbose):\n",
    "        # initialize input array\n",
    "        num_rows = len(self.one_d_time_series) - self.lag_window_length\n",
    "        array = np.zeros((num_rows, self.lag_window_length + 1))\n",
    "        \n",
    "        # loop through data and populate array\n",
    "        for i in range(num_rows):\n",
    "            # input features\n",
    "            array[i,0:self.lag_window_length+1] = self.one_d_time_series[i:i+self.lag_window_length+1]\n",
    "            # target feature/s\n",
    "            array[i,-1] = self.one_d_time_series[i+self.lag_window_length]\n",
    "            \n",
    "            if verbose == 1:\n",
    "                # show pattern\n",
    "                print(array[i,0:self.lag_window_length],' : ',array[i,self.lag_window_length])\n",
    "\n",
    "        # save results as a class attribute\n",
    "        self.input_data = array[:,0:self.lag_window_length]\n",
    "        self.target_data = array[:,self.lag_window_length]\n",
    "\n",
    "    # method to perform a training and testing split for dataset with only a single column of target variables\n",
    "    def train_test_split(self,split):\n",
    "        self.training_split = split\n",
    "        self.X_train = self.input_data[0:split,:]\n",
    "        self.X_test = self.input_data[split:,:]\n",
    "        self.y_train = self.target_data[0:split]\n",
    "        self.y_test = self.target_data[split:]\n",
    "\n",
    "    # method to plot testing and training split of data\n",
    "    def test_train_plot(self):\n",
    "        fig, ax = plt.subplots(figsize=(10,5))\n",
    "        ax.plot(self.time_series_dates[0:self.training_split] ,self.one_d_time_series[0:self.training_split],'k-',label='Training data') # replace returns with sp_500 for other data plotting\n",
    "        ax.plot(self.time_series_dates[self.training_split:] ,self.one_d_time_series[self.training_split:],'r-',label='Testing data')\n",
    "        ax.plot(self.time_series_dates[self.training_split+self.lag_window_length:] ,self.y_test,'o',label='Windowed testing data') # important to match time by start 5 (length of time window) after where segmented our testing and training data\n",
    "        plt.legend(loc=0) \n",
    "        ax.set_xticks([self.time_series_dates[x] for x in range(0,len(self.time_series_dates),150)])\n",
    "        ax.tick_params(rotation=30) \n",
    "        plt.tight_layout()\n",
    "\n",
    "# ****************************************************************************************************************\n",
    "    # predictive models\n",
    "# ****************************************************************************************************************\n",
    "\n",
    "    def linear_regression(self):\n",
    "        print('Training multivariate linear regression:')\n",
    "        # train model\n",
    "        reg_model = LinearRegression().fit(self.X_train,self.y_train)\n",
    "        print('\\nLinear regression coefficients: \\n',reg_model.coef_)\n",
    "\n",
    "        # test model\n",
    "        predictions = reg_model.predict(self.X_test)\n",
    "\n",
    "        # evaluate: use sklearn metric methods to calc rmse and mae\n",
    "        mse = mean_squared_error(self.y_test,predictions)\n",
    "        mae = mean_absolute_error(self.y_test,predictions)\n",
    "\n",
    "        print('RMSE: ',np.sqrt(mse))\n",
    "        print('MAE: ',mae)\n",
    "\n",
    "        # save predictions\n",
    "        self.linear_reg_predictions = predictions\n",
    "\n",
    "    def support_vector_machine(self):\n",
    "        print('\\nTraining support vector machine:')\n",
    "        # train model\n",
    "        svm_regres = LinearSVR(max_iter=1000,C=0.5).fit(self.X_train,self.y_train)\n",
    "\n",
    "        # predict\n",
    "        svm_predictions = svm_regres.predict(self.X_test)\n",
    "\n",
    "        # evaluate\n",
    "        mse = mean_squared_error(self.y_test,svm_predictions[:])\n",
    "        mae = mean_absolute_error(self.y_test,svm_predictions[:])\n",
    "\n",
    "        print('RMSE: ',np.sqrt(mse))\n",
    "        print('MAE: ',mae)\n",
    "\n",
    "        # save predictions\n",
    "        self.svm_predictions = svm_predictions\n",
    "\n",
    "    def neural_net_mlp(self,verbose=0):\n",
    "        print('\\nTraining neural network: ')\n",
    "        # train neural network\n",
    "        nn_regres = MLPRegressor(hidden_layer_sizes=(int(self.lag_window_length*2)),shuffle=False,random_state=1, \n",
    "                                max_iter=1000,verbose=verbose).fit(self.X_train,self.y_train)\n",
    "\n",
    "        # make predictions\n",
    "        nn_predictions = nn_regres.predict(self.X_test)\n",
    "\n",
    "        # evaluate\n",
    "        mse = mean_squared_error(self.y_test,nn_predictions[:])\n",
    "        mae = mean_absolute_error(self.y_test,nn_predictions[:])\n",
    "\n",
    "        print('RMSE: ',np.sqrt(mse))\n",
    "        print('MAE: ',mae)\n",
    "\n",
    "        # save predictions\n",
    "        self.neural_net_predictions = nn_predictions\n",
    "\n",
    "    def lstm(self):\n",
    "        print('\\nTraining LSTM: ')\n",
    "\n",
    "        # transform data\n",
    "        trainX = np.reshape(self.X_train, (self.X_train.shape[0], 1, self.X_train.shape[1]))\n",
    "        testX = np.reshape(self.X_test, (self.X_test.shape[0], 1, self.X_train.shape[1]))\n",
    "        trainY = normal.y_train\n",
    "        testY = normal.y_test\n",
    "\n",
    "        # create and fit the LSTM network\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(4, input_shape=(1, self.lag_window_length)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "        # make predictions\n",
    "        trainPredict = model.predict(trainX)\n",
    "        testPredict = model.predict(testX)\n",
    "\n",
    "        # calculate root mean squared error\n",
    "        trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "        print('Train Score: %.2f RMSE' % (trainScore))\n",
    "        testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "        print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "        # save predictions\n",
    "        self.lstm_predictions = testPredict\n",
    "\n",
    "    def naive_model(self): # t's prediction is t-1's value, note that this means you miss the first time point\n",
    "        preds = np.zeros(len(self.one_d_time_series)-1)\n",
    "        preds[0] = np.nan()\n",
    "        preds[1:] = self.one_d_time_series[0:-2]\n",
    "        self.naive_predictions = preds\n",
    "\n",
    "# ****************************************************************************************************************\n",
    "    # visualize results\n",
    "# ****************************************************************************************************************\n",
    "    def error(self,real_data,predicted_data):\n",
    "        error = np.zeros(len(real_data))\n",
    "        error = (real_data - predicted_data) / real_data\n",
    "        return error\n",
    "\n",
    "    # visualize orignal time series signal aswell as predictions    \n",
    "    def vis_results_time_series(self,second_plot='error'):\n",
    "        # plot prediction against actual + training data\n",
    "        fig, ax = plt.subplots(2,1,figsize=(10,7),sharex=True)\n",
    "\n",
    "        # original time series\n",
    "        ax[0].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.one_d_time_series[self.training_split+self.lag_window_length:],'o-',linewidth=3,label='real values',markersize=5) \n",
    "\n",
    "        # predicted y values\n",
    "        ax[0].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.linear_reg_predictions,'o-',label='linear regression prediction',markersize=5)\n",
    "        # ax[0].plot(self.time_series_dates,self.naive_predictions,'.--',label='naive prediction',markersize=5)\n",
    "        ax[0].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.svm_predictions,'.--',label='svm prediction',markersize=5)\n",
    "        ax[0].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.neural_net_predictions,'.--',label='nn prediction',markersize=5)\n",
    "        ax[0].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.lstm_predictions,'.--',label='lstm prediction',markersize=5)\n",
    "\n",
    "        ax[0].legend()\n",
    "        ax[0].set_title('Real values vs model predictions')\n",
    "\n",
    "        # plot error plot\n",
    "        if second_plot == 'error':\n",
    "            error_linreg = self.error(self.y_test,self.linear_reg_predictions)\n",
    "            # error_naive = error(np.array(test_data[:,-1]),naive_predictions)\n",
    "            error_svm = self.error(self.y_test,self.svm_predictions)\n",
    "            error_nn = self.error(self.y_test,self.neural_net_predictions)\n",
    "            error_lstm = self.error(self.y_test,self.lstm_predictions)\n",
    "\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],error_linreg,'r-',label='linear reg error')\n",
    "            # ax[1].plot(self.time_series_dates,error_naive[1:],'-',label='naive error')\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],error_svm,'-',label='svm error')\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],error_nn,'-',label='nn error')\n",
    "            # ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],error_lstm,'-',label='lstm error')\n",
    "\n",
    "            ax[1].set_title('Error signal for predictive models')\n",
    "            ax[1].set_xlabel('Dates')\n",
    "            ax[1].legend()\n",
    "            # ax[1].set_ylim([-10,10])\n",
    "            ax[1].set_xticks([self.time_series_dates[x] for x in range(self.training_split,len(self.time_series_dates),28)])\n",
    "            ax[1].tick_params(rotation=30)\n",
    "        \n",
    "        elif second_plot == 'cumprod':\n",
    "\n",
    "            # plot cummulative prod plots - this should only be done if input data is percentage retunrs\n",
    "            self.real_vals_cumprod = (self.y_test+1).cumprod()\n",
    "            self.linear_reg_predictions_cumprod = (self.linear_reg_predictions + 1).cumprod()\n",
    "            self.svm_predictions_cumprod = (self.svm_predictions + 1).cumprod()\n",
    "            self.neural_net_predictions_cumprod = (self.neural_net_predictions + 1).cumprod()\n",
    "\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.real_vals_cumprod,'-',label='real vals cumprod')\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.linear_reg_predictions_cumprod,'-',label='linear reg cumprod')\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.svm_predictions_cumprod,'-',label='svm cumprod')\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.neural_net_predictions_cumprod,'-',label='nn cumprod')\n",
    "\n",
    "            ax[1].set_xticks([self.time_series_dates[x] for x in range(self.training_split,len(self.time_series_dates),28)])\n",
    "            ax[1].tick_params(rotation=30)\n",
    "            ax[1].legend()\n",
    "\n",
    "        # titles and save figures\n",
    "        # title_string = 'S&P500 predictions _ y is '+str(column)+'_ window len is '+ str(window_length)\n",
    "        # fig.suptitle(title_string)\n",
    "        \n",
    "        # fig_name = '../results/univariate_single_step_ahead/'+title_string+'.png'\n",
    "        # plt.savefig(fig_name,facecolor='w')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # visualize predictions against real values using scatter plot\n",
    "    def vis_results_scatter(self):\n",
    "\n",
    "        # create dataframe to hold all results\n",
    "        df_predictions = pd.DataFrame(index=self.time_series_dates[self.training_split+self.lag_window_length:],columns=['Real_values','linear_reg_predictions','svm_predictions','neural_net_predictions'])\n",
    "        df_predictions['Real_values'] = self.y_test\n",
    "        df_predictions['linear_reg_predictions'] = self.linear_reg_predictions\n",
    "        df_predictions['svm_predictions'] = self.svm_predictions\n",
    "        df_predictions['neural_net_predictions'] = self.neural_net_predictions\n",
    "\n",
    "        # scatter plot with hues\n",
    "        fig, ax = plt.subplots(3,1,figsize=(7,10))\n",
    "        sns.scatterplot(y=df_predictions['Real_values'],x=df_predictions['linear_reg_predictions'],ax=ax[0])\n",
    "        sns.lineplot(x=self.y_test,y=self.y_test,ax=ax[0],color='red')\n",
    "\n",
    "        sns.scatterplot(y=df_predictions['Real_values'],x=df_predictions['svm_predictions'],ax=ax[1])\n",
    "        sns.lineplot(x=self.y_test,y=self.y_test,ax=ax[1],color='red')\n",
    "\n",
    "        sns.scatterplot(y=df_predictions['Real_values'],x=df_predictions['neural_net_predictions'],ax=ax[2])\n",
    "        sns.lineplot(x=self.y_test,y=self.y_test,ax=ax[2],color='red')\n",
    "\n",
    "        # plot formatting\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive figures\n",
    "%matplotlib widget \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# model evalution metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# predictive models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# keras stuff\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9293368b9cb4e6eb3b25e898b5fe66a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [-5.29974189e-03  1.09889909e-02  5.68325781e-03 -5.23024579e-03\n",
      "  1.35640174e-02 -2.06747888e-02 -4.12676867e-02  3.12380743e-02\n",
      " -2.38106442e-03 -1.80034275e-02  5.21215387e-02 -3.48359439e-02\n",
      " -3.21185713e-03 -1.62708396e-02 -2.11880631e-02 -3.17930890e-04\n",
      "  7.08400049e-02 -2.01885024e-02 -2.68193588e-02  1.73789668e-02\n",
      " -2.06058227e-02  1.78855098e-02 -2.22785404e-02  1.71610930e-02\n",
      "  3.05507286e-02 -6.40153945e-03  4.00164741e-03 -4.57306488e-02\n",
      "  2.99407068e-02 -5.06184533e-02  9.56161607e-03  9.41030292e-03\n",
      "  1.46674487e-02  2.96855518e-02 -5.68940970e-02  3.12164019e-02\n",
      "  3.05131670e-02  2.32076617e-02 -6.00486713e-02  5.72698483e-02\n",
      "  4.67667902e-02 -3.19916856e-02  1.46908312e-02 -3.54448562e-02\n",
      "  1.25181752e-02 -1.64904528e-02 -1.22431389e-03  1.28537001e-02\n",
      "  3.35283270e-02 -1.87108172e-02 -1.14772180e-02 -4.26150993e-02\n",
      " -2.54102922e-02  6.36050556e-02 -9.50645923e-03  1.09221566e-02\n",
      " -1.95125332e-02  3.51846181e-02  3.60349663e-03 -1.43792908e-02\n",
      "  2.26398068e-02  1.29495548e-02  7.64852112e-03 -1.21536216e-02\n",
      " -2.54047053e-02  1.25555386e-02 -3.89955769e-02 -2.51701451e-02\n",
      "  2.81953390e-02  7.40061554e-02 -7.23648212e-04 -4.39807542e-02\n",
      "  4.24467170e-02 -1.88279814e-02 -1.59747902e-02 -6.50270945e-03\n",
      " -3.68730774e-02  2.62605510e-02  3.87956712e-02 -2.22525051e-02\n",
      " -2.02812259e-02 -5.04556345e-02  2.71581682e-02 -1.17496799e-02\n",
      " -1.84435238e-02  1.23688943e-02  2.65064682e-02  1.89990995e-02\n",
      "  1.27193867e-02  2.79777378e-04  1.73945363e-02 -1.24859662e-04\n",
      "  4.21756919e-02 -2.23299766e-02 -1.94820432e-02  2.08990725e-02\n",
      " -2.48194510e-03  1.14321277e-02 -9.62259858e-03 -2.79157360e-02\n",
      "  1.70704339e-02 -4.05231832e-02  1.64822718e-02 -7.23360605e-03\n",
      "  2.22566893e-02 -2.18723967e-02  2.14566943e-02 -2.73701075e-02\n",
      "  7.02714763e-03  3.18724490e-03 -8.45316168e-05  5.36620385e-02\n",
      " -3.14833756e-02 -1.54467352e-02  2.54040292e-02 -4.92397557e-02\n",
      "  4.21451963e-02  4.97708085e-02 -5.93615498e-03 -3.82431821e-02\n",
      " -1.07732747e-02  2.99199178e-02  1.41236802e-02  1.51275349e-02\n",
      "  1.38805044e-02 -3.67986536e-02  8.34260588e-03 -2.16737548e-02\n",
      "  4.04258362e-02  3.90794657e-04 -5.85423052e-02  7.11323349e-02\n",
      "  4.45506217e-02 -2.00688849e-02 -2.36600710e-02  8.40589010e-03\n",
      " -7.17081476e-03  5.33421827e-03 -2.02124374e-02  2.74369430e-02\n",
      "  5.81588666e-02  2.42147957e-02 -3.22422316e-02 -1.71414274e-02\n",
      "  3.79759056e-02  6.42416143e-02  1.83046662e-02  1.11438357e-02\n",
      "  1.67355378e-01  4.92434101e-01]\n",
      "RMSE:  0.4788709693459286\n",
      "MAE:  0.34422873796075426\n",
      "\n",
      "Training support vector machine:\n",
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "RMSE:  0.5666036575551917\n",
      "MAE:  0.4615236110378425\n",
      "\n",
      "Training neural network: \n",
      "RMSE:  0.4708511273120434\n",
      "MAE:  0.33422664805556535\n",
      "\n",
      "Training LSTM: \n",
      "Epoch 1/100\n",
      "3500/3500 - 3s - loss: 2.2562\n",
      "Epoch 2/100\n",
      "3500/3500 - 1s - loss: 1.3225\n",
      "Epoch 3/100\n",
      "3500/3500 - 1s - loss: 0.9902\n",
      "Epoch 4/100\n",
      "3500/3500 - 1s - loss: 0.7845\n",
      "Epoch 5/100\n",
      "3500/3500 - 1s - loss: 0.7194\n",
      "Epoch 6/100\n",
      "3500/3500 - 1s - loss: 0.6889\n",
      "Epoch 7/100\n",
      "3500/3500 - 1s - loss: 0.6560\n",
      "Epoch 8/100\n",
      "3500/3500 - 1s - loss: 0.6268\n",
      "Epoch 9/100\n",
      "3500/3500 - 1s - loss: 0.5883\n",
      "Epoch 10/100\n",
      "3500/3500 - 1s - loss: 0.6163\n",
      "Epoch 11/100\n",
      "3500/3500 - 1s - loss: 0.6235\n",
      "Epoch 12/100\n",
      "3500/3500 - 1s - loss: 0.5607\n",
      "Epoch 13/100\n",
      "3500/3500 - 1s - loss: 0.5712\n",
      "Epoch 14/100\n",
      "3500/3500 - 1s - loss: 0.5375\n",
      "Epoch 15/100\n",
      "3500/3500 - 1s - loss: 0.6027\n",
      "Epoch 16/100\n",
      "3500/3500 - 1s - loss: 0.5984\n",
      "Epoch 17/100\n",
      "3500/3500 - 1s - loss: 0.5612\n",
      "Epoch 18/100\n",
      "3500/3500 - 1s - loss: 0.5563\n",
      "Epoch 19/100\n",
      "3500/3500 - 1s - loss: 0.6103\n",
      "Epoch 20/100\n",
      "3500/3500 - 1s - loss: 0.5640\n",
      "Epoch 21/100\n",
      "3500/3500 - 1s - loss: 0.5596\n",
      "Epoch 22/100\n",
      "3500/3500 - 1s - loss: 0.5494\n",
      "Epoch 23/100\n",
      "3500/3500 - 1s - loss: 1.1495\n",
      "Epoch 24/100\n",
      "3500/3500 - 1s - loss: 0.8280\n",
      "Epoch 25/100\n",
      "3500/3500 - 1s - loss: 0.7158\n",
      "Epoch 26/100\n",
      "3500/3500 - 1s - loss: 0.6909\n",
      "Epoch 27/100\n",
      "3500/3500 - 1s - loss: 0.6549\n",
      "Epoch 28/100\n",
      "3500/3500 - 1s - loss: 0.6312\n",
      "Epoch 29/100\n",
      "3500/3500 - 1s - loss: 0.6357\n",
      "Epoch 30/100\n",
      "3500/3500 - 1s - loss: 0.6212\n",
      "Epoch 31/100\n",
      "3500/3500 - 1s - loss: 0.6025\n",
      "Epoch 32/100\n",
      "3500/3500 - 1s - loss: 0.6057\n",
      "Epoch 33/100\n",
      "3500/3500 - 1s - loss: 0.6161\n",
      "Epoch 34/100\n",
      "3500/3500 - 1s - loss: 0.6090\n",
      "Epoch 35/100\n",
      "3500/3500 - 1s - loss: 0.5993\n",
      "Epoch 36/100\n",
      "3500/3500 - 1s - loss: 0.6183\n",
      "Epoch 37/100\n",
      "3500/3500 - 1s - loss: 0.6047\n",
      "Epoch 38/100\n",
      "3500/3500 - 1s - loss: 0.6122\n",
      "Epoch 39/100\n",
      "3500/3500 - 1s - loss: 0.6143\n",
      "Epoch 40/100\n",
      "3500/3500 - 1s - loss: 0.5944\n",
      "Epoch 41/100\n",
      "3500/3500 - 1s - loss: 0.5998\n",
      "Epoch 42/100\n",
      "3500/3500 - 1s - loss: 0.5970\n",
      "Epoch 43/100\n",
      "3500/3500 - 1s - loss: 0.6285\n",
      "Epoch 44/100\n",
      "3500/3500 - 1s - loss: 0.5928\n",
      "Epoch 45/100\n",
      "3500/3500 - 1s - loss: 0.6013\n",
      "Epoch 46/100\n",
      "3500/3500 - 1s - loss: 0.6177\n",
      "Epoch 47/100\n",
      "3500/3500 - 1s - loss: 0.5991\n",
      "Epoch 48/100\n",
      "3500/3500 - 1s - loss: 0.5928\n",
      "Epoch 49/100\n",
      "3500/3500 - 1s - loss: 0.6126\n",
      "Epoch 50/100\n",
      "3500/3500 - 1s - loss: 0.6125\n",
      "Epoch 51/100\n",
      "3500/3500 - 1s - loss: 0.6283\n",
      "Epoch 52/100\n",
      "3500/3500 - 1s - loss: 0.5953\n",
      "Epoch 53/100\n",
      "3500/3500 - 1s - loss: 0.5977\n",
      "Epoch 54/100\n",
      "3500/3500 - 1s - loss: 0.5977\n",
      "Epoch 55/100\n",
      "3500/3500 - 1s - loss: 0.6019\n",
      "Epoch 56/100\n",
      "3500/3500 - 1s - loss: 0.6216\n",
      "Epoch 57/100\n",
      "3500/3500 - 1s - loss: 0.5908\n",
      "Epoch 58/100\n",
      "3500/3500 - 1s - loss: 0.5982\n",
      "Epoch 59/100\n",
      "3500/3500 - 1s - loss: 0.5847\n",
      "Epoch 60/100\n",
      "3500/3500 - 1s - loss: 0.5908\n",
      "Epoch 61/100\n",
      "3500/3500 - 1s - loss: 0.5907\n",
      "Epoch 62/100\n",
      "3500/3500 - 1s - loss: 0.5996\n",
      "Epoch 63/100\n",
      "3500/3500 - 1s - loss: 0.6019\n",
      "Epoch 64/100\n",
      "3500/3500 - 1s - loss: 0.5887\n",
      "Epoch 65/100\n",
      "3500/3500 - 1s - loss: 0.5884\n",
      "Epoch 66/100\n",
      "3500/3500 - 1s - loss: 0.6105\n",
      "Epoch 67/100\n",
      "3500/3500 - 1s - loss: 0.5963\n",
      "Epoch 68/100\n",
      "3500/3500 - 1s - loss: 0.6025\n",
      "Epoch 69/100\n",
      "3500/3500 - 1s - loss: 0.5913\n",
      "Epoch 70/100\n",
      "3500/3500 - 1s - loss: 0.5831\n",
      "Epoch 71/100\n",
      "3500/3500 - 1s - loss: 0.5687\n",
      "Epoch 72/100\n",
      "3500/3500 - 1s - loss: 0.5909\n",
      "Epoch 73/100\n",
      "3500/3500 - 1s - loss: 0.5913\n",
      "Epoch 74/100\n",
      "3500/3500 - 1s - loss: 0.5793\n",
      "Epoch 75/100\n",
      "3500/3500 - 1s - loss: 0.5804\n",
      "Epoch 76/100\n",
      "3500/3500 - 1s - loss: 0.5731\n",
      "Epoch 77/100\n",
      "3500/3500 - 1s - loss: 0.5913\n",
      "Epoch 78/100\n",
      "3500/3500 - 1s - loss: 0.6074\n",
      "Epoch 79/100\n",
      "3500/3500 - 1s - loss: 0.6001\n",
      "Epoch 80/100\n",
      "3500/3500 - 1s - loss: 0.5951\n",
      "Epoch 81/100\n",
      "3500/3500 - 1s - loss: 0.6188\n",
      "Epoch 82/100\n",
      "3500/3500 - 1s - loss: 0.5792\n",
      "Epoch 83/100\n",
      "3500/3500 - 1s - loss: 0.5896\n",
      "Epoch 84/100\n",
      "3500/3500 - 1s - loss: 0.6058\n",
      "Epoch 85/100\n",
      "3500/3500 - 1s - loss: 0.5826\n",
      "Epoch 86/100\n",
      "3500/3500 - 1s - loss: 0.5993\n",
      "Epoch 87/100\n",
      "3500/3500 - 1s - loss: 0.5871\n",
      "Epoch 88/100\n",
      "3500/3500 - 1s - loss: 0.5737\n",
      "Epoch 89/100\n",
      "3500/3500 - 1s - loss: 0.6057\n",
      "Epoch 90/100\n",
      "3500/3500 - 1s - loss: 0.5899\n",
      "Epoch 91/100\n",
      "3500/3500 - 1s - loss: 0.5953\n",
      "Epoch 92/100\n",
      "3500/3500 - 1s - loss: 0.5954\n",
      "Epoch 93/100\n",
      "3500/3500 - 1s - loss: 0.6013\n",
      "Epoch 94/100\n",
      "3500/3500 - 1s - loss: 0.5788\n",
      "Epoch 95/100\n",
      "3500/3500 - 1s - loss: 0.5882\n",
      "Epoch 96/100\n",
      "3500/3500 - 1s - loss: 0.5824\n",
      "Epoch 97/100\n",
      "3500/3500 - 1s - loss: 0.5920\n",
      "Epoch 98/100\n",
      "3500/3500 - 1s - loss: 0.5913\n",
      "Epoch 99/100\n",
      "3500/3500 - 1s - loss: 0.5907\n",
      "Epoch 100/100\n",
      "3500/3500 - 1s - loss: 0.5961\n",
      "Train Score: 0.73 RMSE\n",
      "Test Score: 0.66 RMSE\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b510701d09cf41c7b51f70393831d08d"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "########################################################################\n",
    "# data\n",
    "########################################################################\n",
    "sp_500 = pd.read_csv('../test_data/GSPC.csv')\n",
    "x = sp_500['Volume'][-4000:]\n",
    "dates = sp_500['Date'][-4000:]\n",
    "\n",
    "# percentage returns\n",
    "x_pct = x.pct_change().fillna(0)\n",
    "x_pct\n",
    "\n",
    "# create new df hold both\n",
    "df = pd.DataFrame(columns=['Dates','Open','pct_change','pct_change_cumprod']) # ,'log_transform'\n",
    "df['Dates'] = dates\n",
    "df['Volume'] =  x\n",
    "df['pct_change'] = x_pct\n",
    "df['pct_change_cumprod'] = (x_pct + 1).cumprod()\n",
    "\n",
    "########################################################################\n",
    "# initialize class object\n",
    "########################################################################\n",
    "normal = time_series_prediction(df['Dates'][-4000:],df['Volume'][-4000:]/1e9,150,1) # pass time series, lag window length, a number of steps ahead to predict\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised learning ML problem\n",
    "normal.train_test_split(split=3500) # testing and training dataset split\n",
    "normal.test_train_plot()    # visualize training split\n",
    "\n",
    "########################################################################\n",
    "# perform some prediction tasks\n",
    "########################################################################\n",
    "normal.linear_regression()\n",
    "normal.support_vector_machine()\n",
    "normal.neural_net_mlp()\n",
    "normal.lstm()\n",
    "\n",
    "\n",
    "normal.vis_results_time_series(second_plot='error')"
   ]
  },
  {
   "source": [
    "## Build lstm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "3500/3500 - 2s - loss: 1.3003\n",
      "Epoch 2/100\n",
      "3500/3500 - 1s - loss: 0.4772\n",
      "Epoch 3/100\n",
      "3500/3500 - 1s - loss: 0.4081\n",
      "Epoch 4/100\n",
      "3500/3500 - 1s - loss: 0.3913\n",
      "Epoch 5/100\n",
      "3500/3500 - 1s - loss: 0.3805\n",
      "Epoch 6/100\n",
      "3500/3500 - 1s - loss: 0.3764\n",
      "Epoch 7/100\n",
      "3500/3500 - 1s - loss: 0.3747\n",
      "Epoch 8/100\n",
      "3500/3500 - 1s - loss: 0.3765\n",
      "Epoch 9/100\n",
      "3500/3500 - 1s - loss: 0.3737\n",
      "Epoch 10/100\n",
      "3500/3500 - 1s - loss: 0.3764\n",
      "Epoch 11/100\n",
      "3500/3500 - 1s - loss: 0.3683\n",
      "Epoch 12/100\n",
      "3500/3500 - 1s - loss: 0.3710\n",
      "Epoch 13/100\n",
      "3500/3500 - 1s - loss: 0.3645\n",
      "Epoch 14/100\n",
      "3500/3500 - 1s - loss: 0.3699\n",
      "Epoch 15/100\n",
      "3500/3500 - 1s - loss: 0.3657\n",
      "Epoch 16/100\n",
      "3500/3500 - 1s - loss: 0.3639\n",
      "Epoch 17/100\n",
      "3500/3500 - 1s - loss: 0.3678\n",
      "Epoch 18/100\n",
      "3500/3500 - 1s - loss: 0.3634\n",
      "Epoch 19/100\n",
      "3500/3500 - 1s - loss: 0.3622\n",
      "Epoch 20/100\n",
      "3500/3500 - 1s - loss: 0.3590\n",
      "Epoch 21/100\n",
      "3500/3500 - 1s - loss: 0.3586\n",
      "Epoch 22/100\n",
      "3500/3500 - 1s - loss: 0.3630\n",
      "Epoch 23/100\n",
      "3500/3500 - 1s - loss: 0.3635\n",
      "Epoch 24/100\n",
      "3500/3500 - 1s - loss: 0.3624\n",
      "Epoch 25/100\n",
      "3500/3500 - 1s - loss: 0.3590\n",
      "Epoch 26/100\n",
      "3500/3500 - 1s - loss: 0.3628\n",
      "Epoch 27/100\n",
      "3500/3500 - 1s - loss: 0.3608\n",
      "Epoch 28/100\n",
      "3500/3500 - 1s - loss: 0.3566\n",
      "Epoch 29/100\n",
      "3500/3500 - 1s - loss: 0.3582\n",
      "Epoch 30/100\n",
      "3500/3500 - 1s - loss: 0.3601\n",
      "Epoch 31/100\n",
      "3500/3500 - 1s - loss: 0.3577\n",
      "Epoch 32/100\n",
      "3500/3500 - 1s - loss: 0.3574\n",
      "Epoch 33/100\n",
      "3500/3500 - 1s - loss: 0.3579\n",
      "Epoch 34/100\n",
      "3500/3500 - 1s - loss: 0.3552\n",
      "Epoch 35/100\n",
      "3500/3500 - 1s - loss: 0.3585\n",
      "Epoch 36/100\n",
      "3500/3500 - 1s - loss: 0.3582\n",
      "Epoch 37/100\n",
      "3500/3500 - 1s - loss: 0.3558\n",
      "Epoch 38/100\n",
      "3500/3500 - 1s - loss: 0.3570\n",
      "Epoch 39/100\n",
      "3500/3500 - 1s - loss: 0.3529\n",
      "Epoch 40/100\n",
      "3500/3500 - 1s - loss: 0.3523\n",
      "Epoch 41/100\n",
      "3500/3500 - 1s - loss: 0.3550\n",
      "Epoch 42/100\n",
      "3500/3500 - 1s - loss: 0.3533\n",
      "Epoch 43/100\n",
      "3500/3500 - 1s - loss: 0.3539\n",
      "Epoch 44/100\n",
      "3500/3500 - 1s - loss: 0.3501\n",
      "Epoch 45/100\n",
      "3500/3500 - 1s - loss: 0.3516\n",
      "Epoch 46/100\n",
      "3500/3500 - 1s - loss: 0.3577\n",
      "Epoch 47/100\n",
      "3500/3500 - 1s - loss: 0.3518\n",
      "Epoch 48/100\n",
      "3500/3500 - 1s - loss: 0.3523\n",
      "Epoch 49/100\n",
      "3500/3500 - 1s - loss: 0.3531\n",
      "Epoch 50/100\n",
      "3500/3500 - 1s - loss: 0.3520\n",
      "Epoch 51/100\n",
      "3500/3500 - 1s - loss: 0.3548\n",
      "Epoch 52/100\n",
      "3500/3500 - 1s - loss: 0.3503\n",
      "Epoch 53/100\n",
      "3500/3500 - 1s - loss: 0.3505\n",
      "Epoch 54/100\n",
      "3500/3500 - 1s - loss: 0.3538\n",
      "Epoch 55/100\n",
      "3500/3500 - 1s - loss: 0.3530\n",
      "Epoch 56/100\n",
      "3500/3500 - 1s - loss: 0.3509\n",
      "Epoch 57/100\n",
      "3500/3500 - 1s - loss: 0.3511\n",
      "Epoch 58/100\n",
      "3500/3500 - 1s - loss: 0.3542\n",
      "Epoch 59/100\n",
      "3500/3500 - 1s - loss: 0.3504\n",
      "Epoch 60/100\n",
      "3500/3500 - 1s - loss: 0.3498\n",
      "Epoch 61/100\n",
      "3500/3500 - 1s - loss: 0.3501\n",
      "Epoch 62/100\n",
      "3500/3500 - 1s - loss: 0.3488\n",
      "Epoch 63/100\n",
      "3500/3500 - 1s - loss: 0.3478\n",
      "Epoch 64/100\n",
      "3500/3500 - 1s - loss: 0.3481\n",
      "Epoch 65/100\n",
      "3500/3500 - 1s - loss: 0.3479\n",
      "Epoch 66/100\n",
      "3500/3500 - 1s - loss: 0.3507\n",
      "Epoch 67/100\n",
      "3500/3500 - 1s - loss: 0.3508\n",
      "Epoch 68/100\n",
      "3500/3500 - 1s - loss: 0.3493\n",
      "Epoch 69/100\n",
      "3500/3500 - 1s - loss: 0.3479\n",
      "Epoch 70/100\n",
      "3500/3500 - 1s - loss: 0.3461\n",
      "Epoch 71/100\n",
      "3500/3500 - 1s - loss: 0.3494\n",
      "Epoch 72/100\n",
      "3500/3500 - 1s - loss: 0.3504\n",
      "Epoch 73/100\n",
      "3500/3500 - 1s - loss: 0.3488\n",
      "Epoch 74/100\n",
      "3500/3500 - 1s - loss: 0.3488\n",
      "Epoch 75/100\n",
      "3500/3500 - 1s - loss: 0.3521\n",
      "Epoch 76/100\n",
      "3500/3500 - 1s - loss: 0.3496\n",
      "Epoch 77/100\n",
      "3500/3500 - 1s - loss: 0.3464\n",
      "Epoch 78/100\n",
      "3500/3500 - 1s - loss: 0.3501\n",
      "Epoch 79/100\n",
      "3500/3500 - 1s - loss: 0.3463\n",
      "Epoch 80/100\n",
      "3500/3500 - 1s - loss: 0.3480\n",
      "Epoch 81/100\n",
      "3500/3500 - 1s - loss: 0.3465\n",
      "Epoch 82/100\n",
      "3500/3500 - 1s - loss: 0.3501\n",
      "Epoch 83/100\n",
      "3500/3500 - 1s - loss: 0.3457\n",
      "Epoch 84/100\n",
      "3500/3500 - 1s - loss: 0.3480\n",
      "Epoch 85/100\n",
      "3500/3500 - 1s - loss: 0.3499\n",
      "Epoch 86/100\n",
      "3500/3500 - 1s - loss: 0.3457\n",
      "Epoch 87/100\n",
      "3500/3500 - 1s - loss: 0.3486\n",
      "Epoch 88/100\n",
      "3500/3500 - 1s - loss: 0.3464\n",
      "Epoch 89/100\n",
      "3500/3500 - 1s - loss: 0.3451\n",
      "Epoch 90/100\n",
      "3500/3500 - 1s - loss: 0.3440\n",
      "Epoch 91/100\n",
      "3500/3500 - 1s - loss: 0.3482\n",
      "Epoch 92/100\n",
      "3500/3500 - 1s - loss: 0.3475\n",
      "Epoch 93/100\n",
      "3500/3500 - 1s - loss: 0.3486\n",
      "Epoch 94/100\n",
      "3500/3500 - 1s - loss: 0.3472\n",
      "Epoch 95/100\n",
      "3500/3500 - 1s - loss: 0.3484\n",
      "Epoch 96/100\n",
      "3500/3500 - 1s - loss: 0.3443\n",
      "Epoch 97/100\n",
      "3500/3500 - 1s - loss: 0.3439\n",
      "Epoch 98/100\n",
      "3500/3500 - 1s - loss: 0.3465\n",
      "Epoch 99/100\n",
      "3500/3500 - 1s - loss: 0.3468\n",
      "Epoch 100/100\n",
      "3500/3500 - 1s - loss: 0.3425\n",
      "Train Score: 0.61 RMSE\n",
      "Test Score: 0.56 RMSE\n"
     ]
    }
   ],
   "source": [
    "trainX = np.reshape(normal.X_train, (normal.X_train.shape[0], 1, normal.X_train.shape[1]))\n",
    "testX = np.reshape(normal.X_test, (normal.X_test.shape[0], 1, normal.X_train.shape[1]))\n",
    "trainY = normal.y_train\n",
    "testY = normal.y_test\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, 5)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2.7830205],\n",
       "       [2.6712413],\n",
       "       [2.2477574],\n",
       "       ...,\n",
       "       [3.8193555],\n",
       "       [3.7082005],\n",
       "       [3.7810779]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-41413e09f43f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnormal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}