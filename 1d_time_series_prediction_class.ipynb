{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e1d4880ad13fa2099fc93eba0cb791232af4f1a31a1c632661aaef6a29f2ead6",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Code up class to perform different tasks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive figures\n",
    "%matplotlib widget \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# model evalution metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# predictive models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class time_series_prediction():\n",
    "\n",
    "    def __init__(self,one_d_time_series,lag_window_length,n_ahead_prediction):\n",
    "\n",
    "        # raw input data + settings for time series -> supervised learning ML problem\n",
    "        self.one_d_time_series = np.array(one_d_time_series)      # time series array, to array ensure index works as expected for class methods\n",
    "        self.lag_window_length = lag_window_length                # length of lag window\n",
    "        self.n_ahead_prediction = n_ahead_prediction              # time ahead to predict\n",
    "\n",
    "        # transfromed data: set after calling .sliding_window_1()\n",
    "        self.input_data = None\n",
    "        self.target_data = None\n",
    "\n",
    "        # testing and training data: set after calling .train_test_split()\n",
    "        self.training_split = None\n",
    "        self.X_test = None\n",
    "        self.X_train = None\n",
    "        self.y_test = None\n",
    "        self.y_train = None\n",
    "\n",
    "# ****************************************************************************************************************\n",
    "    # data wrangling\n",
    "# ****************************************************************************************************************\n",
    "\n",
    "    # method to transfroms 1-D time series to supervised ML problem: one step ahead forecasting   \n",
    "    def sliding_window_1(self,verbose):\n",
    "        # initialize input array\n",
    "        num_rows = len(self.one_d_time_series) - self.lag_window_length\n",
    "        array = np.zeros((num_rows, self.lag_window_length + 1))\n",
    "        \n",
    "        # loop through data and populate array\n",
    "        for i in range(num_rows):\n",
    "            # input features\n",
    "            array[i,0:self.lag_window_length+1] = self.one_d_time_series[i:i+self.lag_window_length+1]\n",
    "            # target feature/s\n",
    "            array[i,-1] = self.one_d_time_series[i+self.lag_window_length]\n",
    "            \n",
    "            if verbose == 1:\n",
    "                # show pattern\n",
    "                print(array[i,0:self.lag_window_length],' : ',array[i,self.lag_window_length])\n",
    "\n",
    "        # save results as a class attribute\n",
    "        self.input_data = array[:,0:self.lag_window_length]\n",
    "        self.target_data = array[:,self.lag_window_length]\n",
    "\n",
    "    # method to perform a training and testing split for dataset with only a single column of target variables\n",
    "    def train_test_split(self,split):\n",
    "        self.training_split = split\n",
    "        self.X_train = self.input_data[0:split,:]\n",
    "        self.X_test = self.input_data[split:,:]\n",
    "        self.y_train = self.target_data[0:split]\n",
    "        self.y_test = self.target_data[split:]\n",
    "\n",
    "    # method to plot testing and training split of data\n",
    "    def test_train_plot(self):\n",
    "        num_days = range(len(self.one_d_time_series)) # hacking this as x-axis of plot\n",
    "        fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "        ax.plot(num_days[0:self.training_split] ,self.one_d_time_series[0:self.training_split],'k-',label='Training data') # replace returns with sp_500 for other data plotting\n",
    "        ax.plot(num_days[self.training_split:] ,self.one_d_time_series[self.training_split:],'r-',label='Testing data')\n",
    "        plt.plot(num_days[self.training_split+self.lag_window_length:] ,self.y_test,'o',label='Windowed testing data') # important to match time by start 5 (length of time window) after where segmented our testing and training data\n",
    "        plt.legend(loc=0)  \n",
    "\n",
    "# ****************************************************************************************************************\n",
    "    # predictive models\n",
    "# ****************************************************************************************************************\n",
    "\n",
    "    def linear_regression(self):\n",
    "        print('Training multivariate linear regression:')\n",
    "        # train model\n",
    "        reg_model = LinearRegression().fit(self.X_train,self.y_train)\n",
    "        print('Linear regression coefficients: \\n',reg_model.coef_)\n",
    "\n",
    "        # test model\n",
    "        predictions = reg_model.predict(self.X_test)\n",
    "\n",
    "        # evaluate: use sklearn metric methods to calc rmse and mae\n",
    "        mse = mean_squared_error(y_test,predictions)\n",
    "        mae = mean_absolute_error(y_test,predictions)\n",
    "\n",
    "        print('RMSE: ',np.sqrt(mse))\n",
    "        print('MAE: ',mae)\n",
    "\n",
    "    def support_vector_machine(self):\n",
    "        print('Training support vector machine:')\n",
    "        # train model\n",
    "        svm_regres = LinearSVR(max_iter=1000).fit(X_train,y_train)\n",
    "\n",
    "        # predict\n",
    "        svm_predictions = svm_regres.predict(X_test)\n",
    "\n",
    "        # evaluate\n",
    "        mse = mean_squared_error(y_test,svm_predictions[:])\n",
    "        mae = mean_absolute_error(y_test,svm_predictions[:])\n",
    "\n",
    "        print('RMSE: ',np.sqrt(mse))\n",
    "        print('MAE: ',mae)\n",
    "\n",
    "    def neural_net_mlp(self):\n",
    "        print('Training neural network: ')\n",
    "        # train neural network\n",
    "        nn_regres = MLPRegressor(hidden_layer_sizes=(100,100,100),shuffle=False,random_state=1, \n",
    "                                max_iter=1000,verbose=1).fit(X_train,y_train)\n",
    "\n",
    "        # make predictions\n",
    "        nn_predictions = nn_regres.predict(X_test)\n",
    "\n",
    "        # evaluate\n",
    "        mse = mean_squared_error(y_test,nn_predictions[:])\n",
    "        mae = mean_absolute_error(y_test,nn_predictions[:])\n",
    "\n",
    "        print('RMSE: ',np.sqrt(mse))\n",
    "        print('MAE: ',mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Date         Open         High          Low        Close  \\\n",
       "0      1950-01-03    16.660000    16.660000    16.660000    16.660000   \n",
       "1      1950-01-04    16.850000    16.850000    16.850000    16.850000   \n",
       "2      1950-01-05    16.930000    16.930000    16.930000    16.930000   \n",
       "3      1950-01-06    16.980000    16.980000    16.980000    16.980000   \n",
       "4      1950-01-09    17.080000    17.080000    17.080000    17.080000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "17213  2018-05-31  2720.979980  2722.500000  2700.679932  2705.270020   \n",
       "17214  2018-06-01  2718.699951  2736.929932  2718.699951  2734.620117   \n",
       "17215  2018-06-04  2741.669922  2749.159912  2740.540039  2746.870117   \n",
       "17216  2018-06-05  2748.459961  2752.610107  2739.510010  2748.800049   \n",
       "17217  2018-06-06  2753.250000  2772.389893  2748.459961  2772.350098   \n",
       "\n",
       "         Adj Close      Volume  \n",
       "0        16.660000     1260000  \n",
       "1        16.850000     1890000  \n",
       "2        16.930000     2550000  \n",
       "3        16.980000     2010000  \n",
       "4        17.080000     2520000  \n",
       "...            ...         ...  \n",
       "17213  2705.270020  4235370000  \n",
       "17214  2734.620117  3684130000  \n",
       "17215  2746.870117  3376510000  \n",
       "17216  2748.800049  3517790000  \n",
       "17217  2772.350098  3651640000  \n",
       "\n",
       "[17218 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1950-01-03</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>1260000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1950-01-04</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>1890000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1950-01-05</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>2550000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1950-01-06</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>2010000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1950-01-09</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>2520000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17213</th>\n      <td>2018-05-31</td>\n      <td>2720.979980</td>\n      <td>2722.500000</td>\n      <td>2700.679932</td>\n      <td>2705.270020</td>\n      <td>2705.270020</td>\n      <td>4235370000</td>\n    </tr>\n    <tr>\n      <th>17214</th>\n      <td>2018-06-01</td>\n      <td>2718.699951</td>\n      <td>2736.929932</td>\n      <td>2718.699951</td>\n      <td>2734.620117</td>\n      <td>2734.620117</td>\n      <td>3684130000</td>\n    </tr>\n    <tr>\n      <th>17215</th>\n      <td>2018-06-04</td>\n      <td>2741.669922</td>\n      <td>2749.159912</td>\n      <td>2740.540039</td>\n      <td>2746.870117</td>\n      <td>2746.870117</td>\n      <td>3376510000</td>\n    </tr>\n    <tr>\n      <th>17216</th>\n      <td>2018-06-05</td>\n      <td>2748.459961</td>\n      <td>2752.610107</td>\n      <td>2739.510010</td>\n      <td>2748.800049</td>\n      <td>2748.800049</td>\n      <td>3517790000</td>\n    </tr>\n    <tr>\n      <th>17217</th>\n      <td>2018-06-06</td>\n      <td>2753.250000</td>\n      <td>2772.389893</td>\n      <td>2748.459961</td>\n      <td>2772.350098</td>\n      <td>2772.350098</td>\n      <td>3651640000</td>\n    </tr>\n  </tbody>\n</table>\n<p>17218 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# import some data\n",
    "sp_500 = pd.read_csv('../test_data/GSPC.csv')\n",
    "sp_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normal = time_series_prediction(sp_500['Volume'][-2000:],5,1)\n",
    "normal.sliding_window_1(verbose=0)\n",
    "normal.train_test_split(split=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3896410000, 6136700000, 5067080000, ..., 3376510000, 3517790000,\n",
       "       3651640000], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "normal.one_d_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1995, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "normal.input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1995,)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "normal.target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f7d32cb0d7a403db759872109acd2a1"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "normal.test_train_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}