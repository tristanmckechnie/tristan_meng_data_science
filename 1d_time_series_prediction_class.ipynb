{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "e1d4880ad13fa2099fc93eba0cb791232af4f1a31a1c632661aaef6a29f2ead6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Code up class to perform different tasks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# interactive figures\r\n",
    "%matplotlib widget \r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from one_dimensional_time_series_forecasting import time_series_prediction"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.0 Import some test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# import some data\r\n",
    "sp_500 = pd.read_csv('./test_data/AirPassengers.csv') # sp_500 = GSPC.csv, # airplaine = AirPassengers.csv\r\n",
    "sp_500"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>#Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1960-08</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1960-09</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1960-10</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1960-11</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1960-12</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  #Passengers\n",
       "0    1949-01          112\n",
       "1    1949-02          118\n",
       "2    1949-03          132\n",
       "3    1949-04          129\n",
       "4    1949-05          121\n",
       "..       ...          ...\n",
       "139  1960-08          606\n",
       "140  1960-09          508\n",
       "141  1960-10          461\n",
       "142  1960-11          390\n",
       "143  1960-12          432\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.0 Example of using class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# initialize class object\r\n",
    "normal = time_series_prediction(sp_500['Month'],sp_500['#Passengers'],5,1)#time_series_prediction(sp_500['Date'][-4000:],sp_500['Volume'][-4000:]/1e9,5,1) # pass: ime series dates, univariate time series, lag window length, a number of steps ahead to predict\r\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised ML problem\r\n",
    "normal.train_test_split(split=120) # testing and training dataset split\r\n",
    "normal.test_train_plot()    # visualize training split"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bed0c9412d5476d9c153b80faa6c6f1"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d3469ca12274f48b045cdeccb6c38bb"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# perform some prediction tasks\r\n",
    "normal.linear_regression()\r\n",
    "normal.support_vector_machine(model_tunning=True)\r\n",
    "normal.neural_net_mlp(model_tunning=True)\r\n",
    "normal.naive_model()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [ 0.2855884  -0.23434857  0.10106481 -0.391026    1.20859648]\n",
      "RMSE:  48.02671734923388\n",
      "MAE:  39.998781021856935\n",
      "\n",
      "Training support vector machine:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  72 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-3)]: Done 240 out of 240 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_score:  -1021.4497817413388\n",
      "best_model:  SVR(C=10, epsilon=10, kernel='linear')\n",
      "best_params:  {'C': 10, 'epsilon': 10, 'kernel': 'linear'}\n",
      "RMSE:  51.54507490642474\n",
      "MAE:  42.032807216025525\n",
      "\n",
      "Training neural network: \n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done 140 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-3)]: Done 378 out of 405 | elapsed:    6.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-3)]: Done 405 out of 405 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_score:  -628.1820929181683\n",
      "best_model:  MLPRegressor(hidden_layer_sizes=(1000,), learning_rate_init=0.01, max_iter=1000,\n",
      "             shuffle=False)\n",
      "best_params:  {'activation': 'relu', 'hidden_layer_sizes': (1000,), 'learning_rate': 'constant', 'learning_rate_init': 0.01}\n",
      "RMSE:  36.051338036456684\n",
      "MAE:  27.670057543258803\n",
      "\n",
      "Naive model results:\n",
      "RMSE:  55.59628916052808\n",
      "MAE:  48.526315789473685\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# visualize results\r\n",
    "normal.vis_results_time_series(second_plot='error')\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aad6a94327e0410d81b54fd4954e600a"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- even with the volume data which seems more stationary than open price data, the forecasts are still dominated by t-1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# plot predicted vs real value scatter plots\r\n",
    "normal.vis_results_scatter()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1f8bb26f2614450a8a1a93e6b6953c5"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.0 Play around with standardization and prediction returns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# some misc data\r\n",
    "x = sp_500['Open'][-2000:]\r\n",
    "dates = sp_500['Date'][-2000:]\r\n",
    "# percentage returns\r\n",
    "x_pct = x.pct_change().fillna(0)\r\n",
    "x_pct\r\n",
    "\r\n",
    "# create new df hold both\r\n",
    "df = pd.DataFrame(columns=['Dates','Open','pct_change','pct_change_cumprod']) # ,'log_transform'\r\n",
    "df['Dates'] = dates\r\n",
    "df['Open'] =  x\r\n",
    "df['pct_change'] = x_pct\r\n",
    "df['pct_change_cumprod'] = (x_pct + 1).cumprod()\r\n",
    "# df['log_transform'] = np.log(df['Open'] )\r\n",
    "\r\n",
    "df.reset_index(inplace=True,drop=True)\r\n",
    "\r\n",
    "# plot\r\n",
    "df.plot(subplots=True,sharex=True,figsize=(7,7))\r\n",
    "plt.tight_layout()\r\n",
    "\r\n",
    "# view data\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc89b935ba3c4e2d891666aa2a8b0bf7"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Open</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>pct_change_cumprod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-28</td>\n",
       "      <td>1077.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>1071.099976</td>\n",
       "      <td>-0.005940</td>\n",
       "      <td>0.994060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>1040.560059</td>\n",
       "      <td>-0.028513</td>\n",
       "      <td>0.965717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>1031.099976</td>\n",
       "      <td>-0.009091</td>\n",
       "      <td>0.956937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>1027.650024</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>0.953736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>2720.979980</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>2.525271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>2718.699951</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>2.523155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>2741.669922</td>\n",
       "      <td>0.008449</td>\n",
       "      <td>2.544473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2018-06-05</td>\n",
       "      <td>2748.459961</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>2.550775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>2753.250000</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>2.555220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dates         Open  pct_change  pct_change_cumprod\n",
       "0     2010-06-28  1077.500000    0.000000            1.000000\n",
       "1     2010-06-29  1071.099976   -0.005940            0.994060\n",
       "2     2010-06-30  1040.560059   -0.028513            0.965717\n",
       "3     2010-07-01  1031.099976   -0.009091            0.956937\n",
       "4     2010-07-02  1027.650024   -0.003346            0.953736\n",
       "...          ...          ...         ...                 ...\n",
       "1995  2018-05-31  2720.979980    0.006864            2.525271\n",
       "1996  2018-06-01  2718.699951   -0.000838            2.523155\n",
       "1997  2018-06-04  2741.669922    0.008449            2.544473\n",
       "1998  2018-06-05  2748.459961    0.002477            2.550775\n",
       "1999  2018-06-06  2753.250000    0.001743            2.555220\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- unsure what the log transform is required for"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 predicting using returns data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "scaler = MinMaxScaler()\n",
    "df['pct_change_normalised'] = scaler.fit_transform(df['pct_change'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "normal = time_series_prediction(df['Dates'],df['pct_change_normalised'],10,1) # pass time series, lag window length, a number of steps ahead to predict\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised learning ML problem\n",
    "normal.train_test_split(split=1500) # testing and training dataset split\n",
    "normal.test_train_plot() "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce6f5ab2d9ba4f33b1e538929dcf4451"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "585e40dcfea740f6a1f517f5a0bc6736"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# perform some prediction tasks\n",
    "normal.linear_regression()\n",
    "normal.support_vector_machine(model_tunning=True)\n",
    "normal.neural_net_mlp(model_tunning=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [ 0.0399997  -0.03879977 -0.00294204 -0.00418228 -0.00415419 -0.0923927\n",
      " -0.0174214  -0.07352073  0.02916561 -0.01048691]\n",
      "RMSE:  0.060951546047454785\n",
      "MAE:  0.03906715020243121\n",
      "\n",
      "Training support vector machine:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done 142 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done 213 out of 240 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done 240 out of 240 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "best_score:  -0.0072276237637182664\n",
      "best_model:  SVR(C=0.1, kernel='sigmoid')\n",
      "best_params:  {'C': 0.1, 'epsilon': 0.1, 'kernel': 'sigmoid'}\n",
      "RMSE:  0.05981790295000705\n",
      "MAE:  0.03859594759057162\n",
      "\n",
      "Training neural network: \n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[Parallel(n_jobs=-3)]: Done 140 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-3)]: Done 378 out of 405 | elapsed:   27.8s remaining:    1.9s\n",
      "[Parallel(n_jobs=-3)]: Done 405 out of 405 | elapsed:   46.2s finished\n",
      "best_score:  -0.007219447548982068\n",
      "best_model:  MLPRegressor(activation='logistic', hidden_layer_sizes=(1000,), max_iter=1000,\n",
      "             shuffle=False)\n",
      "best_params:  {'activation': 'logistic', 'hidden_layer_sizes': (1000,), 'learning_rate': 'constant', 'learning_rate_init': 0.001}\n",
      "RMSE:  0.060022399672992464\n",
      "MAE:  0.038872635180143444\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "normal.vis_results_time_series(second_plot='error')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1951c6ba970f4c33af3691e20677ee23"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "some remarks on predictions using returns of open price:\n",
    "- prediction accuracy of models look terrible. Is it even worth comparing feature engineering approaches if predictions are this bad?\n",
    "- evaluating models using cummulative gains seems reasonable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.0 Denosing using fourier transform "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "# import scipy fft functions\n",
    "from scipy.fft import fft, ifft, fftfreq"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "# apply discrete fourier transform\n",
    "signal = np.array(sp_500['Volume'][-2100:]/1e9) # data\n",
    "fft_coefficients = fft(signal) # fourier transform\n",
    "fft_coefficients"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7841.0835      -0.j        ,  344.33876287 -95.53936485j,\n",
       "       -101.66935261-291.99051477j, ...,  133.3537504 +170.01192444j,\n",
       "       -101.66935261+291.99051477j,  344.33876287 +95.53936485j])"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "# plot orignal signal and inverse fourier transform, shows you can transform signal to frequency domain, then back to time domain\n",
    "inverse_fft = ifft(fft_coefficients)\n",
    "fig,ax = plt.subplots(figsize=(10,4))\n",
    "ax.plot(sp_500['Date'][-2100:],inverse_fft,'-',label='Inverse fourier data')\n",
    "ax.plot(range(0,len(inverse_fft)),signal,'.',label='Real data')\n",
    "ax.set_xlabel('Days')\n",
    "ax.set_xticks([sp_500['Date'][-2100:].iloc[x] for x in range(0,len(sp_500['Date'][-2100:]),120)])\n",
    "ax.legend()\n",
    "ax.tick_params(rotation=30,labelsize=15)\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48417c48733241d4955cc213c7695b31"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "# plot amplitude vs frequency \n",
    "n = len(signal)\n",
    "\n",
    "# get frequencies and psd\n",
    "freqs = fftfreq(signal.shape[0]) # x axis of amplitude vs frequency graphs\n",
    "psd = np.abs(fft_coefficients)/n # psd is amplitude/N, psd or power spectrum density is the magnitude of the coefficients resulting from fourier transform\n",
    "\n",
    "# plot psd\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(freqs[1:int(n/2)],psd[1:int(n/2)])\n",
    "ax.set_ylabel('Power spectrum',fontsize=15)\n",
    "ax.set_xlabel('Frequencies',fontsize=15)\n",
    "ax.set_title('FFT')\n",
    "ax.tick_params(labelsize=15)\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00f4988caa6442d6b4cea0df03df6e50"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "observations from coefficient magnitude vs frequency graph:\n",
    "- most frequencies have low amplitude\n",
    "- can denoise signal by setting coefficients with low amplitude to zero - ie a thresholding approach. Here the threshold might be something like 0.06\n",
    "- fyi: frequency = 1 / #days therefore "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "# Threshold coefficients to denoise signal\n",
    "psd_indices = psd > 0.06 # mask\n",
    "fft_filtered = fft_coefficients*psd_indices\n",
    "\n",
    "# low pass filtering\n",
    "freq_indices = freqs < 0.003 \n",
    "fft_filtered = fft_coefficients*freq_indices\n",
    "\n",
    "# inverse transform filter coefficients\n",
    "inverse_transform_filtered = ifft(fft_filtered)\n",
    "\n",
    "# plot this\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(sp_500['Date'][-2100:],signal,'-',label='Real data')\n",
    "ax.plot(sp_500['Date'][-2100:],inverse_transform_filtered,'-',label='Inverse fourier filtered')\n",
    "ax.legend()\n",
    "ax.set_title('Threshold = 0.06')\n",
    "ax.set_xlabel('Days',fontsize=15)\n",
    "ax.set_xticks([sp_500['Date'][-2100:].iloc[x] for x in range(0,len(sp_500['Date'][-2100:]),120)])\n",
    "ax.tick_params(rotation=30,labelsize=15)\n",
    "\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "476b743e87da431a931139d5346bacdb"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "# put together artifical data, here the training set is denoised and the testing set is left unchanged\n",
    "df_data = pd.DataFrame(columns=['Dates','artificial_data'])\n",
    "df_data['Dates'] = sp_500['Date'][-2000:]\n",
    "df_data['artificial_data'] = np.concatenate((np.real(inverse_transform_filtered)[-2000:-500],sp_500['Volume'][-500:].to_numpy()/1e9),axis=None)\n",
    "\n",
    "# plot this\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(sp_500['Date'][-2000:],sp_500['Volume'][-2000:]/1e9,'-',label='Real data')\n",
    "ax.plot(df_data['Dates'],df_data['artificial_data'],'-',label='Artificial testing and training data')\n",
    "ax.legend()\n",
    "ax.set_title('Threshold = 0.06')\n",
    "ax.set_xlabel('Days',fontsize=15)\n",
    "ax.set_xticks([sp_500['Date'][-2000:].iloc[x] for x in range(0,len(sp_500['Date'][-2000:]),120)])\n",
    "ax.tick_params(rotation=30,labelsize=15)\n",
    "\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c8b1eac747e456dbcd77d949e36ec46"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1 now run predictions by training on filtered data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "source": [
    "# initializing predicition class object for denoise\n",
    "fft_denoised = time_series_prediction(sp_500['Date'][-2000:],df_data['artificial_data'],5,1) # pass time series, lag window length, a number of steps ahead to predict\n",
    "fft_denoised.sliding_window_1(verbose=0) # time series to supervised learning ML problem\n",
    "fft_denoised.train_test_split(split=1500) # testing and training dataset split\n",
    "fft_denoised.test_train_plot() "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf8f39d416354c8d875bd82125c71ae4"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90787c283df9464694bd2c23e4096456"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "source": [
    "# perform some prediction tasks\n",
    "fft_denoised.linear_regression()\n",
    "fft_denoised.support_vector_machine(model_tunning=True,C= 100, epsilon= 0.1, kernel= 'linear') # these values come from first training model on normal data\n",
    "fft_denoised.neural_net_mlp(model_tunning=True,activation= 'tanh', hidden_layer_sizes= (1000,), learning_rate= 'constant', learning_rate_init= 0.001) # these values come from first training model on normal data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [0.12485823 0.04414433 0.06316444 0.17700903 0.47536663]\n",
      "RMSE:  0.5346242481632774\n",
      "MAE:  0.34899960149011056\n",
      "\n",
      "Training support vector machine:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  75 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-3)]: Done 152 out of 240 | elapsed:    1.5s remaining:    0.8s\n",
      "[Parallel(n_jobs=-3)]: Done 240 out of 240 | elapsed:    3.3s finished\n",
      "best_score:  -0.08275972620987947\n",
      "best_model:  SVR(C=100, kernel='linear')\n",
      "best_params:  {'C': 100, 'epsilon': 0.1, 'kernel': 'linear'}\n",
      "RMSE:  0.5356419260767656\n",
      "MAE:  0.34698266067530154\n",
      "\n",
      "Training neural network: \n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done 140 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-3)]: Done 341 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-3)]: Done 378 out of 405 | elapsed:   38.5s remaining:    2.7s\n",
      "best_score:  -0.08385066904666261\n",
      "best_model:  MLPRegressor(learning_rate='adaptive', learning_rate_init=0.01, max_iter=1000,\n",
      "             shuffle=False)\n",
      "best_params:  {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01}\n",
      "RMSE:  0.5455745096042889\n",
      "MAE:  0.3570306086210215\n",
      "[Parallel(n_jobs=-3)]: Done 405 out of 405 | elapsed:   47.1s finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "fft_denoised.vis_results_time_series(second_plot='error')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51f19d93352f41d6bfaf11f987e5fd23"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2 Compare denoised results to normal "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "source": [
    "# run predictions on volume data without denoising\n",
    "\n",
    "# initializing predicition class object for denoise\n",
    "normal = time_series_prediction(sp_500['Date'][-2000:],sp_500['Volume'][-2000:]/1e9,5,1) # pass time series, lag window length, a number of steps ahead to predict\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised learning ML problem\n",
    "normal.train_test_split(split=1500) # testing and training dataset split\n",
    "normal.test_train_plot() \n",
    "\n",
    "# perform some prediction tasks\n",
    "normal.linear_regression()\n",
    "normal.support_vector_machine(model_tunning=False,C= 100, epsilon= 0.1, kernel= 'linear')\n",
    "normal.neural_net_mlp(model_tunning=False,activation= 'relu', hidden_layer_sizes= (100,), learning_rate= 'adaptive', learning_rate_init= 0.01)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0f6b03f0a424852a06f2b83475ecc73"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dccf23f0f576415ebb9abe6eb677d305"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [0.09282714 0.02080688 0.04822414 0.15111368 0.44476971]\n",
      "RMSE:  0.5274919871056635\n",
      "MAE:  0.3471744942971835\n",
      "\n",
      "Training support vector machine:\n",
      "Model params:  {'C': 100, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "RMSE:  0.6609905743797734\n",
      "MAE:  0.44956223654614363\n",
      "\n",
      "Training neural network: \n",
      "Model params: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': False, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "RMSE:  0.5354893830493296\n",
      "MAE:  0.34509062992508055\n",
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "source": [
    "# compare results for denoised and normal data: pulling data from predicito objects\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.y_test,'-',label='real vals')\n",
    "ax.plot(fft_denoised.time_series_dates[fft_denoised.training_split+fft_denoised.lag_window_length:],fft_denoised.linear_reg_predictions,'-',label='linear reg - denoised')\n",
    "ax.plot(fft_denoised.time_series_dates[fft_denoised.training_split+fft_denoised.lag_window_length:],fft_denoised.svm_predictions,'-',label='svm - denoised')\n",
    "ax.plot(fft_denoised.time_series_dates[fft_denoised.training_split+fft_denoised.lag_window_length:],fft_denoised.neural_net_predictions,'-',label='nn - denoised')\n",
    "\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.linear_reg_predictions,'--',label='linear reg ')\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.svm_predictions,'--',label='svm ')\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.neural_net_predictions,'--',label='nn ')\n",
    "\n",
    "ax.set_xticks([normal.time_series_dates[x] for x in range(normal.training_split,len(normal.time_series_dates),28)])\n",
    "ax.tick_params(rotation=30)\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fbf6abce5ce4c6291018896f7218031"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How to compare results before and after denoising?\n",
    "- rmse for predictions of denoised data cant be compared to remse of predictions using normal data because you are comparing against two different signals, one noisy and one denoised."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6.0 Wavelet denoising"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drawbacks of fourier transform / denoising:\n",
    "- requires stationary data\n",
    "- no localization of when different frequencies occured\n",
    "- thresholding fourier trasnform coefficients requires setting a hyperparameter - the threshold \n",
    "\n",
    "Benefits of wavelets transform:\n",
    "- data does not need to be stationary\n",
    "- localization of when frequencies occur\n",
    "\n",
    "Drawbacks of wavelets for denoising:\n",
    "- more hyperparameters, threshold value as well as selecting wavelet type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.1 Wavelet transform / decomposition of time series signal"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wavelet denoisng method:\n",
    "- First perform a wavelet transform of the open data, denoise by thresholding coefficients, then computes returns of denoised signal. Compute returns and perform forecasting. Transform predictions to value and compare. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "\n",
    "import pywt\n",
    "import sys\n",
    "\n",
    "# Data format:\n",
    "# Raw data should be in a .txt file with two columns, separated by tabs:\n",
    "#  - The first column should be a time-series index\n",
    "#  - The second column should contain the data to be filtered\n",
    "\n",
    "# Time series / data:\n",
    "data = sp_500['Open'][-5000:] \n",
    "\n",
    "index = sp_500['Open'][-5000:].index\n",
    "\n",
    "# Create wavelet object and define parameters\n",
    "w = pywt.Wavelet('sym8') # sym family look good too sym8, this is where you should change the wavelet type, haar wavelet is simply 'haar'\n",
    "maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
    "print(\"maximum level is \" + str(maxlev))\n",
    "threshold = 0.8 # Threshold for filtering coefficients as part of denoising, the higher this value the more coefficients you set to zero, ie more of the original signal you truncate away / denoise\n",
    "\n",
    "# Decompose into wavelet components, to the level selected:\n",
    "coeffs = pywt.wavedec(data, w, level=4)\n",
    "\n",
    "# Threshold the wavelet coefficients, thereby removing noise\n",
    "\n",
    "# plt.figure(figsize=(8,15))\n",
    "for i in range(1, len(coeffs)):\n",
    "    # plt.subplot(maxlev, 1, i)\n",
    "    # plt.plot(coeffs[i],label='Original coefficients')\n",
    "    coeffs[i] = pywt.threshold(coeffs[i], threshold*max(coeffs[i]),mode='hard')\n",
    "    # plt.plot(coeffs[i],label='Thresholded coefficients')\n",
    "    # plt.ylabel('Scale: '+str(maxlev-i+1))\n",
    "    # plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "# inverse transform coefficient to reconstruct time series signal, minus noise\n",
    "datarec = pywt.waverec(coeffs, w)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(index, data,label='Raw signal')\n",
    "plt.plot(index, datarec,label=\"De-noised signal using wavelet techniques\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distance measures between true signal and denoised\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "maximum level is 8\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9ed7837dd0d42e0a7dd21869e826305"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "coeffs = pywt.wavedec(data, w, level=maxlev)\n",
    "coeffs_array = np.array(coeffs)\n",
    "for i in range(len(coeffs)):\n",
    "    print(i,' : ',len(coeffs[i]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0  :  34\n",
      "1  :  34\n",
      "2  :  53\n",
      "3  :  92\n",
      "4  :  170\n",
      "5  :  326\n",
      "6  :  638\n",
      "7  :  1261\n",
      "8  :  2507\n",
      "<ipython-input-48-b8260bc4145e>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  coeffs_array = np.array(coeffs)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.2 Predictions: normal data vs wavelet denoised"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "predict sp500 open price one day ahead, using precentage returns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# some data processing: \n",
    "\n",
    "# create new df for normal data\n",
    "df_normal = pd.DataFrame(columns=['Dates','Open','pct_change','pct_change_cumprod'])\n",
    "df_normal['Dates'] = sp_500['Date'][-5000:]\n",
    "df_normal['Open'] =   sp_500['Open'][-5000:]\n",
    "df_normal['pct_change'] = df_normal['Open'].pct_change().fillna(0)\n",
    "df_normal['pct_change_cumprod'] = (df_normal['pct_change']  + 1).cumprod()\n",
    "\n",
    "df_normal.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# create new df for wavelet denoised data\n",
    "df_denoised= pd.DataFrame(columns=['Dates','Open','pct_change','pct_change_cumprod'])\n",
    "df_denoised['Dates'] = sp_500['Date'][-5000:]\n",
    "df_denoised['Open'] =   datarec\n",
    "df_denoised['pct_change'] = df_denoised['Open'].pct_change().fillna(0)\n",
    "df_denoised['pct_change_cumprod'] = (df_denoised['pct_change']  + 1).cumprod()\n",
    "\n",
    "df_denoised.reset_index(inplace=True,drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "fig,ax = plt.subplots(figsize=(10,7))\n",
    "df_normal.plot(subplots=True,ax=ax)\n",
    "fig,ax = plt.subplots(figsize=(10,7))\n",
    "df_denoised.plot(subplots=True,ax=ax)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34fed73c60af4e51b2da2e1ced115990"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py:61: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared\n",
      "  plot_obj.generate()\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3b81e8b70384a45a072d60a39ba146d"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py:61: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared\n",
      "  plot_obj.generate()\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([<AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.2 Perform prediction on data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "########################################################################\n",
    "# forecasting on normal data\n",
    "########################################################################\n",
    "\n",
    "normal = time_series_prediction(df_normal['Dates'],df_normal['pct_change'],10,1) # pass time series, lag window length, a number of steps ahead to predict\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised learning ML problem\n",
    "normal.train_test_split(split=4500) # testing and training dataset split\n",
    "normal.test_train_plot()    # visualize training split\n",
    "\n",
    "# perform some prediction tasks\n",
    "normal.linear_regression()\n",
    "normal.support_vector_machine(model_tunning=True)\n",
    "normal.neural_net_mlp(model_tunning=True)\n",
    "\n",
    "#visualize results\n",
    "normal.vis_results_time_series(second_plot='cumprod')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a12e783307f145769773d7c0f4f873f5"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "493a76545daa47a5aa6c472e2d4837d7"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [ 0.00827728 -0.01519066  0.01269019 -0.03919226 -0.00528929 -0.05123576\n",
      " -0.011838    0.00053218 -0.05485617 -0.0432033 ]\n",
      "RMSE:  0.006622549754153012\n",
      "MAE:  0.004311865851622058\n",
      "\n",
      "Training support vector machine:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  84 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-3)]: Done 213 out of 240 | elapsed:    1.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-3)]: Done 240 out of 240 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "best_score:  -0.0002024966760961271\n",
      "best_model:  SVR(C=0.1, epsilon=100, kernel='linear')\n",
      "best_params:  {'C': 0.1, 'epsilon': 100, 'kernel': 'linear'}\n",
      "RMSE:  0.011372765579198503\n",
      "MAE:  0.009777494110736069\n",
      "\n",
      "Training neural network: \n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[Parallel(n_jobs=-3)]: Done 140 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-3)]: Done 335 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-3)]: Done 378 out of 405 | elapsed:  1.0min remaining:    4.3s\n",
      "best_score:  -0.00014193589817502336\n",
      "best_model:  MLPRegressor(hidden_layer_sizes=(10,), learning_rate='invscaling',\n",
      "             learning_rate_init=0.01, max_iter=1000, shuffle=False)\n",
      "best_params:  {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01}\n",
      "RMSE:  0.006616881896142459\n",
      "MAE:  0.004300205007511253\n",
      "[Parallel(n_jobs=-3)]: Done 405 out of 405 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "add1d42333be45bd8ba7fb70c634111e"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "########################################################################\n",
    "# forecasting on denoised data\n",
    "########################################################################\n",
    "\n",
    "denoised = time_series_prediction(df_denoised['Dates'],df_denoised['pct_change'],10,1) # pass time series, lag window length, a number of steps ahead to predict\n",
    "denoised.sliding_window_1(verbose=0) # time series to supervised learning ML problem\n",
    "denoised.train_test_split(split=4500) # testing and training dataset split\n",
    "denoised.test_train_plot() \n",
    "\n",
    "# perform some prediction tasks\n",
    "denoised.linear_regression()\n",
    "denoised.support_vector_machine(model_tunning=True,C= 0.1, epsilon= 10, kernel= 'linear')\n",
    "denoised.neural_net_mlp(model_tunning=True,activation= 'relu', hidden_layer_sizes= (100,), learning_rate= 'adaptive', learning_rate_init= 0.001)\n",
    "\n",
    "#visualize results\n",
    "denoised.vis_results_time_series(second_plot='cumprod')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "429af1d638ef43d7bdc31669f5814374"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1278805bcb0f4990a081061f1a8fcbd0"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [ 0.0237145  -0.02246668  0.04740009  0.00701641  0.03584964 -0.03737366\n",
      " -0.03726144  0.05776496  0.03446961  0.17203609]\n",
      "RMSE:  0.004456301705215824\n",
      "MAE:  0.0016611758073728459\n",
      "\n",
      "Training support vector machine:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  70 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-3)]: Done 240 out of 240 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "best_score:  -0.00023433945042440927\n",
      "best_model:  SVR(C=0.1, epsilon=10, kernel='linear')\n",
      "best_params:  {'C': 0.1, 'epsilon': 10, 'kernel': 'linear'}\n",
      "RMSE:  0.015381430721325244\n",
      "MAE:  0.014829075969529875\n",
      "\n",
      "Training neural network: \n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[Parallel(n_jobs=-3)]: Done 140 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-3)]: Done 329 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-3)]: Done 378 out of 405 | elapsed:  1.2min remaining:    5.1s\n",
      "best_score:  -3.784801693916872e-05\n",
      "best_model:  MLPRegressor(activation='logistic', hidden_layer_sizes=(10,),\n",
      "             learning_rate='invscaling', learning_rate_init=0.01, max_iter=1000,\n",
      "             shuffle=False)\n",
      "best_params:  {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01}\n",
      "RMSE:  0.0044628414884044796\n",
      "MAE:  0.0017067176124213601\n",
      "[Parallel(n_jobs=-3)]: Done 405 out of 405 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d5c199b9c124efd828cabb1fba45f18"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.3 Compare results for normal vs denoised"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "# compare results for denoised and normal data\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.real_vals_cumprod,'-',label='real vals cumprod',linewidth=3)\n",
    "ax.plot(denoised.time_series_dates[denoised.training_split+denoised.lag_window_length:],denoised.linear_reg_predictions_cumprod,'-',label='linear reg cumprod - denoised')\n",
    "# ax.plot(denoised.time_series_dates[denoised.training_split+denoised.lag_window_length:],denoised.svm_predictions_cumprod,'-',label='svm cumprod - denoised')\n",
    "ax.plot(denoised.time_series_dates[denoised.training_split+denoised.lag_window_length:],denoised.neural_net_predictions_cumprod,'-',label='nn cumprod - denoised')\n",
    "\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.linear_reg_predictions_cumprod,'--',label='linear reg cumprod')\n",
    "# ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.svm_predictions_cumprod,'--',label='svm cumprod')\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.neural_net_predictions_cumprod,'--',label='nn cumprod')\n",
    "\n",
    "ax.set_xticks([normal.time_series_dates[x] for x in range(normal.training_split,len(normal.time_series_dates),28)])\n",
    "ax.tick_params(rotation=30)\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cfc121117ce4d74b2ee60f7e465639f"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.4 transform return predictions back to price data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "When testing denoising methods, we need to compare against predictions without denoising. But once you denoise the original signal, you cant compare the RMSE metric of the denoised results to that of the normal (without denoising) prediction method because these metrics are computed against different based y_true values. So: \n",
    "\n",
    "\n",
    "- 1) transform price to returns\n",
    "- 2) predict returns with and without denoising\n",
    "- 3) convert returns to price and compute rmse, with and without denosing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "# define some new dataframes to hold all data\n",
    "df_normal_results = df_normal.iloc[4521:,:]\n",
    "df_denoised_results = df_denoised.iloc[4521:,:]\n",
    "\n",
    "# no denoising\n",
    "df_normal_results['linear_reg_prices'] = df_normal['Open'][4521] * normal.linear_reg_predictions_cumprod\n",
    "df_normal_results['svm_reg_prices'] = df_normal['Open'][4521] * normal.svm_predictions_cumprod\n",
    "df_normal_results['nn_reg_prices'] = df_normal['Open'][4521] * normal.neural_net_predictions_cumprod\n",
    "\n",
    "# with denoising\n",
    "df_denoised_results['linear_reg_prices'] = df_denoised['Open'][4521] * denoised.linear_reg_predictions_cumprod\n",
    "df_denoised_results['svm_reg_prices'] = df_denoised['Open'][4521] * denoised.svm_predictions_cumprod\n",
    "df_denoised_results['nn_reg_prices'] = df_denoised['Open'][4521] * denoised.neural_net_predictions_cumprod\n",
    "\n",
    "# plot results\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_normal_results['Dates'],df_normal_results['Open'],label='Real open data')\n",
    "\n",
    "plt.plot(df_normal_results['Dates'],df_normal_results['linear_reg_prices'],label='linear normal')\n",
    "# plt.plot(df_normal_results['Dates'],df_normal_results['svm_reg_prices'],label='svm normal')\n",
    "plt.plot(df_normal_results['Dates'],df_normal_results['nn_reg_prices'],label='nn normal')\n",
    "\n",
    "plt.plot(df_normal_results['Dates'],df_denoised_results['linear_reg_prices'],'--',label='linear denoised')\n",
    "# plt.plot(df_normal_results['Dates'],df_denoised_results['svm_reg_prices'],label='svm denoised')\n",
    "plt.plot(df_normal_results['Dates'],df_denoised_results['nn_reg_prices'],'--',label='nn denoised')\n",
    "\n",
    "\n",
    "plt.xticks([df_normal_results['Dates'].iloc[x] for x in range(0,len(df_normal_results['Dates'][:]),28)])\n",
    "plt.tick_params(rotation=30)\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-115-c730201f51f1>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_normal_results['linear_reg_prices'] = df_normal['Open'][4521] * normal.linear_reg_predictions_cumprod\n",
      "<ipython-input-115-c730201f51f1>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_normal_results['svm_reg_prices'] = df_normal['Open'][4521] * normal.svm_predictions_cumprod\n",
      "<ipython-input-115-c730201f51f1>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_normal_results['nn_reg_prices'] = df_normal['Open'][4521] * normal.neural_net_predictions_cumprod\n",
      "<ipython-input-115-c730201f51f1>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_denoised_results['linear_reg_prices'] = df_denoised['Open'][4521] * denoised.linear_reg_predictions_cumprod\n",
      "<ipython-input-115-c730201f51f1>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_denoised_results['svm_reg_prices'] = df_denoised['Open'][4521] * denoised.svm_predictions_cumprod\n",
      "<ipython-input-115-c730201f51f1>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_denoised_results['nn_reg_prices'] = df_denoised['Open'][4521] * denoised.neural_net_predictions_cumprod\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "516da746127744cfa661cad887876b16"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "# compute evaluation metrics: look at RMSE between cummulative gains of real data vs predictions with and without denoising\n",
    "\n",
    "# data\n",
    "y_true = df_normal_results['Open']\n",
    "\n",
    "# no denoising\n",
    "y_pred_1 = df_normal_results['linear_reg_prices']\n",
    "y_pred_2 = df_normal_results['svm_reg_prices']\n",
    "y_pred_3 = df_normal_results['nn_reg_prices']\n",
    "\n",
    "# with denoising\n",
    "y_pred_4 = df_denoised_results['linear_reg_prices']\n",
    "y_pred_5 = df_denoised_results['svm_reg_prices']\n",
    "y_pred_6 = df_denoised_results['nn_reg_prices']\n",
    "\n",
    "# metrics\n",
    "\n",
    "rmse_linear_normal = mean_squared_error(y_true,y_pred_1)\n",
    "rmse_svm_normal = mean_squared_error(y_true,y_pred_2)\n",
    "rmse_ann_normal = mean_squared_error(y_true,y_pred_3)\n",
    "\n",
    "rmse_linear_denoised = mean_squared_error(y_true,y_pred_4)\n",
    "rmse_svn_denoised = mean_squared_error(y_true,y_pred_5)\n",
    "rmse_ann_denoised = mean_squared_error(y_true,y_pred_6)\n",
    "\n",
    "# print metrics\n",
    "print('Linear normal - RMSE cumulatic gains:\\t',rmse_linear_normal**0.5)\n",
    "print('SVM normal - RMSE cumulatic gains:\\t',rmse_svm_normal**0.5)\n",
    "print('ANN normal - RMSE cumulatic gains:\\t',rmse_ann_normal**0.5)\n",
    "\n",
    "print('Linear denoised - RMSE cumulatic gains:\\t',rmse_linear_denoised**0.5)\n",
    "print('SVM denoised - RMSE cumulatic gains:\\t',rmse_svn_denoised**0.5)\n",
    "print('ANN denoised - RMSE cumulatic gains:\\t',rmse_ann_denoised**0.5)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear normal - RMSE cumulatic gains:\t 273.7957156081383\n",
      "SVM normal - RMSE cumulatic gains:\t 73853.8022660274\n",
      "ANN normal - RMSE cumulatic gains:\t 166.67343763907598\n",
      "Linear denoised - RMSE cumulatic gains:\t 178.58542289582076\n",
      "SVM denoised - RMSE cumulatic gains:\t 809173.9539076653\n",
      "ANN denoised - RMSE cumulatic gains:\t 306.7646744121744\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear normal - RMSE cumulatic gains:\t 103.78796952459727\n",
    "SVM normal - RMSE cumulatic gains:\t 2119.0777666368795\n",
    "ANN normal - RMSE cumulatic gains:\t 229.97477972358672\n",
    "Linear denoised - RMSE cumulatic gains:\t 49.60068080046763\n",
    "SVM denoised - RMSE cumulatic gains:\t 14452.351946378596\n",
    "ANN denoised - RMSE cumulatic gains:\t 115.447881267899"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Summary of takeaways from denoising using signal processing techniques:\n",
    "- Question, should you denoise before are after computing returns? \n",
    "    - Fourier transform needs to be computed on stationary signal(the sinusoids continue through infinity ie stationary), therefore you must do returns first?\n",
    "    - Wavelet transform can be computed for non-stationary signals - see nice denosing of s&p 500 open prices\n",
    "\n",
    "- How do we compare forecasting results for different denosing results?\n",
    "    - RMSE or MAE against the denoised signals means we are comparing the forecasting results of fourier and wavelet denoised against different signals?\n",
    "    - If we look at cumulative returns over testing dataset, then do we compare against the original cummulative returns?\n",
    "\n",
    "- Some hyperparameters for wavelet transform:\n",
    "    - type of wavelet, should be chosen based on data, all papers I've read have used the haar wavelet. Sym look better in my results.\n",
    "    - Once the dwt transform is applied then a thresholding approach can be applied to set low coefficients to zero. Then iDWT taken to retrieve denoised signal. This threshold value and type of thresholding are another hyperparameter. \n",
    "    - The level of decomposition is also a hyperparameter. \n",
    "\n",
    "- Some hyperparameters for fourier transform:\n",
    "    - thresholding value of different frequencies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# some random extras"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "import pywt\n",
    "\n",
    "# single level wavelet denoising\n",
    "data = sp_500['Volume'][-2000:]/1e9\n",
    "plt.figure(figsize=(15,5))\n",
    "data.plot()\n",
    "\n",
    "x = np.array(data)                \n",
    "(ca, cd) = pywt.dwt(x, \"sym20\")                \n",
    "cat = pywt.threshold(ca, 0.5, mode=\"hard\")                \n",
    "cdt = pywt.threshold(cd, 0.5, mode=\"soft\")                \n",
    "tx = pywt.idwt(cat, cdt, \"sym20\")\n",
    "\n",
    "plt.plot(sp_500['Volume'][-2000:].index,tx,'-.')\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "401b5912bb684288aab8a1991e0e2e3e"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "pywt.wavelist(kind='discrete')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['bior1.1',\n",
       " 'bior1.3',\n",
       " 'bior1.5',\n",
       " 'bior2.2',\n",
       " 'bior2.4',\n",
       " 'bior2.6',\n",
       " 'bior2.8',\n",
       " 'bior3.1',\n",
       " 'bior3.3',\n",
       " 'bior3.5',\n",
       " 'bior3.7',\n",
       " 'bior3.9',\n",
       " 'bior4.4',\n",
       " 'bior5.5',\n",
       " 'bior6.8',\n",
       " 'coif1',\n",
       " 'coif2',\n",
       " 'coif3',\n",
       " 'coif4',\n",
       " 'coif5',\n",
       " 'coif6',\n",
       " 'coif7',\n",
       " 'coif8',\n",
       " 'coif9',\n",
       " 'coif10',\n",
       " 'coif11',\n",
       " 'coif12',\n",
       " 'coif13',\n",
       " 'coif14',\n",
       " 'coif15',\n",
       " 'coif16',\n",
       " 'coif17',\n",
       " 'db1',\n",
       " 'db2',\n",
       " 'db3',\n",
       " 'db4',\n",
       " 'db5',\n",
       " 'db6',\n",
       " 'db7',\n",
       " 'db8',\n",
       " 'db9',\n",
       " 'db10',\n",
       " 'db11',\n",
       " 'db12',\n",
       " 'db13',\n",
       " 'db14',\n",
       " 'db15',\n",
       " 'db16',\n",
       " 'db17',\n",
       " 'db18',\n",
       " 'db19',\n",
       " 'db20',\n",
       " 'db21',\n",
       " 'db22',\n",
       " 'db23',\n",
       " 'db24',\n",
       " 'db25',\n",
       " 'db26',\n",
       " 'db27',\n",
       " 'db28',\n",
       " 'db29',\n",
       " 'db30',\n",
       " 'db31',\n",
       " 'db32',\n",
       " 'db33',\n",
       " 'db34',\n",
       " 'db35',\n",
       " 'db36',\n",
       " 'db37',\n",
       " 'db38',\n",
       " 'dmey',\n",
       " 'haar',\n",
       " 'rbio1.1',\n",
       " 'rbio1.3',\n",
       " 'rbio1.5',\n",
       " 'rbio2.2',\n",
       " 'rbio2.4',\n",
       " 'rbio2.6',\n",
       " 'rbio2.8',\n",
       " 'rbio3.1',\n",
       " 'rbio3.3',\n",
       " 'rbio3.5',\n",
       " 'rbio3.7',\n",
       " 'rbio3.9',\n",
       " 'rbio4.4',\n",
       " 'rbio5.5',\n",
       " 'rbio6.8',\n",
       " 'sym2',\n",
       " 'sym3',\n",
       " 'sym4',\n",
       " 'sym5',\n",
       " 'sym6',\n",
       " 'sym7',\n",
       " 'sym8',\n",
       " 'sym9',\n",
       " 'sym10',\n",
       " 'sym11',\n",
       " 'sym12',\n",
       " 'sym13',\n",
       " 'sym14',\n",
       " 'sym15',\n",
       " 'sym16',\n",
       " 'sym17',\n",
       " 'sym18',\n",
       " 'sym19',\n",
       " 'sym20']"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  }
 ]
}