{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e1d4880ad13fa2099fc93eba0cb791232af4f1a31a1c632661aaef6a29f2ead6",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Code up class to perform different tasks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive figures\n",
    "%matplotlib widget \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# model evalution metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# predictive models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "source": [
    "# 1.0 Class for univariate one-step ahead forecasting "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class time_series_prediction():\n",
    "\n",
    "    def __init__(self,dates,one_d_time_series,lag_window_length,n_ahead_prediction):\n",
    "\n",
    "        # raw input data + settings for time series -> supervised learning ML problem\n",
    "        self.one_d_time_series = np.array(one_d_time_series)      # time series array, to array ensure index works as expected for class methods\n",
    "        self.time_series_dates = np.array(dates)                  # time stamp / date for each data point\n",
    "        self.lag_window_length = lag_window_length                # length of lag window\n",
    "        self.n_ahead_prediction = n_ahead_prediction              # time ahead to predict\n",
    "\n",
    "        # transfromed data: set after calling .sliding_window_1()\n",
    "        self.input_data = None\n",
    "        self.target_data = None\n",
    "\n",
    "        # testing and training data: set after calling .train_test_split()\n",
    "        self.training_split = None\n",
    "        self.X_test = None\n",
    "        self.X_train = None\n",
    "        self.y_test = None\n",
    "        self.y_train = None\n",
    "\n",
    "        # predictions from various models - set after calling each models training\n",
    "        self.linear_reg_predictions = None\n",
    "        self.svm_predictions = None\n",
    "        self.neural_net_predictions = None\n",
    "        self.naive_predictions = None\n",
    "\n",
    "        # cumprod results from predictions - set after calling .vis_results_time_series()\n",
    "        self.real_vals_cumprod = None\n",
    "        self.linear_reg_predictions_cumprod = None\n",
    "        self.svm_predictions_cumprod = None\n",
    "        self.neural_net_predictions_cumprod = None\n",
    "    \n",
    "\n",
    "# ****************************************************************************************************************\n",
    "    # data wrangling\n",
    "# ****************************************************************************************************************\n",
    "\n",
    "    # method to transfroms 1-D time series to supervised ML problem: one step ahead forecasting   \n",
    "    def sliding_window_1(self,verbose):\n",
    "        # initialize input array\n",
    "        num_rows = len(self.one_d_time_series) - self.lag_window_length\n",
    "        array = np.zeros((num_rows, self.lag_window_length + 1))\n",
    "        \n",
    "        # loop through data and populate array\n",
    "        for i in range(num_rows):\n",
    "            # input features\n",
    "            array[i,0:self.lag_window_length+1] = self.one_d_time_series[i:i+self.lag_window_length+1]\n",
    "            # target feature/s\n",
    "            array[i,-1] = self.one_d_time_series[i+self.lag_window_length]\n",
    "            \n",
    "            if verbose == 1:\n",
    "                # show pattern\n",
    "                print(array[i,0:self.lag_window_length],' : ',array[i,self.lag_window_length])\n",
    "\n",
    "        # save results as a class attribute\n",
    "        self.input_data = array[:,0:self.lag_window_length]\n",
    "        self.target_data = array[:,self.lag_window_length]\n",
    "\n",
    "    # method to perform a training and testing split for dataset with only a single column of target variables\n",
    "    def train_test_split(self,split):\n",
    "        self.training_split = split\n",
    "        self.X_train = self.input_data[0:split,:]\n",
    "        self.X_test = self.input_data[split:,:]\n",
    "        self.y_train = self.target_data[0:split]\n",
    "        self.y_test = self.target_data[split:]\n",
    "\n",
    "    # method to plot testing and training split of data\n",
    "    def test_train_plot(self):\n",
    "        fig, ax = plt.subplots(figsize=(10,5))\n",
    "        ax.plot(self.time_series_dates[0:self.training_split] ,self.one_d_time_series[0:self.training_split],'k-',label='Training data') # replace returns with sp_500 for other data plotting\n",
    "        ax.plot(self.time_series_dates[self.training_split:] ,self.one_d_time_series[self.training_split:],'r-',label='Testing data')\n",
    "        ax.plot(self.time_series_dates[self.training_split+self.lag_window_length:] ,self.y_test,'o',label='Windowed testing data') # important to match time by start 5 (length of time window) after where segmented our testing and training data\n",
    "        plt.legend(loc=0) \n",
    "        ax.set_xticks([self.time_series_dates[x] for x in range(0,len(self.time_series_dates),150)])\n",
    "        ax.tick_params(rotation=30) \n",
    "        plt.tight_layout()\n",
    "\n",
    "# ****************************************************************************************************************\n",
    "    # predictive models\n",
    "# ****************************************************************************************************************\n",
    "\n",
    "    def linear_regression(self):\n",
    "        print('Training multivariate linear regression:')\n",
    "        # train model\n",
    "        reg_model = LinearRegression().fit(self.X_train,self.y_train)\n",
    "        print('\\nLinear regression coefficients: \\n',reg_model.coef_)\n",
    "\n",
    "        # test model\n",
    "        predictions = reg_model.predict(self.X_test)\n",
    "\n",
    "        # evaluate: use sklearn metric methods to calc rmse and mae\n",
    "        mse = mean_squared_error(self.y_test,predictions)\n",
    "        mae = mean_absolute_error(self.y_test,predictions)\n",
    "\n",
    "        print('RMSE: ',np.sqrt(mse))\n",
    "        print('MAE: ',mae)\n",
    "\n",
    "        # save predictions\n",
    "        self.linear_reg_predictions = predictions\n",
    "\n",
    "    def support_vector_machine(self):\n",
    "        print('\\nTraining support vector machine:')\n",
    "        # train model\n",
    "        svm_regres = LinearSVR(max_iter=1000,C=0.5).fit(self.X_train,self.y_train)\n",
    "\n",
    "        # predict\n",
    "        svm_predictions = svm_regres.predict(self.X_test)\n",
    "\n",
    "        # evaluate\n",
    "        mse = mean_squared_error(self.y_test,svm_predictions[:])\n",
    "        mae = mean_absolute_error(self.y_test,svm_predictions[:])\n",
    "\n",
    "        print('RMSE: ',np.sqrt(mse))\n",
    "        print('MAE: ',mae)\n",
    "\n",
    "        # save predictions\n",
    "        self.svm_predictions = svm_predictions\n",
    "\n",
    "    def neural_net_mlp(self,verbose=0):\n",
    "        print('\\nTraining neural network: ')\n",
    "        # train neural network\n",
    "        nn_regres = MLPRegressor(hidden_layer_sizes=(20),shuffle=False,random_state=1, \n",
    "                                max_iter=1000,verbose=verbose).fit(self.X_train,self.y_train)\n",
    "\n",
    "        # make predictions\n",
    "        nn_predictions = nn_regres.predict(self.X_test)\n",
    "\n",
    "        # evaluate\n",
    "        mse = mean_squared_error(self.y_test,nn_predictions[:])\n",
    "        mae = mean_absolute_error(self.y_test,nn_predictions[:])\n",
    "\n",
    "        print('RMSE: ',np.sqrt(mse))\n",
    "        print('MAE: ',mae)\n",
    "\n",
    "        # save predictions\n",
    "        self.neural_net_predictions = nn_predictions\n",
    "\n",
    "    def naive_model(self): # t's prediction is t-1's value, note that this means you miss the first time point\n",
    "        preds = np.zeros(len(self.one_d_time_series)-1)\n",
    "        preds[0] = np.nan()\n",
    "        preds[1:] = self.one_d_time_series[0:-2]\n",
    "        self.naive_predictions = preds\n",
    "\n",
    "# ****************************************************************************************************************\n",
    "    # visualize results\n",
    "# ****************************************************************************************************************\n",
    "    def error(self,real_data,predicted_data):\n",
    "        error = np.zeros(len(real_data))\n",
    "        error = (real_data - predicted_data) / real_data\n",
    "        return error\n",
    "\n",
    "    # visualize orignal time series signal aswell as predictions    \n",
    "    def vis_results_time_series(self,second_plot='error'):\n",
    "        # plot prediction against actual + training data\n",
    "        fig, ax = plt.subplots(2,1,figsize=(10,7),sharex=True)\n",
    "\n",
    "        # original time series\n",
    "        ax[0].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.one_d_time_series[self.training_split+self.lag_window_length:],'o-',linewidth=3,label='real values',markersize=5) \n",
    "\n",
    "        # predicted y values\n",
    "        ax[0].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.linear_reg_predictions,'o-',label='linear regression prediction',markersize=5)\n",
    "        # ax[0].plot(self.time_series_dates,self.naive_predictions,'.--',label='naive prediction',markersize=5)\n",
    "        ax[0].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.svm_predictions,'.--',label='svm prediction',markersize=5)\n",
    "        ax[0].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.neural_net_predictions,'.--',label='nn prediction',markersize=5)\n",
    "\n",
    "        ax[0].legend()\n",
    "        ax[0].set_title('Real values vs model predictions')\n",
    "\n",
    "        # plot error plot\n",
    "        if second_plot == 'error':\n",
    "            error_linreg = self.error(self.y_test,self.linear_reg_predictions)\n",
    "            # error_naive = error(np.array(test_data[:,-1]),naive_predictions)\n",
    "            error_svm = self.error(self.y_test,self.svm_predictions)\n",
    "            error_nn = self.error(self.y_test,self.neural_net_predictions)\n",
    "\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],error_linreg,'r-',label='linear reg error')\n",
    "            # ax[1].plot(self.time_series_dates,error_naive[1:],'-',label='naive error')\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],error_svm,'-',label='svm error')\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],error_nn,'-',label='nn error')\n",
    "            ax[1].set_title('Error signal for predictive models')\n",
    "            ax[1].set_xlabel('Dates')\n",
    "            ax[1].legend()\n",
    "            # ax[1].set_ylim([-10,10])\n",
    "            ax[1].set_xticks([self.time_series_dates[x] for x in range(self.training_split,len(self.time_series_dates),28)])\n",
    "            ax[1].tick_params(rotation=30)\n",
    "        \n",
    "        elif second_plot == 'cumprod':\n",
    "\n",
    "            # plot cummulative prod plots - this should only be done if input data is percentage retunrs\n",
    "            self.real_vals_cumprod = (self.y_test+1).cumprod()\n",
    "            self.linear_reg_predictions_cumprod = (self.linear_reg_predictions + 1).cumprod()\n",
    "            self.svm_predictions_cumprod = (self.svm_predictions + 1).cumprod()\n",
    "            self.neural_net_predictions_cumprod = (self.neural_net_predictions + 1).cumprod()\n",
    "\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.real_vals_cumprod,'-',label='real vals cumprod')\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.linear_reg_predictions_cumprod,'-',label='linear reg cumprod')\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.svm_predictions_cumprod,'-',label='svm cumprod')\n",
    "            ax[1].plot(self.time_series_dates[self.training_split+self.lag_window_length:],self.neural_net_predictions_cumprod,'-',label='nn cumprod')\n",
    "\n",
    "            ax[1].set_xticks([self.time_series_dates[x] for x in range(self.training_split,len(self.time_series_dates),28)])\n",
    "            ax[1].tick_params(rotation=30)\n",
    "            ax[1].legend()\n",
    "\n",
    "        # titles and save figures\n",
    "        # title_string = 'S&P500 predictions _ y is '+str(column)+'_ window len is '+ str(window_length)\n",
    "        # fig.suptitle(title_string)\n",
    "        \n",
    "        # fig_name = '../results/univariate_single_step_ahead/'+title_string+'.png'\n",
    "        # plt.savefig(fig_name,facecolor='w')\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # visualize predictions against real values using scatter plot\n",
    "    def vis_results_scatter(self):\n",
    "\n",
    "        # create dataframe to hold all results\n",
    "        df_predictions = pd.DataFrame(index=self.time_series_dates[self.training_split+self.lag_window_length:],columns=['Real_values','linear_reg_predictions','svm_predictions','neural_net_predictions'])\n",
    "        df_predictions['Real_values'] = self.y_test\n",
    "        df_predictions['linear_reg_predictions'] = self.linear_reg_predictions\n",
    "        df_predictions['svm_predictions'] = self.svm_predictions\n",
    "        df_predictions['neural_net_predictions'] = self.neural_net_predictions\n",
    "\n",
    "        # scatter plot with hues\n",
    "        fig, ax = plt.subplots(3,1,figsize=(7,10))\n",
    "        sns.scatterplot(y=df_predictions['Real_values'],x=df_predictions['linear_reg_predictions'],ax=ax[0])\n",
    "        sns.lineplot(x=self.y_test,y=self.y_test,ax=ax[0],color='red')\n",
    "\n",
    "        sns.scatterplot(y=df_predictions['Real_values'],x=df_predictions['svm_predictions'],ax=ax[1])\n",
    "        sns.lineplot(x=self.y_test,y=self.y_test,ax=ax[1],color='red')\n",
    "\n",
    "        sns.scatterplot(y=df_predictions['Real_values'],x=df_predictions['neural_net_predictions'],ax=ax[2])\n",
    "        sns.lineplot(x=self.y_test,y=self.y_test,ax=ax[2],color='red')\n",
    "\n",
    "        # plot formatting\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "source": [
    "# 2.0 Import some test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Date         Open         High          Low        Close  \\\n",
       "0      1950-01-03    16.660000    16.660000    16.660000    16.660000   \n",
       "1      1950-01-04    16.850000    16.850000    16.850000    16.850000   \n",
       "2      1950-01-05    16.930000    16.930000    16.930000    16.930000   \n",
       "3      1950-01-06    16.980000    16.980000    16.980000    16.980000   \n",
       "4      1950-01-09    17.080000    17.080000    17.080000    17.080000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "17213  2018-05-31  2720.979980  2722.500000  2700.679932  2705.270020   \n",
       "17214  2018-06-01  2718.699951  2736.929932  2718.699951  2734.620117   \n",
       "17215  2018-06-04  2741.669922  2749.159912  2740.540039  2746.870117   \n",
       "17216  2018-06-05  2748.459961  2752.610107  2739.510010  2748.800049   \n",
       "17217  2018-06-06  2753.250000  2772.389893  2748.459961  2772.350098   \n",
       "\n",
       "         Adj Close      Volume  \n",
       "0        16.660000     1260000  \n",
       "1        16.850000     1890000  \n",
       "2        16.930000     2550000  \n",
       "3        16.980000     2010000  \n",
       "4        17.080000     2520000  \n",
       "...            ...         ...  \n",
       "17213  2705.270020  4235370000  \n",
       "17214  2734.620117  3684130000  \n",
       "17215  2746.870117  3376510000  \n",
       "17216  2748.800049  3517790000  \n",
       "17217  2772.350098  3651640000  \n",
       "\n",
       "[17218 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1950-01-03</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>16.660000</td>\n      <td>1260000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1950-01-04</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>16.850000</td>\n      <td>1890000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1950-01-05</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>16.930000</td>\n      <td>2550000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1950-01-06</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>16.980000</td>\n      <td>2010000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1950-01-09</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>17.080000</td>\n      <td>2520000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17213</th>\n      <td>2018-05-31</td>\n      <td>2720.979980</td>\n      <td>2722.500000</td>\n      <td>2700.679932</td>\n      <td>2705.270020</td>\n      <td>2705.270020</td>\n      <td>4235370000</td>\n    </tr>\n    <tr>\n      <th>17214</th>\n      <td>2018-06-01</td>\n      <td>2718.699951</td>\n      <td>2736.929932</td>\n      <td>2718.699951</td>\n      <td>2734.620117</td>\n      <td>2734.620117</td>\n      <td>3684130000</td>\n    </tr>\n    <tr>\n      <th>17215</th>\n      <td>2018-06-04</td>\n      <td>2741.669922</td>\n      <td>2749.159912</td>\n      <td>2740.540039</td>\n      <td>2746.870117</td>\n      <td>2746.870117</td>\n      <td>3376510000</td>\n    </tr>\n    <tr>\n      <th>17216</th>\n      <td>2018-06-05</td>\n      <td>2748.459961</td>\n      <td>2752.610107</td>\n      <td>2739.510010</td>\n      <td>2748.800049</td>\n      <td>2748.800049</td>\n      <td>3517790000</td>\n    </tr>\n    <tr>\n      <th>17217</th>\n      <td>2018-06-06</td>\n      <td>2753.250000</td>\n      <td>2772.389893</td>\n      <td>2748.459961</td>\n      <td>2772.350098</td>\n      <td>2772.350098</td>\n      <td>3651640000</td>\n    </tr>\n  </tbody>\n</table>\n<p>17218 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# import some data\n",
    "sp_500 = pd.read_csv('../test_data/GSPC.csv')\n",
    "sp_500"
   ]
  },
  {
   "source": [
    "# 3.0 Example of using class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19f5f6a7ed05454db3b7ef27cd4885ee"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# initialize class object\n",
    "normal = time_series_prediction(sp_500['Date'][-2000:],sp_500['Volume'][-2000:]/1e9,5,1) # pass time series, lag window length, a number of steps ahead to predict\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised learning ML problem\n",
    "normal.train_test_split(split=1200) # testing and training dataset split\n",
    "normal.test_train_plot()    # visualize training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [0.10077061 0.04071057 0.03651907 0.14864236 0.43403925]\n",
      "RMSE:  0.5491520347058507\n",
      "MAE:  0.366115072166878\n",
      "\n",
      "Training support vector machine:\n",
      "RMSE:  0.5535767665711491\n",
      "MAE:  0.363937042880904\n",
      "\n",
      "Training neural network: \n",
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "RMSE:  0.5542544123599602\n",
      "MAE:  0.3655117729032284\n"
     ]
    }
   ],
   "source": [
    "# perform some prediction tasks\n",
    "normal.linear_regression()\n",
    "normal.support_vector_machine()\n",
    "normal.neural_net_mlp()\n",
    "# normal.naive_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77297ee8464548128265462086100324"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "normal.vis_results_time_series(second_plot='error')"
   ]
  },
  {
   "source": [
    "- even with the volume data which seems more stationary than open price data, the forecasts are still dominated by t-1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted vs real value scatter plots\n",
    "# normal.vis_results_scatter()"
   ]
  },
  {
   "source": [
    "# Play around with Zander's standardization stuff"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85a151a96222410084135a80e22b47d0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Dates         Open  pct_change  pct_change_cumprod  log_transform\n",
       "0     2010-06-28  1077.500000    0.000000            1.000000       6.982399\n",
       "1     2010-06-29  1071.099976   -0.005940            0.994060       6.976441\n",
       "2     2010-06-30  1040.560059   -0.028513            0.965717       6.947514\n",
       "3     2010-07-01  1031.099976   -0.009091            0.956937       6.938381\n",
       "4     2010-07-02  1027.650024   -0.003346            0.953736       6.935030\n",
       "...          ...          ...         ...                 ...            ...\n",
       "1995  2018-05-31  2720.979980    0.006864            2.525271       7.908747\n",
       "1996  2018-06-01  2718.699951   -0.000838            2.523155       7.907909\n",
       "1997  2018-06-04  2741.669922    0.008449            2.544473       7.916322\n",
       "1998  2018-06-05  2748.459961    0.002477            2.550775       7.918796\n",
       "1999  2018-06-06  2753.250000    0.001743            2.555220       7.920537\n",
       "\n",
       "[2000 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dates</th>\n      <th>Open</th>\n      <th>pct_change</th>\n      <th>pct_change_cumprod</th>\n      <th>log_transform</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-06-28</td>\n      <td>1077.500000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>6.982399</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-06-29</td>\n      <td>1071.099976</td>\n      <td>-0.005940</td>\n      <td>0.994060</td>\n      <td>6.976441</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-06-30</td>\n      <td>1040.560059</td>\n      <td>-0.028513</td>\n      <td>0.965717</td>\n      <td>6.947514</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-07-01</td>\n      <td>1031.099976</td>\n      <td>-0.009091</td>\n      <td>0.956937</td>\n      <td>6.938381</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-07-02</td>\n      <td>1027.650024</td>\n      <td>-0.003346</td>\n      <td>0.953736</td>\n      <td>6.935030</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>2018-05-31</td>\n      <td>2720.979980</td>\n      <td>0.006864</td>\n      <td>2.525271</td>\n      <td>7.908747</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>2018-06-01</td>\n      <td>2718.699951</td>\n      <td>-0.000838</td>\n      <td>2.523155</td>\n      <td>7.907909</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>2018-06-04</td>\n      <td>2741.669922</td>\n      <td>0.008449</td>\n      <td>2.544473</td>\n      <td>7.916322</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>2018-06-05</td>\n      <td>2748.459961</td>\n      <td>0.002477</td>\n      <td>2.550775</td>\n      <td>7.918796</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>2018-06-06</td>\n      <td>2753.250000</td>\n      <td>0.001743</td>\n      <td>2.555220</td>\n      <td>7.920537</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# some misc data\n",
    "x = sp_500['Open'][-2000:]\n",
    "dates = sp_500['Date'][-2000:]\n",
    "# percentage returns\n",
    "x_pct = x.pct_change().fillna(0)\n",
    "x_pct\n",
    "\n",
    "# create new df hold both\n",
    "df = pd.DataFrame(columns=['Dates','Open','pct_change','pct_change_cumprod','log_transform'])\n",
    "df['Dates'] = dates\n",
    "df['Open'] =  x\n",
    "df['pct_change'] = x_pct\n",
    "df['pct_change_cumprod'] = (x_pct + 1).cumprod()\n",
    "df['log_transform'] = np.log(df['Open'] )\n",
    "\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# plot\n",
    "df.plot(subplots=True,sharex=True,figsize=(7,7))\n",
    "plt.tight_layout()\n",
    "\n",
    "# view data\n",
    "df"
   ]
  },
  {
   "source": [
    "- unsure what the log transform is required for"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1477db8c3662463bbc12f972efc46124"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "normal = time_series_prediction(df['Dates'],df['pct_change'],10,1) # pass time series, lag window length, a number of steps ahead to predict\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised learning ML problem\n",
    "normal.train_test_split(split=1500) # testing and training dataset split\n",
    "normal.test_train_plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [ 0.0399997  -0.03879977 -0.00294204 -0.00418228 -0.00415419 -0.0923927\n",
      " -0.0174214  -0.07352073  0.02916561 -0.01048691]\n",
      "RMSE:  0.006783875497107386\n",
      "MAE:  0.00434815357749492\n",
      "\n",
      "Training support vector machine:\n",
      "RMSE:  0.006664687686071732\n",
      "MAE:  0.004260153648427088\n",
      "\n",
      "Training neural network: \n",
      "RMSE:  0.007033618242642029\n",
      "MAE:  0.004595420014010832\n",
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# perform some prediction tasks\n",
    "normal.linear_regression()\n",
    "normal.support_vector_machine()\n",
    "normal.neural_net_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08af56ff087846869f683b8049704b1a"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "normal.vis_results_time_series(second_plot='cumprod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted vs real value scatter plots\n",
    "# normal.vis_results_scatter()"
   ]
  },
  {
   "source": [
    "# Try denoising use fft "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy fft functions\n",
    "from scipy.fft import fft, ifft, fftfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.01462727-0.j        , 0.07742948-0.12909129j,\n",
       "       0.08978698+0.29639753j, ..., 0.02326016+0.07084956j,\n",
       "       0.08978698-0.29639753j, 0.07742948+0.12909129j])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# apply discrete fourier transform\n",
    "signal = np.array(df['pct_change'])#np.array(sp_500['Open'][-2000:])\n",
    "fft_coefficients = fft(signal)\n",
    "fft_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "166efa2d7957446aa83460eda145071c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Frequencies')"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# plot amplitude vs frequency \n",
    "n = len(signal)\n",
    "\n",
    "# get frequencies and psd\n",
    "freqs = fftfreq(signal.shape[0])\n",
    "psd = np.abs(fft_coefficients)/n # psd is amplitude/N\n",
    "\n",
    "# plot psd\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(freqs[0:int(n/2)],psd[0:int(n/2)])\n",
    "ax.set_ylabel('Power spectrum')\n",
    "ax.set_xlabel('Frequencies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97a4995f3a78450d9439e373797b6308"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# plot inverse fourier transform as sanity check\n",
    "inverse_fft = ifft(fft_coefficients)\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(range(0,len(inverse_fft)),inverse_fft,'-',label='Inverse fourier')\n",
    "ax.plot(range(0,len(inverse_fft)),signal,'.',label='Real data')\n",
    "ax.legend()\n",
    "ax.tick_params(rotation=30)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b677d749db3445b0a1e0656c2d48a676"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# try denoise data\n",
    "psd_indices = psd > 0.0004 # mask\n",
    "fft_filtered = fft_coefficients*psd_indices\n",
    "\n",
    "inverse_transform_filtered = ifft(fft_filtered)\n",
    "\n",
    "# plot this\n",
    "fig,ax = plt.subplots(figsize=(12,5))\n",
    "ax.plot(range(0,len(inverse_fft)),signal,'-',label='Real data')\n",
    "ax.plot(range(0,len(inverse_fft)),inverse_transform_filtered,'-',label='Inverse fourier filtered')\n",
    "ax.legend()\n",
    "ax.tick_params(rotation=30)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "source": [
    "## now train on filtered data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-2-c0288e7c1238>:48: ComplexWarning: Casting complex values to real discards the imaginary part\n  array[i,0:self.lag_window_length+1] = self.one_d_time_series[i:i+self.lag_window_length+1]\n<ipython-input-2-c0288e7c1238>:50: ComplexWarning: Casting complex values to real discards the imaginary part\n  array[i,-1] = self.one_d_time_series[i+self.lag_window_length]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d628b8aad0624aecbbd3af4ac9655227"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n  return array(a, dtype, copy=False, order=order)\nC:\\Users\\tristan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "fft_denoised = time_series_prediction(df['Dates'],inverse_transform_filtered,10,1) # pass time series, lag window length, a number of steps ahead to predict\n",
    "fft_denoised.sliding_window_1(verbose=0) # time series to supervised learning ML problem\n",
    "fft_denoised.train_test_split(split=1500) # testing and training dataset split\n",
    "fft_denoised.test_train_plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [-0.06694886  0.00248511 -0.54125478  0.36460841 -0.51534226  0.19963451\n",
      " -0.72572638  0.26936598 -0.63479409  0.28630021]\n",
      "RMSE:  0.0020272530362578436\n",
      "MAE:  0.0015866217625426359\n",
      "\n",
      "Training support vector machine:\n",
      "RMSE:  0.0023151390174558136\n",
      "MAE:  0.001827396063214591\n",
      "\n",
      "Training neural network: \n",
      "RMSE:  0.002971738483058432\n",
      "MAE:  0.0023715682383264676\n",
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# perform some prediction tasks\n",
    "fft_denoised.linear_regression()\n",
    "fft_denoised.support_vector_machine()\n",
    "fft_denoised.neural_net_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9610c4580d0043f59ad6898372ad65c0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "fft_denoised.vis_results_time_series(second_plot='cumprod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd5113e76a5d4a9e9404e3ac033fadcd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1eb6f98bbe0>"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "# compare results for denoised and normal data\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.real_vals_cumprod,'-',label='real vals cumprod')\n",
    "ax.plot(fft_denoised.time_series_dates[fft_denoised.training_split+fft_denoised.lag_window_length:],fft_denoised.linear_reg_predictions_cumprod,'-',label='linear reg cumprod - denoised')\n",
    "ax.plot(fft_denoised.time_series_dates[fft_denoised.training_split+fft_denoised.lag_window_length:],fft_denoised.svm_predictions_cumprod,'-',label='svm cumprod - denoised')\n",
    "ax.plot(fft_denoised.time_series_dates[fft_denoised.training_split+fft_denoised.lag_window_length:],fft_denoised.neural_net_predictions_cumprod,'-',label='nn cumprod - denoised')\n",
    "\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.linear_reg_predictions_cumprod,'--',label='linear reg cumprod')\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.svm_predictions_cumprod,'--',label='svm cumprod')\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.neural_net_predictions_cumprod,'--',label='nn cumprod')\n",
    "\n",
    "ax.set_xticks([normal.time_series_dates[x] for x in range(normal.training_split,len(normal.time_series_dates),28)])\n",
    "ax.tick_params(rotation=30)\n",
    "ax.legend()"
   ]
  },
  {
   "source": [
    "# Wavelet denoising"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da39496f931d4a39a8a19cf29a38c1c9"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "import pywt\n",
    "\n",
    "# single level wavelet denoising\n",
    "data = sp_500['Volume'][-2000:]/1e9\n",
    "plt.figure(figsize=(15,5))\n",
    "data.plot()\n",
    "\n",
    "x = np.array(data)                \n",
    "(ca, cd) = pywt.dwt(x, \"sym20\")                \n",
    "cat = pywt.threshold(ca, 0.5, mode=\"hard\")                \n",
    "cdt = pywt.threshold(cd, 0.5, mode=\"soft\")                \n",
    "tx = pywt.idwt(cat, cdt, \"sym20\")\n",
    "\n",
    "plt.plot(sp_500['Volume'][-2000:].index,tx,'-.')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['bior1.1',\n",
       " 'bior1.3',\n",
       " 'bior1.5',\n",
       " 'bior2.2',\n",
       " 'bior2.4',\n",
       " 'bior2.6',\n",
       " 'bior2.8',\n",
       " 'bior3.1',\n",
       " 'bior3.3',\n",
       " 'bior3.5',\n",
       " 'bior3.7',\n",
       " 'bior3.9',\n",
       " 'bior4.4',\n",
       " 'bior5.5',\n",
       " 'bior6.8',\n",
       " 'coif1',\n",
       " 'coif2',\n",
       " 'coif3',\n",
       " 'coif4',\n",
       " 'coif5',\n",
       " 'coif6',\n",
       " 'coif7',\n",
       " 'coif8',\n",
       " 'coif9',\n",
       " 'coif10',\n",
       " 'coif11',\n",
       " 'coif12',\n",
       " 'coif13',\n",
       " 'coif14',\n",
       " 'coif15',\n",
       " 'coif16',\n",
       " 'coif17',\n",
       " 'db1',\n",
       " 'db2',\n",
       " 'db3',\n",
       " 'db4',\n",
       " 'db5',\n",
       " 'db6',\n",
       " 'db7',\n",
       " 'db8',\n",
       " 'db9',\n",
       " 'db10',\n",
       " 'db11',\n",
       " 'db12',\n",
       " 'db13',\n",
       " 'db14',\n",
       " 'db15',\n",
       " 'db16',\n",
       " 'db17',\n",
       " 'db18',\n",
       " 'db19',\n",
       " 'db20',\n",
       " 'db21',\n",
       " 'db22',\n",
       " 'db23',\n",
       " 'db24',\n",
       " 'db25',\n",
       " 'db26',\n",
       " 'db27',\n",
       " 'db28',\n",
       " 'db29',\n",
       " 'db30',\n",
       " 'db31',\n",
       " 'db32',\n",
       " 'db33',\n",
       " 'db34',\n",
       " 'db35',\n",
       " 'db36',\n",
       " 'db37',\n",
       " 'db38',\n",
       " 'dmey',\n",
       " 'haar',\n",
       " 'rbio1.1',\n",
       " 'rbio1.3',\n",
       " 'rbio1.5',\n",
       " 'rbio2.2',\n",
       " 'rbio2.4',\n",
       " 'rbio2.6',\n",
       " 'rbio2.8',\n",
       " 'rbio3.1',\n",
       " 'rbio3.3',\n",
       " 'rbio3.5',\n",
       " 'rbio3.7',\n",
       " 'rbio3.9',\n",
       " 'rbio4.4',\n",
       " 'rbio5.5',\n",
       " 'rbio6.8',\n",
       " 'sym2',\n",
       " 'sym3',\n",
       " 'sym4',\n",
       " 'sym5',\n",
       " 'sym6',\n",
       " 'sym7',\n",
       " 'sym8',\n",
       " 'sym9',\n",
       " 'sym10',\n",
       " 'sym11',\n",
       " 'sym12',\n",
       " 'sym13',\n",
       " 'sym14',\n",
       " 'sym15',\n",
       " 'sym16',\n",
       " 'sym17',\n",
       " 'sym18',\n",
       " 'sym19',\n",
       " 'sym20']"
      ]
     },
     "metadata": {},
     "execution_count": 407
    }
   ],
   "source": [
    "pywt.wavelist(kind='discrete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "maximum level is 7\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "998694bb5aaa46c2bd1ffa87b16633f9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf311f432d7a4f47af2d496567b0a11e"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import sys\n",
    "\n",
    "# Data format:\n",
    "# Raw data should be in a .txt file with two columns, separated by tabs:\n",
    "#  - The first column should be a time-series index\n",
    "#  - The second column should contain the data to be filtered\n",
    "\n",
    "# Get data:\n",
    "data = sp_500['Open'][-2000:]#/1e9\n",
    "index = sp_500['Open'][-2000:].index\n",
    "\n",
    "# Create wavelet object and define parameters\n",
    "w = pywt.Wavelet('sym8') # sym family look good too\n",
    "maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
    "# maxlev = 1 # Override if desired\n",
    "print(\"maximum level is \" + str(maxlev))\n",
    "threshold = 0.5 # Threshold for filtering\n",
    "\n",
    "# Decompose into wavelet components, to the level selected:\n",
    "coeffs = pywt.wavedec(data, w, level=maxlev)\n",
    "\n",
    "plt.figure(figsize=(8,15))\n",
    "for i in range(1, len(coeffs)):\n",
    "    plt.subplot(maxlev, 1, i)\n",
    "    plt.plot(coeffs[i],label='Original coefficients')\n",
    "    coeffs[i] = pywt.threshold(coeffs[i], threshold*max(coeffs[i]),mode='hard')\n",
    "    plt.plot(coeffs[i],label='Thresholded coefficients')\n",
    "    plt.ylabel('Scale: '+str(maxlev-i+1))\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "datarec = pywt.waverec(coeffs, w)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(index, data,label='Raw signal')\n",
    "plt.plot(index, datarec,label=\"De-noised signal using wavelet techniques\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "so first perform a wavelet transform of the open data then computes returns and do forecasting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create new df for normal data\n",
    "df_normal = pd.DataFrame(columns=['Dates','Open','pct_change','pct_change_cumprod'])\n",
    "df_normal['Dates'] = sp_500['Date'][-2000:]\n",
    "df_normal['Open'] =   sp_500['Open'][-2000:]\n",
    "df_normal['pct_change'] = df_normal['Open'].pct_change().fillna(0)\n",
    "df_normal['pct_change_cumprod'] = (df_normal['pct_change']  + 1).cumprod()\n",
    "\n",
    "df_normal.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# create new df for wavelet denoised data\n",
    "df_denoised= pd.DataFrame(columns=['Dates','Open','pct_change','pct_change_cumprod'])\n",
    "df_denoised['Dates'] = sp_500['Date'][-2000:]\n",
    "df_denoised['Open'] =   datarec\n",
    "df_denoised['pct_change'] = df_denoised['Open'].pct_change().fillna(0)\n",
    "df_denoised['pct_change_cumprod'] = (df_denoised['pct_change']  + 1).cumprod()\n",
    "\n",
    "df_denoised.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84c719332ddf4558a63f459dcfae88fb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [-0.10334584 -0.01491812 -0.07344753  0.03088411 -0.01014383]\n",
      "RMSE:  0.006749482367231604\n",
      "MAE:  0.004326723581147357\n",
      "\n",
      "Training support vector machine:\n",
      "RMSE:  0.006648038074642522\n",
      "MAE:  0.0042460717215129316\n",
      "\n",
      "Training neural network: \n",
      "RMSE:  0.0066358447310458785\n",
      "MAE:  0.004320974885499472\n",
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa4fbefe266d48e1beef3fb72aa493c8"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "########################################################################\n",
    "# forecasting on normal data\n",
    "########################################################################\n",
    "\n",
    "normal = time_series_prediction(df_normal['Dates'],df_normal['pct_change'],5,1) # pass time series, lag window length, a number of steps ahead to predict\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised learning ML problem\n",
    "normal.train_test_split(split=1500) # testing and training dataset split\n",
    "normal.test_train_plot()    # visualize training split\n",
    "\n",
    "# perform some prediction tasks\n",
    "normal.linear_regression()\n",
    "normal.support_vector_machine()\n",
    "normal.neural_net_mlp()\n",
    "\n",
    "#visualize results\n",
    "normal.vis_results_time_series(second_plot='cumprod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1dd6cee52984559aec6c223493ba88d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [ 0.03753123 -0.15570638 -0.07851535  0.14137091  0.25596489]\n",
      "RMSE:  0.0048424349108406465\n",
      "MAE:  0.0017908449987325303\n",
      "\n",
      "Training support vector machine:\n",
      "RMSE:  0.004947773368530203\n",
      "MAE:  0.0015063315082727289\n",
      "\n",
      "Training neural network: \n",
      "RMSE:  0.004466321693126055\n",
      "MAE:  0.002059845947976687\n",
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a092de147eb94f3aa4c5ac0db825c222"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "########################################################################\n",
    "# forecasting on denoised data\n",
    "########################################################################\n",
    "\n",
    "denoised = time_series_prediction(df_denoised['Dates'],df_denoised['pct_change'],5,1) # pass time series, lag window length, a number of steps ahead to predict\n",
    "denoised.sliding_window_1(verbose=0) # time series to supervised learning ML problem\n",
    "denoised.train_test_split(split=1500) # testing and training dataset split\n",
    "denoised.test_train_plot() \n",
    "\n",
    "# perform some prediction tasks\n",
    "denoised.linear_regression()\n",
    "denoised.support_vector_machine()\n",
    "denoised.neural_net_mlp()\n",
    "\n",
    "#visualize results\n",
    "denoised.vis_results_time_series(second_plot='cumprod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9970b82e3449410f9118116e4d56adea"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# compare results for denoised and normal data\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.real_vals_cumprod,'-',label='real vals cumprod',linewidth=3)\n",
    "ax.plot(denoised.time_series_dates[denoised.training_split+denoised.lag_window_length:],denoised.linear_reg_predictions_cumprod,'-',label='linear reg cumprod - denoised')\n",
    "ax.plot(denoised.time_series_dates[denoised.training_split+denoised.lag_window_length:],denoised.svm_predictions_cumprod,'-',label='svm cumprod - denoised')\n",
    "ax.plot(denoised.time_series_dates[denoised.training_split+denoised.lag_window_length:],denoised.neural_net_predictions_cumprod,'-',label='nn cumprod - denoised')\n",
    "\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.linear_reg_predictions_cumprod,'--',label='linear reg cumprod')\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.svm_predictions_cumprod,'--',label='svm cumprod')\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.neural_net_predictions_cumprod,'--',label='nn cumprod')\n",
    "\n",
    "ax.set_xticks([normal.time_series_dates[x] for x in range(normal.training_split,len(normal.time_series_dates),28)])\n",
    "ax.tick_params(rotation=30)\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "source": [
    "Summary of takeaways from denoising using signal processing techniques:\n",
    "- Question, should you denoise before are after computing returns? \n",
    "    - Fourier transform needs to be computed on stationary signal(the sinusoids continue through infinity ie stationary), therefore you must do returns first?\n",
    "    - Wavelet transform can be computed for non-stationary signals - see nice denosing of s&p 500 open prices\n",
    "\n",
    "- How do we compare forecasting results for different denosing results?\n",
    "    - RMSE or MAE against the denoised signals means we are comparing the forecasting results of fourier and wavelet denoised against different signals?\n",
    "    - If we look at cumulative returns over testing dataset, then do we compare against the original cummulative returns?\n",
    "\n",
    "- Some hyperparameters for wavelet transform:\n",
    "    - type of wavelet, should be chosen based on data, all papers I've read have used the haar wavelet. Sym look better in my results.\n",
    "    - Once the dwt transform is applied then a thresholding approach can be applied to set low coefficients to zero. Then iDWT taken to retrieve denoised signal. This threshold value and type of thresholding are another hyperparameter. \n",
    "    - The level of decomposition is also a hyperparameter. \n",
    "\n",
    "- Some hyperparameters for fourier transform:\n",
    "    - thresholding value of different frequencies."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}