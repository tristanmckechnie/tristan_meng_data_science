{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "e1d4880ad13fa2099fc93eba0cb791232af4f1a31a1c632661aaef6a29f2ead6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Code up class to perform different tasks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# interactive figures\r\n",
    "%matplotlib widget \r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# ml training code\r\n",
    "from one_dimensional_time_series_forecasting import time_series_prediction\r\n",
    "from one_dimensional_time_series_forecasting import hit_rate\r\n",
    "\r\n",
    "# model evalution metrics\r\n",
    "from sklearn.metrics import mean_absolute_error\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "\r\n",
    "# data preprocessing\r\n",
    "from sklearn.preprocessing import normalize\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "df = pd.read_csv('./test_data/chart_c.csv') # sp_500 = GSPC.csv, # airplaine = AirPassengers.csv\r\n",
    "fig,ax = plt.subplots(figsize=(15,4))\r\n",
    "df.plot(x='DateTime',y='In-Game',marker='o',ax=ax,rot=30)\r\n",
    "plt.tight_layout()\r\n",
    "display(df.info())\r\n",
    "display(df)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d6c12de326941f09cadcfb85900f31c"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2016 entries, 0 to 2015\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   DateTime     2016 non-null   object \n",
      " 1   Users        2016 non-null   int64  \n",
      " 2   Users Trend  2016 non-null   float64\n",
      " 3   In-Game      2016 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 63.1+ KB\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Users</th>\n",
       "      <th>Users Trend</th>\n",
       "      <th>In-Game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-03 08:50:00</td>\n",
       "      <td>16995985</td>\n",
       "      <td>1.948013e+07</td>\n",
       "      <td>3664115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-03 09:00:00</td>\n",
       "      <td>17066265</td>\n",
       "      <td>1.949637e+07</td>\n",
       "      <td>3667309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-03 09:10:00</td>\n",
       "      <td>17136411</td>\n",
       "      <td>1.951287e+07</td>\n",
       "      <td>3684229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-03 09:20:00</td>\n",
       "      <td>17241081</td>\n",
       "      <td>1.952978e+07</td>\n",
       "      <td>3707665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-03 09:30:00</td>\n",
       "      <td>17327721</td>\n",
       "      <td>1.954682e+07</td>\n",
       "      <td>3719017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2021-09-17 08:00:00</td>\n",
       "      <td>16465737</td>\n",
       "      <td>1.828497e+07</td>\n",
       "      <td>3578403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2021-09-17 08:10:00</td>\n",
       "      <td>16563757</td>\n",
       "      <td>1.829027e+07</td>\n",
       "      <td>3619142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2021-09-17 08:20:00</td>\n",
       "      <td>16669358</td>\n",
       "      <td>1.829550e+07</td>\n",
       "      <td>3660871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2021-09-17 08:30:00</td>\n",
       "      <td>16761577</td>\n",
       "      <td>1.830059e+07</td>\n",
       "      <td>3693956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2021-09-17 08:40:00</td>\n",
       "      <td>16850643</td>\n",
       "      <td>1.830553e+07</td>\n",
       "      <td>3722116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DateTime     Users   Users Trend  In-Game\n",
       "0     2021-09-03 08:50:00  16995985  1.948013e+07  3664115\n",
       "1     2021-09-03 09:00:00  17066265  1.949637e+07  3667309\n",
       "2     2021-09-03 09:10:00  17136411  1.951287e+07  3684229\n",
       "3     2021-09-03 09:20:00  17241081  1.952978e+07  3707665\n",
       "4     2021-09-03 09:30:00  17327721  1.954682e+07  3719017\n",
       "...                   ...       ...           ...      ...\n",
       "2011  2021-09-17 08:00:00  16465737  1.828497e+07  3578403\n",
       "2012  2021-09-17 08:10:00  16563757  1.829027e+07  3619142\n",
       "2013  2021-09-17 08:20:00  16669358  1.829550e+07  3660871\n",
       "2014  2021-09-17 08:30:00  16761577  1.830059e+07  3693956\n",
       "2015  2021-09-17 08:40:00  16850643  1.830553e+07  3722116\n",
       "\n",
       "[2016 rows x 4 columns]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.0 Forecast Deep Rock Galagtic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# import some data\r\n",
    "df = pd.read_csv('./test_data/chart_c.csv') # sp_500 = GSPC.csv, # airplaine = AirPassengers.csv\r\n",
    "df['In-Game'].plot(marker='o')\r\n",
    "display(df)\r\n",
    "\r\n",
    "\r\n",
    "# model and forecast\r\n",
    "\r\n",
    "window_length = 50\r\n",
    "split = 1500 # 1009 \r\n",
    "\r\n",
    "# initialize class object\r\n",
    "normal = time_series_prediction(df['DateTime'],df['In-Game'],window_length,1)#time_series_prediction(sp_500['Date'][-4000:],sp_500['Volume'][-4000:]/1e9,5,1) # pass: ime series dates, univariate time series, lag window length, a number of steps ahead to predict\r\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised ML problem\r\n",
    "normal.train_test_split(split=split) # testing and training dataset split\r\n",
    "normal.test_train_plot()    # visualize training split\r\n",
    "\r\n",
    "# perform some prediction tasks\r\n",
    "normal.linear_regression()\r\n",
    "normal.support_vector_machine(model_tunning=True)\r\n",
    "normal.neural_net_mlp(model_tunning=True)\r\n",
    "normal.naive_model()\r\n",
    "\r\n",
    "# visualize results\r\n",
    "normal.vis_results_time_series(second_plot='error')\r\n",
    "\r\n",
    "# tabulate results\r\n",
    "tabulated_results_0 = normal.results()\r\n",
    "tabulated_results_0.plot()\r\n",
    "display(tabulated_results_0)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Users</th>\n",
       "      <th>Users Trend</th>\n",
       "      <th>In-Game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-03 08:50:00</td>\n",
       "      <td>16995985</td>\n",
       "      <td>1.948013e+07</td>\n",
       "      <td>3664115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-03 09:00:00</td>\n",
       "      <td>17066265</td>\n",
       "      <td>1.949637e+07</td>\n",
       "      <td>3667309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-03 09:10:00</td>\n",
       "      <td>17136411</td>\n",
       "      <td>1.951287e+07</td>\n",
       "      <td>3684229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-03 09:20:00</td>\n",
       "      <td>17241081</td>\n",
       "      <td>1.952978e+07</td>\n",
       "      <td>3707665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-03 09:30:00</td>\n",
       "      <td>17327721</td>\n",
       "      <td>1.954682e+07</td>\n",
       "      <td>3719017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2021-09-17 08:00:00</td>\n",
       "      <td>16465737</td>\n",
       "      <td>1.828497e+07</td>\n",
       "      <td>3578403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2021-09-17 08:10:00</td>\n",
       "      <td>16563757</td>\n",
       "      <td>1.829027e+07</td>\n",
       "      <td>3619142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2021-09-17 08:20:00</td>\n",
       "      <td>16669358</td>\n",
       "      <td>1.829550e+07</td>\n",
       "      <td>3660871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2021-09-17 08:30:00</td>\n",
       "      <td>16761577</td>\n",
       "      <td>1.830059e+07</td>\n",
       "      <td>3693956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2021-09-17 08:40:00</td>\n",
       "      <td>16850643</td>\n",
       "      <td>1.830553e+07</td>\n",
       "      <td>3722116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DateTime     Users   Users Trend  In-Game\n",
       "0     2021-09-03 08:50:00  16995985  1.948013e+07  3664115\n",
       "1     2021-09-03 09:00:00  17066265  1.949637e+07  3667309\n",
       "2     2021-09-03 09:10:00  17136411  1.951287e+07  3684229\n",
       "3     2021-09-03 09:20:00  17241081  1.952978e+07  3707665\n",
       "4     2021-09-03 09:30:00  17327721  1.954682e+07  3719017\n",
       "...                   ...       ...           ...      ...\n",
       "2011  2021-09-17 08:00:00  16465737  1.828497e+07  3578403\n",
       "2012  2021-09-17 08:10:00  16563757  1.829027e+07  3619142\n",
       "2013  2021-09-17 08:20:00  16669358  1.829550e+07  3660871\n",
       "2014  2021-09-17 08:30:00  16761577  1.830059e+07  3693956\n",
       "2015  2021-09-17 08:40:00  16850643  1.830553e+07  3722116\n",
       "\n",
       "[2016 rows x 4 columns]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "862def9cc93d474794dfd8d4817d1c59"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a9ea5723ce24f44a4901e3e76eefd54"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [-0.02461895 -0.02871182  0.03805866  0.0400108   0.01204393 -0.00538615\n",
      " -0.01999516 -0.00099367  0.02547329  0.00344169 -0.01760034 -0.01930462\n",
      " -0.04470614  0.00749487  0.02195196  0.0159408   0.00259444 -0.01542534\n",
      " -0.03085981 -0.00316399  0.03653354  0.02570755  0.00418293 -0.01760425\n",
      " -0.04773033 -0.01361073  0.04805584  0.01262257  0.00915815 -0.0063921\n",
      " -0.03878257 -0.02337616  0.04057288  0.03695393  0.02976078  0.01726553\n",
      " -0.02480973 -0.01988098  0.01181689  0.03020805  0.00451084 -0.02998083\n",
      " -0.07148716 -0.10342332 -0.08230761 -0.07665278 -0.03495644  0.06106776\n",
      "  0.33747384  0.92110328]\n",
      "RMSE:  92987.40041939735\n",
      "MAE:  27275.154252512606\n",
      "\n",
      "Training support vector machine:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.0 Import some test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# import some data\r\n",
    "df = pd.read_csv('./test_data/AirPassengers.csv') # sp_500 = GSPC.csv, # airplaine = AirPassengers.csv\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>#Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1960-08</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1960-09</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1960-10</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1960-11</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1960-12</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  #Passengers\n",
       "0    1949-01          112\n",
       "1    1949-02          118\n",
       "2    1949-03          132\n",
       "3    1949-04          129\n",
       "4    1949-05          121\n",
       "..       ...          ...\n",
       "139  1960-08          606\n",
       "140  1960-09          508\n",
       "141  1960-10          461\n",
       "142  1960-11          390\n",
       "143  1960-12          432\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# add some noise\r\n",
    "df['noisy'] = df['#Passengers'].apply(lambda x: x + random.gauss(0,50))\r\n",
    "df.plot()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b98a71a85532457780e45f215e94e9ca"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# set global forecasting variables:\r\n",
    "ma_window = 5\r\n",
    "window_length = 15\r\n",
    "split = 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.0 Example of using class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# initialize class object\r\n",
    "normal = time_series_prediction(df['Month'],df['#Passengers'],window_length,1)#time_series_prediction(sp_500['Date'][-4000:],sp_500['Volume'][-4000:]/1e9,5,1) # pass: ime series dates, univariate time series, lag window length, a number of steps ahead to predict\r\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised ML problem\r\n",
    "normal.train_test_split(split=split) # testing and training dataset split\r\n",
    "normal.test_train_plot()    # visualize training split\r\n",
    "\r\n",
    "# perform some prediction tasks\r\n",
    "normal.linear_regression()\r\n",
    "normal.support_vector_machine(model_tunning=True)\r\n",
    "normal.neural_net_mlp(model_tunning=True)\r\n",
    "normal.naive_model()\r\n",
    "\r\n",
    "# visualize results\r\n",
    "normal.vis_results_time_series(second_plot='error')\r\n",
    "\r\n",
    "# tabulate results\r\n",
    "tabulated_results_0 = normal.results()\r\n",
    "tabulated_results_0.plot()\r\n",
    "display(tabulated_results_0)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37a1b8e15d5741a4a09da9c84d894c76"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fe152228e83469b8912050babc8af14"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [ 0.17068564 -0.43619066 -0.52110009  0.85529166  0.21998151 -0.16326028\n",
      "  0.15272419 -0.13551272  0.0870167  -0.15020303  0.17336489 -0.15420544\n",
      " -0.00593946  0.20685781  0.70047134]\n",
      "RMSE:  16.37160479513395\n",
      "MAE:  12.641974322064023\n",
      "\n",
      "Training support vector machine:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  76 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-3)]: Done 240 out of 240 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_score:  -223.00536321094188\n",
      "best_model:  SVR(C=1, kernel='linear')\n",
      "best_params:  {'C': 1, 'epsilon': 0.1, 'kernel': 'linear'}\n",
      "RMSE:  17.889176273260063\n",
      "MAE:  13.473920953157533\n",
      "\n",
      "Training neural network: \n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done 140 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-3)]: Done 405 out of 405 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_score:  -159.50359473463922\n",
      "best_model:  MLPRegressor(hidden_layer_sizes=(1000,), learning_rate_init=0.01, max_iter=1000,\n",
      "             shuffle=False)\n",
      "best_params:  {'activation': 'relu', 'hidden_layer_sizes': (1000,), 'learning_rate': 'constant', 'learning_rate_init': 0.01}\n",
      "RMSE:  24.158490983134183\n",
      "MAE:  20.13025044010877\n",
      "\n",
      "Naive model results:\n",
      "RMSE:  52.4913786024544\n",
      "MAE:  44.724137931034484\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1430b91fa52b46038b0516bc6f6832b6"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a06dd23394d4ae789e238a5b49b3173"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Value</th>\n",
       "      <th>Linear</th>\n",
       "      <th>SVM</th>\n",
       "      <th>NN</th>\n",
       "      <th>Naive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1960-08</td>\n",
       "      <td>606</td>\n",
       "      <td>621.999</td>\n",
       "      <td>615.884</td>\n",
       "      <td>587.504</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1960-09</td>\n",
       "      <td>508</td>\n",
       "      <td>515.385</td>\n",
       "      <td>509.973</td>\n",
       "      <td>523.398</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1960-10</td>\n",
       "      <td>461</td>\n",
       "      <td>429.972</td>\n",
       "      <td>428.478</td>\n",
       "      <td>444.769</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1960-11</td>\n",
       "      <td>390</td>\n",
       "      <td>410.561</td>\n",
       "      <td>415.206</td>\n",
       "      <td>414.671</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1960-12</td>\n",
       "      <td>432</td>\n",
       "      <td>434.469</td>\n",
       "      <td>429.675</td>\n",
       "      <td>421.458</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Value   Linear      SVM       NN Naive\n",
       "0    1949-01    112     None     None     None  None\n",
       "1    1949-02    118     None     None     None  None\n",
       "2    1949-03    132     None     None     None  None\n",
       "3    1949-04    129     None     None     None  None\n",
       "4    1949-05    121     None     None     None  None\n",
       "..       ...    ...      ...      ...      ...   ...\n",
       "139  1960-08    606  621.999  615.884  587.504   622\n",
       "140  1960-09    508  515.385  509.973  523.398   606\n",
       "141  1960-10    461  429.972  428.478  444.769   508\n",
       "142  1960-11    390  410.561  415.206  414.671   461\n",
       "143  1960-12    432  434.469  429.675  421.458   390\n",
       "\n",
       "[144 rows x 6 columns]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# what is the accuracy of price movements for these predictions\r\n",
    "\r\n",
    "# data to feed to hit_rate function:\r\n",
    "dates = tabulated_results_0['date'].iloc[split+window_length:]\r\n",
    "original_values = tabulated_results_0['Value'].iloc[split+window_length:]\r\n",
    "lin_predictions = tabulated_results_0['Linear'].iloc[split+window_length:]\r\n",
    "svm_predictions = tabulated_results_0['SVM'].iloc[split+window_length:]\r\n",
    "nn_predictions =  tabulated_results_0['NN'].iloc[split+window_length:]\r\n",
    "naive_predictions =  tabulated_results_0['Naive'].iloc[split+window_length:]\r\n",
    "\r\n",
    "# hit rate calculations\r\n",
    "print('Linear Regression:')\r\n",
    "df_lin = hit_rate(dates,original_values,lin_predictions)\r\n",
    "\r\n",
    "print('SVM:')\r\n",
    "df_svm = hit_rate(dates,original_values,svm_predictions)\r\n",
    "\r\n",
    "print('NN:')\r\n",
    "df_nn = hit_rate(dates,original_values,nn_predictions)\r\n",
    "\r\n",
    "print('Naive:')\r\n",
    "df_naive = hit_rate(dates,original_values,naive_predictions)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear Regression:\n",
      "Movement prediction accuracy: 93.1 %\n",
      "Confusion matrix:\n",
      "[[13  1]\n",
      " [ 1 14]]\n",
      "SVM:\n",
      "Movement prediction accuracy: 96.55 %\n",
      "Confusion matrix:\n",
      "[[14  0]\n",
      " [ 1 14]]\n",
      "NN:\n",
      "Movement prediction accuracy: 89.66 %\n",
      "Confusion matrix:\n",
      "[[11  3]\n",
      " [ 0 15]]\n",
      "Naive:\n",
      "Movement prediction accuracy: 58.62 %\n",
      "Confusion matrix:\n",
      "[[8 6]\n",
      " [6 9]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- even with the volume data which seems more stationary than open price data, the forecasts are still dominated by t-1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# plot predicted vs real value scatter plots\r\n",
    "normal.vis_results_scatter()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88b5af29c7f440aa8d60c8e236294c79"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.0 Play around with standardization and prediction returns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# some misc data\r\n",
    "x = df['#Passengers']#[-2000:]\r\n",
    "dates = df['Month']#[-2000:]\r\n",
    "# percentage returns\r\n",
    "x_pct = x.pct_change().fillna(0)\r\n",
    "x_pct\r\n",
    "\r\n",
    "# create new df hold both\r\n",
    "df = pd.DataFrame(columns=['Month','#Passengers','pct_change','pct_change_cumprod'])#pd.DataFrame(columns=['Dates','Open','pct_change','pct_change_cumprod']) # ,'log_transform'\r\n",
    "df['Month'] = dates\r\n",
    "df['#Passengers'] =  x\r\n",
    "df['pct_change'] = x_pct\r\n",
    "df['pct_change_cumprod'] = (x_pct + 1).cumprod()\r\n",
    "# df['log_transform'] = np.log(df['Open'] )\r\n",
    "\r\n",
    "df.reset_index(inplace=True,drop=True)\r\n",
    "\r\n",
    "# plot\r\n",
    "df.plot(subplots=True,sharex=True,figsize=(7,7))\r\n",
    "plt.tight_layout()\r\n",
    "\r\n",
    "# view data\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8cda7ef242140bea0adf4040e037eca"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>#Passengers</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>pct_change_cumprod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949-01</td>\n",
       "      <td>112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949-02</td>\n",
       "      <td>118</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>1.053571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1949-03</td>\n",
       "      <td>132</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>1.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1949-04</td>\n",
       "      <td>129</td>\n",
       "      <td>-0.022727</td>\n",
       "      <td>1.151786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1949-05</td>\n",
       "      <td>121</td>\n",
       "      <td>-0.062016</td>\n",
       "      <td>1.080357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1960-08</td>\n",
       "      <td>606</td>\n",
       "      <td>-0.025723</td>\n",
       "      <td>5.410714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1960-09</td>\n",
       "      <td>508</td>\n",
       "      <td>-0.161716</td>\n",
       "      <td>4.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1960-10</td>\n",
       "      <td>461</td>\n",
       "      <td>-0.092520</td>\n",
       "      <td>4.116071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1960-11</td>\n",
       "      <td>390</td>\n",
       "      <td>-0.154013</td>\n",
       "      <td>3.482143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1960-12</td>\n",
       "      <td>432</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month  #Passengers  pct_change  pct_change_cumprod\n",
       "0    1949-01          112    0.000000            1.000000\n",
       "1    1949-02          118    0.053571            1.053571\n",
       "2    1949-03          132    0.118644            1.178571\n",
       "3    1949-04          129   -0.022727            1.151786\n",
       "4    1949-05          121   -0.062016            1.080357\n",
       "..       ...          ...         ...                 ...\n",
       "139  1960-08          606   -0.025723            5.410714\n",
       "140  1960-09          508   -0.161716            4.535714\n",
       "141  1960-10          461   -0.092520            4.116071\n",
       "142  1960-11          390   -0.154013            3.482143\n",
       "143  1960-12          432    0.107692            3.857143\n",
       "\n",
       "[144 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- unsure what the log transform is required for"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 predicting using returns data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "scaler = MinMaxScaler()\r\n",
    "df['pct_change_normalised'] = df['pct_change'].to_numpy().reshape(-1, 1)\r\n",
    "\r\n",
    "normal = time_series_prediction(df['Month'],df['pct_change_normalised'],15,1) # pass time series, lag window length, a number of steps ahead to predict\r\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised learning ML problem\r\n",
    "normal.train_test_split(split=120) # testing and training dataset split\r\n",
    "normal.test_train_plot() "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6eb32697ed2345459eaa6bd074c3821f"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d55bc56a4024964b8d945977a55dc6a"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# perform some prediction tasks\r\n",
    "normal.linear_regression()\r\n",
    "normal.support_vector_machine(model_tunning=True)\r\n",
    "normal.neural_net_mlp(model_tunning=True)\r\n",
    "normal.naive_model()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [-0.00159895 -0.35412292  0.00448339 -0.21164916  0.1285251 ]\n",
      "RMSE:  0.22897053338920142\n",
      "MAE:  0.19776139115216448\n",
      "\n",
      "Training support vector machine:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "best_score:  -0.021892121675885994\n",
      "best_model:  SVR(C=1)\n",
      "best_params:  {'C': 1, 'epsilon': 0.1, 'kernel': 'rbf'}\n",
      "RMSE:  0.16080037907558992\n",
      "MAE:  0.11233707036293106\n",
      "\n",
      "Training neural network: \n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done 140 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-3)]: Done 240 out of 240 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done 140 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-3)]: Done 405 out of 405 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_score:  -0.03465973423531474\n",
      "best_model:  MLPRegressor(hidden_layer_sizes=(1000,), learning_rate='adaptive',\n",
      "             max_iter=1000, shuffle=False)\n",
      "best_params:  {'activation': 'relu', 'hidden_layer_sizes': (1000,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.001}\n",
      "RMSE:  0.1696706875583989\n",
      "MAE:  0.13302081520156087\n",
      "\n",
      "Naive model results:\n",
      "RMSE:  0.2802672842896312\n",
      "MAE:  0.23383246334482782\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "normal.vis_results_time_series(second_plot='error')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a265beec9eb345598e7f400707ae2f78"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "some remarks on predictions using returns of open price:\n",
    "- prediction accuracy of models look terrible. Is it even worth comparing feature engineering approaches if predictions are this bad?\n",
    "- evaluating models using cummulative gains seems reasonable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.0 Denosing using fourier transform "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# import scipy fft functions\r\n",
    "from scipy.fft import fft, ifft, fftfreq"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# apply discrete fourier transform\r\n",
    "df = pd.read_csv('./test_data/GSPC.csv')\r\n",
    "signal = np.array(df['Open'][-2000:]) # data\r\n",
    "fft_coefficients = fft(signal) # fourier transform\r\n",
    "fft_coefficients"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 3.66942187e+06     -0.j        ,  3.21287554e+03+487830.95056478j,\n",
       "        1.12223495e+05+238171.48892065j, ...,\n",
       "       -4.56458329e+03-189241.03923405j,  1.12223495e+05-238171.48892065j,\n",
       "        3.21287554e+03-487830.95056478j])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# plot orignal signal and inverse fourier transform, shows you can transform signal to frequency domain, then back to time domain\r\n",
    "inverse_fft = ifft(fft_coefficients)\r\n",
    "fig,ax = plt.subplots(figsize=(10,4))\r\n",
    "ax.plot(df['Date'][-2000:],inverse_fft,'-',label='Inverse fourier data')\r\n",
    "ax.plot(range(0,len(inverse_fft)),signal,'.',label='Real data')\r\n",
    "ax.set_xlabel('Days')\r\n",
    "ax.set_xticks([df['Date'][-2000:].iloc[x] for x in range(0,len(df['Date'][-2000:]),120)])\r\n",
    "ax.legend()\r\n",
    "ax.tick_params(rotation=30,labelsize=15)\r\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "360ad8dc19934b829c82298983304057"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# plot amplitude vs frequency \r\n",
    "n = len(signal)\r\n",
    "\r\n",
    "# get frequencies and psd\r\n",
    "freqs = fftfreq(signal.shape[0]) # x axis of amplitude vs frequency graphs\r\n",
    "psd = np.abs(fft_coefficients)/n # psd is amplitude/N, psd or power spectrum density is the magnitude of the coefficients resulting from fourier transform\r\n",
    "\r\n",
    "# plot psd\r\n",
    "fig,ax = plt.subplots(figsize=(10,5))\r\n",
    "ax.plot(freqs[1:int(n/2)],psd[1:int(n/2)])\r\n",
    "ax.set_ylabel('Power spectrum',fontsize=15)\r\n",
    "ax.set_xlabel('Frequencies',fontsize=15)\r\n",
    "ax.set_title('FFT')\r\n",
    "ax.tick_params(labelsize=15)\r\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73ca88c401c64ece8b52f5b5850f6c60"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "observations from coefficient magnitude vs frequency graph:\n",
    "- most frequencies have low amplitude\n",
    "- can denoise signal by setting coefficients with low amplitude to zero - ie a thresholding approach. Here the threshold might be something like 0.06\n",
    "- fyi: frequency = 1 / #days therefore "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Threshold coefficients to denoise signal\r\n",
    "psd_indices = psd > 3# 0.06 # mask\r\n",
    "fft_filtered = fft_coefficients*psd_indices\r\n",
    "\r\n",
    "# low pass filtering\r\n",
    "# freq_indices = freqs < 0.003 \r\n",
    "# fft_filtered = fft_coefficients*freq_indices\r\n",
    "\r\n",
    "# inverse transform filter coefficients\r\n",
    "inverse_transform_filtered = ifft(fft_filtered)\r\n",
    "\r\n",
    "# plot this\r\n",
    "fig,ax = plt.subplots(figsize=(10,5))\r\n",
    "ax.plot(df['Date'][-2000:],signal,'-',label='Real data')\r\n",
    "ax.plot(df['Date'][-2000:],inverse_transform_filtered,'-',label='Inverse fourier filtered')\r\n",
    "ax.legend()\r\n",
    "ax.set_title('Threshold = 0.06')\r\n",
    "ax.set_xlabel('Days',fontsize=15)\r\n",
    "ax.set_xticks([df['Date'][-2000:].iloc[x] for x in range(0,len(df['Date'][-2000:]),120)])\r\n",
    "ax.tick_params(rotation=30,labelsize=15)\r\n",
    "\r\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-26-671f65149377>:13: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig,ax = plt.subplots(figsize=(10,5))\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07c2bdcb53274b65840ea8c9901337e1"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# put together artifical data, here the training set is denoised and the testing set is left unchanged\r\n",
    "df_data = pd.DataFrame(columns=['Dates','artificial_data'])\r\n",
    "df_data['Dates'] = df['Date'][-2000:]\r\n",
    "df_data['artificial_data'] = np.concatenate((np.real(inverse_transform_filtered)[-2000:-500],df['Open'][-500:].to_numpy()),axis=None)\r\n",
    "\r\n",
    "# plot this\r\n",
    "fig,ax = plt.subplots(figsize=(10,5))\r\n",
    "ax.plot(df['Date'][-2000:],df['Open'][-2000:],'-',label='Real data')\r\n",
    "ax.plot(df_data['Dates'],df_data['artificial_data'],'-',label='Artificial testing and training data')\r\n",
    "ax.legend()\r\n",
    "ax.set_title('Threshold = 0.06')\r\n",
    "ax.set_xlabel('Days',fontsize=15)\r\n",
    "ax.set_xticks([df['Date'][-2000:].iloc[x] for x in range(0,len(df['Date'][-2000:]),120)])\r\n",
    "ax.tick_params(rotation=30,labelsize=15)\r\n",
    "\r\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68f8baeed078491eb7c862d96a83b37e"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1 now run predictions by training on filtered data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# initializing predicition class object for denoise\r\n",
    "fft_denoised = time_series_prediction(df['Date'][-2000:],df_data['artificial_data'],5,1) # pass time series, lag window length, a number of steps ahead to predict\r\n",
    "fft_denoised.sliding_window_1(verbose=0) # time series to supervised learning ML problem\r\n",
    "fft_denoised.train_test_split(split=1500) # testing and training dataset split\r\n",
    "fft_denoised.test_train_plot() "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb181e8f67e749d98222c04bbb03bf6e"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25e6920354994ca2b977273eb51f63cc"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# perform some prediction tasks\r\n",
    "fft_denoised.linear_regression()\r\n",
    "fft_denoised.support_vector_machine(model_tunning=True,C= 100, epsilon= 0.1, kernel= 'linear') # these values come from first training model on normal data\r\n",
    "fft_denoised.neural_net_mlp(model_tunning=True,activation= 'tanh', hidden_layer_sizes= (1000,), learning_rate= 'constant', learning_rate_init= 0.001) # these values come from first training model on normal data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [-1.03457371  3.60524758 -3.86652966  0.10714721  2.18860435]\n",
      "RMSE:  62.968505530904785\n",
      "MAE:  38.441808870062054\n",
      "\n",
      "Training support vector machine:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  79 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-3)]: Done 213 out of 240 | elapsed:    9.6s remaining:    1.1s\n",
      "[Parallel(n_jobs=-3)]: Done 240 out of 240 | elapsed:   35.1s finished\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_score:  -1.7461269326506816\n",
      "best_model:  SVR(C=0.1, kernel='linear')\n",
      "best_params:  {'C': 0.1, 'epsilon': 0.1, 'kernel': 'linear'}\n",
      "RMSE:  46.55096053951141\n",
      "MAE:  28.156603107903628\n",
      "\n",
      "Training neural network: \n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done 104 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-3)]: Done 232 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-3)]: Done 405 out of 405 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_score:  -81.70563319845397\n",
      "best_model:  MLPRegressor(hidden_layer_sizes=(1000,), max_iter=1000, shuffle=False)\n",
      "best_params:  {'activation': 'relu', 'hidden_layer_sizes': (1000,), 'learning_rate': 'constant', 'learning_rate_init': 0.001}\n",
      "RMSE:  18.602506675966758\n",
      "MAE:  11.907933230115955\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "fft_denoised.vis_results_time_series(second_plot='error')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51f19d93352f41d6bfaf11f987e5fd23"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2 Compare denoised results to normal "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "source": [
    "# run predictions on volume data without denoising\r\n",
    "\r\n",
    "# initializing predicition class object for denoise\r\n",
    "normal = time_series_prediction(sp_500['Date'][-2000:],sp_500['Volume'][-2000:]/1e9,5,1) # pass time series, lag window length, a number of steps ahead to predict\r\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised learning ML problem\r\n",
    "normal.train_test_split(split=1500) # testing and training dataset split\r\n",
    "normal.test_train_plot() \r\n",
    "\r\n",
    "# perform some prediction tasks\r\n",
    "normal.linear_regression()\r\n",
    "normal.support_vector_machine(model_tunning=False,C= 100, epsilon= 0.1, kernel= 'linear')\r\n",
    "normal.neural_net_mlp(model_tunning=False,activation= 'relu', hidden_layer_sizes= (100,), learning_rate= 'adaptive', learning_rate_init= 0.01)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0f6b03f0a424852a06f2b83475ecc73"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dccf23f0f576415ebb9abe6eb677d305"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [0.09282714 0.02080688 0.04822414 0.15111368 0.44476971]\n",
      "RMSE:  0.5274919871056635\n",
      "MAE:  0.3471744942971835\n",
      "\n",
      "Training support vector machine:\n",
      "Model params:  {'C': 100, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': 1000, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "RMSE:  0.6609905743797734\n",
      "MAE:  0.44956223654614363\n",
      "\n",
      "Training neural network: \n",
      "Model params: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': False, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "RMSE:  0.5354893830493296\n",
      "MAE:  0.34509062992508055\n",
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "source": [
    "# compare results for denoised and normal data: pulling data from predicito objects\r\n",
    "fig,ax = plt.subplots(figsize=(10,5))\r\n",
    "\r\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.y_test,'-',label='real vals')\r\n",
    "ax.plot(fft_denoised.time_series_dates[fft_denoised.training_split+fft_denoised.lag_window_length:],fft_denoised.linear_reg_predictions,'-',label='linear reg - denoised')\r\n",
    "ax.plot(fft_denoised.time_series_dates[fft_denoised.training_split+fft_denoised.lag_window_length:],fft_denoised.svm_predictions,'-',label='svm - denoised')\r\n",
    "ax.plot(fft_denoised.time_series_dates[fft_denoised.training_split+fft_denoised.lag_window_length:],fft_denoised.neural_net_predictions,'-',label='nn - denoised')\r\n",
    "\r\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.linear_reg_predictions,'--',label='linear reg ')\r\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.svm_predictions,'--',label='svm ')\r\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.neural_net_predictions,'--',label='nn ')\r\n",
    "\r\n",
    "ax.set_xticks([normal.time_series_dates[x] for x in range(normal.training_split,len(normal.time_series_dates),28)])\r\n",
    "ax.tick_params(rotation=30)\r\n",
    "ax.legend()\r\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fbf6abce5ce4c6291018896f7218031"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How to compare results before and after denoising?\n",
    "- rmse for predictions of denoised data cant be compared to remse of predictions using normal data because you are comparing against two different signals, one noisy and one denoised."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6.0 Wavelet denoising"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drawbacks of fourier transform / denoising:\n",
    "- requires stationary data\n",
    "- no localization of when different frequencies occured\n",
    "- thresholding fourier trasnform coefficients requires setting a hyperparameter - the threshold \n",
    "\n",
    "Benefits of wavelets transform:\n",
    "- data does not need to be stationary\n",
    "- localization of when frequencies occur\n",
    "\n",
    "Drawbacks of wavelets for denoising:\n",
    "- more hyperparameters, threshold value as well as selecting wavelet type"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.1 Wavelet transform / decomposition of time series signal"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wavelet denoisng method:\n",
    "- First perform a wavelet transform of the open data, denoise by thresholding coefficients, then computes returns of denoised signal. Compute returns and perform forecasting. Transform predictions to value and compare. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import pywt\r\n",
    "import sys\r\n",
    "\r\n",
    "# Data format:\r\n",
    "# Raw data should be in a .txt file with two columns, separated by tabs:\r\n",
    "#  - The first column should be a time-series index\r\n",
    "#  - The second column should contain the data to be filtered\r\n",
    "\r\n",
    "# Time series / data:\r\n",
    "sp_500 = pd.read_csv('./test_data/GSPC.csv')\r\n",
    "data = sp_500['Open'][-5000:] \r\n",
    "\r\n",
    "index = sp_500['Open'][-5000:].index\r\n",
    "\r\n",
    "# Create wavelet object and define parameters\r\n",
    "w = pywt.Wavelet('sym8') # sym family look good too sym8, this is where you should change the wavelet type, haar wavelet is simply 'haar'\r\n",
    "maxlev = pywt.dwt_max_level(len(data), w.dec_len)\r\n",
    "print(\"maximum level is \" + str(maxlev))\r\n",
    "threshold = 0.8 # Threshold for filtering coefficients as part of denoising, the higher this value the more coefficients you set to zero, ie more of the original signal you truncate away / denoise\r\n",
    "\r\n",
    "# Decompose into wavelet components, to the level selected:\r\n",
    "coeffs = pywt.wavedec(data, w, level=4)\r\n",
    "\r\n",
    "# Threshold the wavelet coefficients, thereby removing noise\r\n",
    "\r\n",
    "# plt.figure(figsize=(8,15))\r\n",
    "for i in range(1, len(coeffs)):\r\n",
    "    # plt.subplot(maxlev, 1, i)\r\n",
    "    # plt.plot(coeffs[i],label='Original coefficients')\r\n",
    "    coeffs[i] = pywt.threshold(coeffs[i], threshold*max(coeffs[i]),mode='hard')\r\n",
    "    # plt.plot(coeffs[i],label='Thresholded coefficients')\r\n",
    "    # plt.ylabel('Scale: '+str(maxlev-i+1))\r\n",
    "    # plt.legend()\r\n",
    "    plt.tight_layout()\r\n",
    "\r\n",
    "# inverse transform coefficient to reconstruct time series signal, minus noise\r\n",
    "datarec = pywt.waverec(coeffs, w)\r\n",
    "\r\n",
    "plt.figure(figsize=(15,5))\r\n",
    "plt.plot(index, data,label='Raw signal')\r\n",
    "plt.plot(index, datarec,label=\"De-noised signal using wavelet techniques\")\r\n",
    "plt.legend()\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "# Distance measures between true signal and denoised\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "maximum level is 8\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f575ee4dba044605933c7929eb4cfc8f"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "coeffs = pywt.wavedec(data, w, level=maxlev)\r\n",
    "coeffs_array = np.array(coeffs)\r\n",
    "for i in range(len(coeffs)):\r\n",
    "    print(i,' : ',len(coeffs[i]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0  :  34\n",
      "1  :  34\n",
      "2  :  53\n",
      "3  :  92\n",
      "4  :  170\n",
      "5  :  326\n",
      "6  :  638\n",
      "7  :  1261\n",
      "8  :  2507\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-32-b8260bc4145e>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  coeffs_array = np.array(coeffs)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.2 Predictions: normal data vs wavelet denoised"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "predict sp500 open price one day ahead, using precentage returns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# some data processing: \r\n",
    "\r\n",
    "# create new df for normal data\r\n",
    "df_normal = pd.DataFrame(columns=['Dates','Open','pct_change','pct_change_cumprod'])\r\n",
    "df_normal['Dates'] = sp_500['Date'][-5000:]\r\n",
    "df_normal['Open'] =   sp_500['Open'][-5000:]\r\n",
    "df_normal['pct_change'] = df_normal['Open'].pct_change().fillna(0)\r\n",
    "df_normal['pct_change_cumprod'] = (df_normal['pct_change']  + 1).cumprod()\r\n",
    "\r\n",
    "df_normal.reset_index(inplace=True,drop=True)\r\n",
    "\r\n",
    "# create new df for wavelet denoised data\r\n",
    "df_denoised= pd.DataFrame(columns=['Dates','Open','pct_change','pct_change_cumprod'])\r\n",
    "df_denoised['Dates'] = sp_500['Date'][-5000:]\r\n",
    "df_denoised['Open'] =   datarec\r\n",
    "df_denoised['pct_change'] = df_denoised['Open'].pct_change().fillna(0)\r\n",
    "df_denoised['pct_change_cumprod'] = (df_denoised['pct_change']  + 1).cumprod()\r\n",
    "\r\n",
    "df_denoised.reset_index(inplace=True,drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "fig,ax = plt.subplots(figsize=(10,7))\r\n",
    "df_normal.plot(subplots=True,ax=ax)\r\n",
    "fig,ax = plt.subplots(figsize=(10,7))\r\n",
    "df_denoised.plot(subplots=True,ax=ax)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d36dae0da8194b66ac1ddcf3467ca07d"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py:61: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared\n",
      "  plot_obj.generate()\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d77bd20ba0c84186aeded593069efc8d"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tristan\\anaconda3\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\__init__.py:61: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared\n",
      "  plot_obj.generate()\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([<AxesSubplot:>, <AxesSubplot:>, <AxesSubplot:>], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.2 Perform prediction on data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "########################################################################\r\n",
    "# forecasting on normal data\r\n",
    "########################################################################\r\n",
    "\r\n",
    "normal = time_series_prediction(df_denoised['Dates'],df_denoised['Open'],10,1) # pass time series, lag window length, a number of steps ahead to predict\r\n",
    "normal.sliding_window_1(verbose=0) # time series to supervised learning ML problem\r\n",
    "normal.train_test_split(split=4500) # testing and training dataset split\r\n",
    "normal.test_train_plot()    # visualize training split\r\n",
    "\r\n",
    "# perform some prediction tasks\r\n",
    "normal.linear_regression()\r\n",
    "normal.support_vector_machine(model_tunning=True)\r\n",
    "normal.neural_net_mlp(model_tunning=True)\r\n",
    "\r\n",
    "#visualize results\r\n",
    "normal.vis_results_time_series(second_plot='error')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1caa2d19a759465c9e50ca72d9419540"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a80b26d79124dc4b695c8ad1ac736a7"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [ -0.37118873   1.60148038  -3.80273113   6.66461263  -9.43264085\n",
      "  11.17871293 -11.26030921   9.50516526  -6.54416521   3.46098803]\n",
      "RMSE:  51.06229108825765\n",
      "MAE:  7.8499745596661095\n",
      "\n",
      "Training support vector machine:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  70 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-3)]: Done 193 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-3)]: Done 240 out of 240 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_score:  -32.04620785441023\n",
      "best_model:  SVR(C=1, epsilon=10, kernel='linear')\n",
      "best_params:  {'C': 1, 'epsilon': 10, 'kernel': 'linear'}\n",
      "RMSE:  28.757202725278542\n",
      "MAE:  14.367173632655456\n",
      "\n",
      "Training neural network: \n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  98 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-3)]: Done 221 tasks      | elapsed:  2.1min\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_score:  -157.12155671576073\n",
      "best_model:  MLPRegressor(hidden_layer_sizes=(10,), learning_rate='adaptive',\n",
      "             learning_rate_init=0.01, max_iter=1000, shuffle=False)\n",
      "best_params:  {'activation': 'relu', 'hidden_layer_sizes': (10,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01}\n",
      "RMSE:  37.696568049785725\n",
      "MAE:  31.29134187499981\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-3)]: Done 405 out of 405 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2cee48813f4f472eaec8d2dade1dbd01"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "x, y, and format string must not be None",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-71a881ea3baa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#visualize results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mnormal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvis_results_time_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_plot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\tristan\\Documents\\MEng Data Science\\code_repo\\one_dimensional_time_series_forecasting.py\u001b[0m in \u001b[0;36mvis_results_time_series\u001b[1;34m(self, second_plot)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;31m# predicted y values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_series_dates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_split\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlag_window_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_reg_predictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'o-'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear regression prediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmarkersize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_series_dates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_split\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlag_window_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_predictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.--'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'naive prediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmarkersize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_series_dates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_split\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlag_window_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm_predictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.--'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svm prediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmarkersize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_series_dates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_split\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlag_window_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_net_predictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.--'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nn prediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmarkersize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;31m# element array of None which causes problems downstream.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x, y, and format string must not be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x, y, and format string must not be None"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "########################################################################\r\n",
    "# forecasting on denoised data\r\n",
    "########################################################################\r\n",
    "\r\n",
    "denoised = time_series_prediction(df_denoised['Dates'],df_denoised['pct_change'],10,1) # pass time series, lag window length, a number of steps ahead to predict\r\n",
    "denoised.sliding_window_1(verbose=0) # time series to supervised learning ML problem\r\n",
    "denoised.train_test_split(split=4500) # testing and training dataset split\r\n",
    "denoised.test_train_plot() \r\n",
    "\r\n",
    "# perform some prediction tasks\r\n",
    "denoised.linear_regression()\r\n",
    "denoised.support_vector_machine(model_tunning=True,C= 0.1, epsilon= 10, kernel= 'linear')\r\n",
    "denoised.neural_net_mlp(model_tunning=True,activation= 'relu', hidden_layer_sizes= (100,), learning_rate= 'adaptive', learning_rate_init= 0.001)\r\n",
    "\r\n",
    "#visualize results\r\n",
    "denoised.vis_results_time_series(second_plot='cumprod')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "429af1d638ef43d7bdc31669f5814374"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1278805bcb0f4990a081061f1a8fcbd0"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training multivariate linear regression:\n",
      "\n",
      "Linear regression coefficients: \n",
      " [ 0.0237145  -0.02246668  0.04740009  0.00701641  0.03584964 -0.03737366\n",
      " -0.03726144  0.05776496  0.03446961  0.17203609]\n",
      "RMSE:  0.004456301705215824\n",
      "MAE:  0.0016611758073728459\n",
      "\n",
      "Training support vector machine:\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  70 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-3)]: Done 240 out of 240 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 14 concurrent workers.\n",
      "best_score:  -0.00023433945042440927\n",
      "best_model:  SVR(C=0.1, epsilon=10, kernel='linear')\n",
      "best_params:  {'C': 0.1, 'epsilon': 10, 'kernel': 'linear'}\n",
      "RMSE:  0.015381430721325244\n",
      "MAE:  0.014829075969529875\n",
      "\n",
      "Training neural network: \n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[Parallel(n_jobs=-3)]: Done 140 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-3)]: Done 329 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-3)]: Done 378 out of 405 | elapsed:  1.2min remaining:    5.1s\n",
      "best_score:  -3.784801693916872e-05\n",
      "best_model:  MLPRegressor(activation='logistic', hidden_layer_sizes=(10,),\n",
      "             learning_rate='invscaling', learning_rate_init=0.01, max_iter=1000,\n",
      "             shuffle=False)\n",
      "best_params:  {'activation': 'logistic', 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'learning_rate_init': 0.01}\n",
      "RMSE:  0.0044628414884044796\n",
      "MAE:  0.0017067176124213601\n",
      "[Parallel(n_jobs=-3)]: Done 405 out of 405 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d5c199b9c124efd828cabb1fba45f18"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.3 Compare results for normal vs denoised"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "# compare results for denoised and normal data\r\n",
    "fig,ax = plt.subplots(figsize=(10,5))\r\n",
    "\r\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.real_vals_cumprod,'-',label='real vals cumprod',linewidth=3)\r\n",
    "ax.plot(denoised.time_series_dates[denoised.training_split+denoised.lag_window_length:],denoised.linear_reg_predictions_cumprod,'-',label='linear reg cumprod - denoised')\r\n",
    "# ax.plot(denoised.time_series_dates[denoised.training_split+denoised.lag_window_length:],denoised.svm_predictions_cumprod,'-',label='svm cumprod - denoised')\r\n",
    "ax.plot(denoised.time_series_dates[denoised.training_split+denoised.lag_window_length:],denoised.neural_net_predictions_cumprod,'-',label='nn cumprod - denoised')\r\n",
    "\r\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.linear_reg_predictions_cumprod,'--',label='linear reg cumprod')\r\n",
    "# ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.svm_predictions_cumprod,'--',label='svm cumprod')\r\n",
    "ax.plot(normal.time_series_dates[normal.training_split+normal.lag_window_length:],normal.neural_net_predictions_cumprod,'--',label='nn cumprod')\r\n",
    "\r\n",
    "ax.set_xticks([normal.time_series_dates[x] for x in range(normal.training_split,len(normal.time_series_dates),28)])\r\n",
    "ax.tick_params(rotation=30)\r\n",
    "ax.legend()\r\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cfc121117ce4d74b2ee60f7e465639f"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.4 transform return predictions back to price data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "When testing denoising methods, we need to compare against predictions without denoising. But once you denoise the original signal, you cant compare the RMSE metric of the denoised results to that of the normal (without denoising) prediction method because these metrics are computed against different based y_true values. So: \n",
    "\n",
    "\n",
    "- 1) transform price to returns\n",
    "- 2) predict returns with and without denoising\n",
    "- 3) convert returns to price and compute rmse, with and without denosing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "# define some new dataframes to hold all data\r\n",
    "df_normal_results = df_normal.iloc[4521:,:]\r\n",
    "df_denoised_results = df_denoised.iloc[4521:,:]\r\n",
    "\r\n",
    "# no denoising\r\n",
    "df_normal_results['linear_reg_prices'] = df_normal['Open'][4521] * normal.linear_reg_predictions_cumprod\r\n",
    "df_normal_results['svm_reg_prices'] = df_normal['Open'][4521] * normal.svm_predictions_cumprod\r\n",
    "df_normal_results['nn_reg_prices'] = df_normal['Open'][4521] * normal.neural_net_predictions_cumprod\r\n",
    "\r\n",
    "# with denoising\r\n",
    "df_denoised_results['linear_reg_prices'] = df_denoised['Open'][4521] * denoised.linear_reg_predictions_cumprod\r\n",
    "df_denoised_results['svm_reg_prices'] = df_denoised['Open'][4521] * denoised.svm_predictions_cumprod\r\n",
    "df_denoised_results['nn_reg_prices'] = df_denoised['Open'][4521] * denoised.neural_net_predictions_cumprod\r\n",
    "\r\n",
    "# plot results\r\n",
    "plt.figure(figsize=(10,4))\r\n",
    "plt.plot(df_normal_results['Dates'],df_normal_results['Open'],label='Real open data')\r\n",
    "\r\n",
    "plt.plot(df_normal_results['Dates'],df_normal_results['linear_reg_prices'],label='linear normal')\r\n",
    "# plt.plot(df_normal_results['Dates'],df_normal_results['svm_reg_prices'],label='svm normal')\r\n",
    "plt.plot(df_normal_results['Dates'],df_normal_results['nn_reg_prices'],label='nn normal')\r\n",
    "\r\n",
    "plt.plot(df_normal_results['Dates'],df_denoised_results['linear_reg_prices'],'--',label='linear denoised')\r\n",
    "# plt.plot(df_normal_results['Dates'],df_denoised_results['svm_reg_prices'],label='svm denoised')\r\n",
    "plt.plot(df_normal_results['Dates'],df_denoised_results['nn_reg_prices'],'--',label='nn denoised')\r\n",
    "\r\n",
    "\r\n",
    "plt.xticks([df_normal_results['Dates'].iloc[x] for x in range(0,len(df_normal_results['Dates'][:]),28)])\r\n",
    "plt.tick_params(rotation=30)\r\n",
    "plt.legend()\r\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-115-c730201f51f1>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_normal_results['linear_reg_prices'] = df_normal['Open'][4521] * normal.linear_reg_predictions_cumprod\n",
      "<ipython-input-115-c730201f51f1>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_normal_results['svm_reg_prices'] = df_normal['Open'][4521] * normal.svm_predictions_cumprod\n",
      "<ipython-input-115-c730201f51f1>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_normal_results['nn_reg_prices'] = df_normal['Open'][4521] * normal.neural_net_predictions_cumprod\n",
      "<ipython-input-115-c730201f51f1>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_denoised_results['linear_reg_prices'] = df_denoised['Open'][4521] * denoised.linear_reg_predictions_cumprod\n",
      "<ipython-input-115-c730201f51f1>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_denoised_results['svm_reg_prices'] = df_denoised['Open'][4521] * denoised.svm_predictions_cumprod\n",
      "<ipython-input-115-c730201f51f1>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_denoised_results['nn_reg_prices'] = df_denoised['Open'][4521] * denoised.neural_net_predictions_cumprod\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "516da746127744cfa661cad887876b16"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "# compute evaluation metrics: look at RMSE between cummulative gains of real data vs predictions with and without denoising\r\n",
    "\r\n",
    "# data\r\n",
    "y_true = df_normal_results['Open']\r\n",
    "\r\n",
    "# no denoising\r\n",
    "y_pred_1 = df_normal_results['linear_reg_prices']\r\n",
    "y_pred_2 = df_normal_results['svm_reg_prices']\r\n",
    "y_pred_3 = df_normal_results['nn_reg_prices']\r\n",
    "\r\n",
    "# with denoising\r\n",
    "y_pred_4 = df_denoised_results['linear_reg_prices']\r\n",
    "y_pred_5 = df_denoised_results['svm_reg_prices']\r\n",
    "y_pred_6 = df_denoised_results['nn_reg_prices']\r\n",
    "\r\n",
    "# metrics\r\n",
    "\r\n",
    "rmse_linear_normal = mean_squared_error(y_true,y_pred_1)\r\n",
    "rmse_svm_normal = mean_squared_error(y_true,y_pred_2)\r\n",
    "rmse_ann_normal = mean_squared_error(y_true,y_pred_3)\r\n",
    "\r\n",
    "rmse_linear_denoised = mean_squared_error(y_true,y_pred_4)\r\n",
    "rmse_svn_denoised = mean_squared_error(y_true,y_pred_5)\r\n",
    "rmse_ann_denoised = mean_squared_error(y_true,y_pred_6)\r\n",
    "\r\n",
    "# print metrics\r\n",
    "print('Linear normal - RMSE cumulatic gains:\\t',rmse_linear_normal**0.5)\r\n",
    "print('SVM normal - RMSE cumulatic gains:\\t',rmse_svm_normal**0.5)\r\n",
    "print('ANN normal - RMSE cumulatic gains:\\t',rmse_ann_normal**0.5)\r\n",
    "\r\n",
    "print('Linear denoised - RMSE cumulatic gains:\\t',rmse_linear_denoised**0.5)\r\n",
    "print('SVM denoised - RMSE cumulatic gains:\\t',rmse_svn_denoised**0.5)\r\n",
    "print('ANN denoised - RMSE cumulatic gains:\\t',rmse_ann_denoised**0.5)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear normal - RMSE cumulatic gains:\t 273.7957156081383\n",
      "SVM normal - RMSE cumulatic gains:\t 73853.8022660274\n",
      "ANN normal - RMSE cumulatic gains:\t 166.67343763907598\n",
      "Linear denoised - RMSE cumulatic gains:\t 178.58542289582076\n",
      "SVM denoised - RMSE cumulatic gains:\t 809173.9539076653\n",
      "ANN denoised - RMSE cumulatic gains:\t 306.7646744121744\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear normal - RMSE cumulatic gains:\t 103.78796952459727\n",
    "SVM normal - RMSE cumulatic gains:\t 2119.0777666368795\n",
    "ANN normal - RMSE cumulatic gains:\t 229.97477972358672\n",
    "Linear denoised - RMSE cumulatic gains:\t 49.60068080046763\n",
    "SVM denoised - RMSE cumulatic gains:\t 14452.351946378596\n",
    "ANN denoised - RMSE cumulatic gains:\t 115.447881267899"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Summary of takeaways from denoising using signal processing techniques:\n",
    "- Question, should you denoise before are after computing returns? \n",
    "    - Fourier transform needs to be computed on stationary signal(the sinusoids continue through infinity ie stationary), therefore you must do returns first?\n",
    "    - Wavelet transform can be computed for non-stationary signals - see nice denosing of s&p 500 open prices\n",
    "\n",
    "- How do we compare forecasting results for different denosing results?\n",
    "    - RMSE or MAE against the denoised signals means we are comparing the forecasting results of fourier and wavelet denoised against different signals?\n",
    "    - If we look at cumulative returns over testing dataset, then do we compare against the original cummulative returns?\n",
    "\n",
    "- Some hyperparameters for wavelet transform:\n",
    "    - type of wavelet, should be chosen based on data, all papers I've read have used the haar wavelet. Sym look better in my results.\n",
    "    - Once the dwt transform is applied then a thresholding approach can be applied to set low coefficients to zero. Then iDWT taken to retrieve denoised signal. This threshold value and type of thresholding are another hyperparameter. \n",
    "    - The level of decomposition is also a hyperparameter. \n",
    "\n",
    "- Some hyperparameters for fourier transform:\n",
    "    - thresholding value of different frequencies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# some random extras"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "import pywt\r\n",
    "\r\n",
    "# single level wavelet denoising\r\n",
    "data = sp_500['Volume'][-2000:]/1e9\r\n",
    "plt.figure(figsize=(15,5))\r\n",
    "data.plot()\r\n",
    "\r\n",
    "x = np.array(data)                \r\n",
    "(ca, cd) = pywt.dwt(x, \"sym20\")                \r\n",
    "cat = pywt.threshold(ca, 0.5, mode=\"hard\")                \r\n",
    "cdt = pywt.threshold(cd, 0.5, mode=\"soft\")                \r\n",
    "tx = pywt.idwt(cat, cdt, \"sym20\")\r\n",
    "\r\n",
    "plt.plot(sp_500['Volume'][-2000:].index,tx,'-.')\r\n",
    "plt.tight_layout()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "401b5912bb684288aab8a1991e0e2e3e"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "pywt.wavelist(kind='discrete')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['bior1.1',\n",
       " 'bior1.3',\n",
       " 'bior1.5',\n",
       " 'bior2.2',\n",
       " 'bior2.4',\n",
       " 'bior2.6',\n",
       " 'bior2.8',\n",
       " 'bior3.1',\n",
       " 'bior3.3',\n",
       " 'bior3.5',\n",
       " 'bior3.7',\n",
       " 'bior3.9',\n",
       " 'bior4.4',\n",
       " 'bior5.5',\n",
       " 'bior6.8',\n",
       " 'coif1',\n",
       " 'coif2',\n",
       " 'coif3',\n",
       " 'coif4',\n",
       " 'coif5',\n",
       " 'coif6',\n",
       " 'coif7',\n",
       " 'coif8',\n",
       " 'coif9',\n",
       " 'coif10',\n",
       " 'coif11',\n",
       " 'coif12',\n",
       " 'coif13',\n",
       " 'coif14',\n",
       " 'coif15',\n",
       " 'coif16',\n",
       " 'coif17',\n",
       " 'db1',\n",
       " 'db2',\n",
       " 'db3',\n",
       " 'db4',\n",
       " 'db5',\n",
       " 'db6',\n",
       " 'db7',\n",
       " 'db8',\n",
       " 'db9',\n",
       " 'db10',\n",
       " 'db11',\n",
       " 'db12',\n",
       " 'db13',\n",
       " 'db14',\n",
       " 'db15',\n",
       " 'db16',\n",
       " 'db17',\n",
       " 'db18',\n",
       " 'db19',\n",
       " 'db20',\n",
       " 'db21',\n",
       " 'db22',\n",
       " 'db23',\n",
       " 'db24',\n",
       " 'db25',\n",
       " 'db26',\n",
       " 'db27',\n",
       " 'db28',\n",
       " 'db29',\n",
       " 'db30',\n",
       " 'db31',\n",
       " 'db32',\n",
       " 'db33',\n",
       " 'db34',\n",
       " 'db35',\n",
       " 'db36',\n",
       " 'db37',\n",
       " 'db38',\n",
       " 'dmey',\n",
       " 'haar',\n",
       " 'rbio1.1',\n",
       " 'rbio1.3',\n",
       " 'rbio1.5',\n",
       " 'rbio2.2',\n",
       " 'rbio2.4',\n",
       " 'rbio2.6',\n",
       " 'rbio2.8',\n",
       " 'rbio3.1',\n",
       " 'rbio3.3',\n",
       " 'rbio3.5',\n",
       " 'rbio3.7',\n",
       " 'rbio3.9',\n",
       " 'rbio4.4',\n",
       " 'rbio5.5',\n",
       " 'rbio6.8',\n",
       " 'sym2',\n",
       " 'sym3',\n",
       " 'sym4',\n",
       " 'sym5',\n",
       " 'sym6',\n",
       " 'sym7',\n",
       " 'sym8',\n",
       " 'sym9',\n",
       " 'sym10',\n",
       " 'sym11',\n",
       " 'sym12',\n",
       " 'sym13',\n",
       " 'sym14',\n",
       " 'sym15',\n",
       " 'sym16',\n",
       " 'sym17',\n",
       " 'sym18',\n",
       " 'sym19',\n",
       " 'sym20']"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  }
 ]
}