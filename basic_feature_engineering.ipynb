{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate results, basic feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook the following approaches are implemented:\n",
    "- no feature engineering\n",
    "- minmax scaling\n",
    "- differenecing\n",
    "- differencing + log transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 12:18:07.755630: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-25 12:18:07.755649: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# import bespoke modules\n",
    "from one_dimensional_time_series_forecasting import time_series_prediction, hit_rate, invert_first_difference,invert_first_difference_2,invert_scaling, invert_first_difference_with_log_2, invert_scaling,inverted_conclusion\n",
    "from walkforward_validation import walk_forward_val, series_to_supervised\n",
    "\n",
    "# model evalution metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error\n",
    "\n",
    "# data preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# interactive figures\n",
    "%matplotlib widget \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Baseline: no feature engineering / minmax only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to test this cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_assets = ['CrudeOil','S&P500','Apple','EurUsd'] # AirPassengers',\n",
    "feat_engineering = 'minmax'\n",
    "column_to_predict = 'Close' #'#Passengers' \n",
    "\n",
    "for financial_asset in financial_assets:\n",
    "    ###################################################################################################\n",
    "    # import some data\n",
    "    ###################################################################################################\n",
    "\n",
    "    df = pd.read_csv(f'./test_data/{financial_asset}_yfinance.csv') # sp_500 = GSPC.csv, # airplaine = AirPassengers.csv\n",
    "    df = df.iloc[-2000:,:].reset_index(drop=True) # only look at last 2000 days\n",
    "    # df['Date'] = df['Month']\n",
    "    df.plot(x='Date',y=f'{column_to_predict}',figsize=(10,5),legend=True,xlabel='Month',subplots=True)\n",
    "    plt.tight_layout()\n",
    "    display(df)\n",
    "\n",
    "\n",
    "    ###################################################################################################\n",
    "    # single out of sample validation results\n",
    "    ###################################################################################################\n",
    "\n",
    "    # some forecasting parameters\n",
    "    window_length = 10\n",
    "    split = 500 # 44 for AirPlane\n",
    "\n",
    "    # input data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_training_data = scaler.fit_transform(df[f'{column_to_predict}'][0:-split].to_numpy().reshape(-1,1)).flatten()\n",
    "    scaled_test_data = scaler.transform(df[f'{column_to_predict}'][-split:].to_numpy().reshape(-1,1)).flatten()\n",
    "    scaled_input_data = np.append(scaled_training_data,scaled_test_data)\n",
    "\n",
    "    # initialize class object\n",
    "    blah = time_series_prediction(financial_asset,feat_engineering,df['Date'],scaled_input_data,window_length,1)#time_series_prediction(sp_500['Date'][-4000:],sp_500['Volume'][-4000:]/1e9,5,1) # pass: ime series dates, univariate time series, lag window length, a number of steps ahead to predict\n",
    "    blah.sliding_window_1(verbose=0) # time series to supervised ML problem\n",
    "    blah.train_test_split(split=split) # testing and training dataset split\n",
    "    blah.test_train_plot(ylabel='Close price')    # visualize training split\n",
    "\n",
    "    # perform some prediction tasks\n",
    "    blah.linear_regression()\n",
    "    blah.support_vector_machine(model_tunning=False,C= 0.1, kernel= 'linear',epsilon=0.1)\n",
    "    blah.neural_net_mlp(model_tunning=False,\n",
    "                        activation= 'relu', \n",
    "                        hidden_layer_sizes= (100, 100, 100), \n",
    "                        learning_rate= 'invscaling', \n",
    "                        learning_rate_init= 0.001,\n",
    "                        solver='adam')\n",
    "    blah.lstm(model_tunning=False,n_batch=64)\n",
    "    blah.naive_model()\n",
    "\n",
    "    # tabulate results nicely\n",
    "    blah.collect_results()\n",
    "\n",
    "    # visualize results\n",
    "    blah.vis_results_time_series(ylabel='Close price',second_plot='error')\n",
    "\n",
    "    # view final results\n",
    "    blah.conclusion()\n",
    "\n",
    "    ###################################################################################################\n",
    "    # invert feature engineering (if possible)\n",
    "    ###################################################################################################\n",
    "\n",
    "    # invert scaling\n",
    "    inverted_predictions_linear, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.linear_reg_predictions)\n",
    "    inverted_predictions_svm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.svm_predictions)\n",
    "    inverted_predictions_nn, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.neural_net_predictions)\n",
    "    inverted_predictions_lstm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.lstm_predictions)\n",
    "\n",
    "    # collect inverted results\n",
    "\n",
    "    df_inverted_results = pd.DataFrame(columns=['Date','Value','Linear','SVM','NN','LSTM'])\n",
    "    df_inverted_results['Date'] = df['Date']\n",
    "    df_inverted_results['Value'] = df[f'{column_to_predict}']\n",
    "    df_inverted_results['Linear'].iloc[-split:] = inverted_predictions_linear.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['SVM'].iloc[-split:] = inverted_predictions_svm.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['NN'].iloc[-split:] =  inverted_predictions_nn.flatten()#['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['LSTM'].iloc[-split:] = inverted_predictions_lstm.flatten()#['invert_pred_value'].astype(float)\n",
    "\n",
    "    # plot invert results\n",
    "    ax = df_inverted_results.plot(figsize=(10,4), x='Date', fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(rotation=30, labelsize=12)    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_inverted.png')\n",
    "\n",
    "    # store results\n",
    "    inverted_conclusion(dates=df['Date'].iloc[-split:],\n",
    "                        original_values=df[f'{column_to_predict}'].iloc[-split:], \n",
    "                        linear_preds=inverted_predictions_linear, \n",
    "                        svm_pred=inverted_predictions_svm, \n",
    "                        nn_preds=inverted_predictions_nn, \n",
    "                        lstm_preds=inverted_predictions_lstm,\n",
    "                        financial_asset=financial_asset,\n",
    "                        feat_engineer=feat_engineering)\n",
    "\n",
    "\n",
    "    ###################################################################################################\n",
    "    # walk forward validation results\n",
    "    ###################################################################################################\n",
    "    mapping = {'LinearReg':blah.linear_regression_model,\n",
    "                'svr':blah.svr_model,\n",
    "                'MLP':blah.mlp_model,\n",
    "                'LSTM':blah.lstm_model\n",
    "                }\n",
    "\n",
    "    # store evaulation results for different models\n",
    "    model_results = []\n",
    "    inverted_results = []\n",
    "    model_pred_results = {'Original Values':None,\n",
    "                'LinearReg':None,\n",
    "                'svr':None,\n",
    "                'MLP':None,\n",
    "                'LSTM':None,\n",
    "                }\n",
    "    # unfeature engineered data for walkforward\n",
    "    walk_forward_input = scaler.transform(df[f'{column_to_predict}'][-2000:].to_numpy().reshape(-1,1)).flatten()\n",
    "\n",
    "    # apply walkforward for all models\n",
    "    for model_name in mapping.keys():\n",
    "\n",
    "        # retrieve model\n",
    "        model = mapping[model_name]\n",
    "\n",
    "        # apply walk forward and save results\n",
    "        train_len = 225 # 48 for Airplane\n",
    "        test_len = 25   # 12 for Airplane\n",
    "        df_walk_forward, df_hit_rate, mse,mae,mape,accuracy = walk_forward_val(model_name,model,\n",
    "                                                                                    original_series = scaled_input_data,\n",
    "                                                                                    time_series_dates=df['Date'].iloc[-2000:],\n",
    "                                                                                    lag_window_length=window_length,\n",
    "                                                                                    train_len=train_len,\n",
    "                                                                                    test_len=test_len,\n",
    "                                                                                    train_frequency=10\n",
    "                                                                                    )\n",
    "\n",
    "        # wrangle results\n",
    "\n",
    "        # tables \n",
    "        model_results.append({'model':model_name,'mse':mse,'mae':mae,'mape':mape,'accuracy':accuracy})\n",
    "\n",
    "        # invert results for different models\n",
    "\n",
    "        # invert scaling\n",
    "        inverted_predictions, inverted_testing_data = invert_scaling(scaler,scaled_input_data[train_len:],df_walk_forward['prediction'].to_numpy())\n",
    "\n",
    "        invert_mse = np.sqrt(mean_squared_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions))\n",
    "        invert_mae = mean_absolute_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions)\n",
    "        invert_mape = mean_absolute_percentage_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_predictions)\n",
    "        df_hit_rate, invert_accuracy = hit_rate(dates=df['Date'].iloc[train_len:],\n",
    "                                        original_values=df[f'{column_to_predict}'].iloc[train_len:],\n",
    "                                        predictions=inverted_predictions)\n",
    "\n",
    "        inverted_results.append({'model':model_name,'mse':invert_mse,'mae':invert_mae,'mape':invert_mape,'accuracy':invert_accuracy})\n",
    "\n",
    "\n",
    "        # save prediction so we can view inverted walk forward results too\n",
    "        model_pred_results['Original Values'] = df[f'{column_to_predict}'].iloc[train_len:]\n",
    "        model_pred_results[model_name] = inverted_predictions.flatten()\n",
    "\n",
    "        # plots\n",
    "        df_walk_forward['error'] = abs((df_walk_forward['real_value'] - df_walk_forward['prediction']) / df_walk_forward['real_value'])\n",
    "        \n",
    "        fig, ax = plt.subplots(2,1, figsize=(10,8),sharex=True)\n",
    "        ax[0].plot(df['Date'].iloc[train_len:],df[f'{column_to_predict}'].iloc[train_len:])\n",
    "        ax[0].set_ylabel('Close')\n",
    "\n",
    "        ax[1].plot(df['Date'].iloc[train_len:],df_walk_forward['error'],color='tab:orange')\n",
    "        ax[1].set_title('Walk forward error through time')\n",
    "        ax[1].set_xlabel('Dates')\n",
    "        ax[1].legend()\n",
    "        ax[1].set_ylim([0,1])\n",
    "\n",
    "        max = df_walk_forward.shape[0]\n",
    "        ax[1].set_xticks([df_walk_forward['date'].iloc[x] for x in range(0,max,150)])\n",
    "        ax[1].tick_params(rotation=30)\n",
    "        ax[1].set_ylabel('Error')\n",
    "        ax[1].set_xlabel('Date')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_{model_name}_wf.png',facecolor='w')\n",
    "        plt.close()\n",
    "        \n",
    "    # place wf results into df, save to csv and latex table\n",
    "    df_conclusion_wf = pd.DataFrame.from_records(model_results)\n",
    "    df_conclusion_wf.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_wf.csv')\n",
    "    \n",
    "    df_conclusion_wf_inverted = pd.DataFrame.from_records(inverted_results)\n",
    "    df_conclusion_wf_inverted.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_inverted_wf.csv')\n",
    "    \n",
    "    \n",
    "    latex_table = tabulate(df_conclusion_wf, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    latex_table = tabulate(df_conclusion_wf_inverted, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_inverted_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    # plot wf prediction results through time\n",
    "    for model in model_pred_results.keys():\n",
    "        model_pred_results[model] = model_pred_results[model].astype(float)\n",
    "\n",
    "    model_pred_results['Date'] = df['Date'].iloc[train_len:]\n",
    "    df_wf_results = pd.DataFrame.from_dict(model_pred_results)\n",
    "    ax = df_wf_results.plot(figsize=(10,4), x='Date',fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(labelsize=12,rotation=30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_wf_results_inverted.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred_results['LinearReg'].flatten().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_assets = ['S&P500','Apple','EurUsd','CrudeOil'] # AirPassengers',\n",
    "feat_engineering = 'difference'\n",
    "column_to_predict = 'Close' #'#Passengers' \n",
    "\n",
    "for financial_asset in financial_assets:\n",
    "    ###################################################################################################\n",
    "    # import some data\n",
    "    ###################################################################################################\n",
    "\n",
    "    df = pd.read_csv(f'./test_data/{financial_asset}_yfinance.csv') # sp_500 = GSPC.csv, # airplaine = AirPassengers.csv\n",
    "    df = df.iloc[-2000:,:].reset_index(drop=True) # only look at last 2000 days\n",
    "    # df['Date'] = df['Month']\n",
    "    df.plot(x='Date',y=f'{column_to_predict}',figsize=(10,5),legend=True,xlabel='Month',subplots=True)\n",
    "    plt.tight_layout()\n",
    "    display(df)\n",
    "\n",
    "    ###################################################################################################\n",
    "    # feature engineer data\n",
    "    ###################################################################################################\n",
    "\n",
    "    df['diff'] = df[f'{column_to_predict}'].diff(periods=1)\n",
    "    df['diff'].iloc[0] = 0\n",
    "\n",
    "    ###################################################################################################\n",
    "    # single out of sample validation results\n",
    "    ###################################################################################################\n",
    "\n",
    "    # some forecasting parameters\n",
    "    window_length = 10\n",
    "    split = 500 # 44 for AirPlane\n",
    "\n",
    "    # input data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_training_data = scaler.fit_transform(df['diff'][0:-split].to_numpy().reshape(-1,1)).flatten()\n",
    "    scaled_test_data = scaler.transform(df['diff'][-split:].to_numpy().reshape(-1,1)).flatten()\n",
    "    scaled_input_data = np.append(scaled_training_data,scaled_test_data)\n",
    "\n",
    "    # initialize class object\n",
    "    blah = time_series_prediction(financial_asset,feat_engineering,df['Date'],scaled_input_data,window_length,1)#time_series_prediction(sp_500['Date'][-4000:],sp_500['Volume'][-4000:]/1e9,5,1) # pass: ime series dates, univariate time series, lag window length, a number of steps ahead to predict\n",
    "    blah.sliding_window_1(verbose=0) # time series to supervised ML problem\n",
    "    blah.train_test_split(split=split) # testing and training dataset split\n",
    "    blah.test_train_plot(ylabel='Differenced Close price')    # visualize training split\n",
    "\n",
    "    # perform some prediction tasks\n",
    "    blah.linear_regression()\n",
    "    blah.support_vector_machine(model_tunning=False,C= 0.1, kernel= 'linear',epsilon=0.1)\n",
    "    blah.neural_net_mlp(model_tunning=False,\n",
    "                        activation= 'relu', \n",
    "                        hidden_layer_sizes= (100, 100, 100), \n",
    "                        learning_rate= 'invscaling', \n",
    "                        learning_rate_init= 0.001,\n",
    "                        solver='adam')\n",
    "    blah.lstm(model_tunning=True,n_batch=128)\n",
    "    blah.naive_model()\n",
    "\n",
    "    # tabulate results nicely\n",
    "    blah.collect_results()\n",
    "\n",
    "    # visualize results\n",
    "    blah.vis_results_time_series(ylabel='Differenced Close price',second_plot='error')\n",
    "\n",
    "    # view final results\n",
    "    blah.conclusion()\n",
    "\n",
    "    ###################################################################################################\n",
    "    # invert feature engineering (if possible)\n",
    "    ###################################################################################################\n",
    "\n",
    "    # invert scaling\n",
    "    inverted_predictions_linear, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.linear_reg_predictions)\n",
    "    inverted_predictions_svm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.svm_predictions)\n",
    "    inverted_predictions_nn, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.neural_net_predictions)\n",
    "    inverted_predictions_lstm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.lstm_predictions)\n",
    "\n",
    "    # invert differencing for different models\n",
    "    inverted_lin = invert_first_difference_2(df[f'{column_to_predict}'].iloc[-split],inverted_predictions_linear,df[f'{column_to_predict}'].iloc[-split:], df['Date'].iloc[-split:])\n",
    "    inverted_svm = invert_first_difference_2(df[f'{column_to_predict}'].iloc[-split],inverted_predictions_svm,df[f'{column_to_predict}'].iloc[-split:],df['Date'].iloc[-split:])\n",
    "    inverted_nn = invert_first_difference_2(df[f'{column_to_predict}'].iloc[-split],inverted_predictions_nn,df[f'{column_to_predict}'].iloc[-split:],df['Date'].iloc[-split:])\n",
    "    inverted_lstm = invert_first_difference_2(df[f'{column_to_predict}'].iloc[-split],inverted_predictions_lstm,df[f'{column_to_predict}'].iloc[-split:],df['Date'].iloc[-split:])\n",
    "\n",
    "    # collect inverted results\n",
    "\n",
    "    df_inverted_results = pd.DataFrame(columns=['Date','Value','Linear','SVM','NN','LSTM'])\n",
    "    df_inverted_results['Date'] = df['Date']\n",
    "    df_inverted_results['Value'] = df[f'{column_to_predict}']\n",
    "    df_inverted_results['Linear'].iloc[-split:] = inverted_lin['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['SVM'].iloc[-split:] = inverted_svm['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['NN'].iloc[-split:] =  inverted_nn['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['LSTM'].iloc[-split:] = inverted_lstm['invert_pred_value'].astype(float)\n",
    "\n",
    "    # plot invert results\n",
    "    ax = df_inverted_results.plot(figsize=(10,4), x='Date', fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(rotation=30, labelsize=12)    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_inverted.png')\n",
    "\n",
    "    # store results\n",
    "    inverted_conclusion(dates=df['Date'].iloc[-split:],\n",
    "                        original_values=df[f'{column_to_predict}'].iloc[-split:], \n",
    "                        linear_preds=inverted_lin['invert_pred_value'], \n",
    "                        svm_pred=inverted_svm['invert_pred_value'], \n",
    "                        nn_preds=inverted_nn['invert_pred_value'], \n",
    "                        lstm_preds=inverted_lstm['invert_pred_value'],\n",
    "                        financial_asset=financial_asset,\n",
    "                        feat_engineer=feat_engineering)\n",
    "\n",
    "\n",
    "    ###################################################################################################\n",
    "    # walk forward validation results\n",
    "    ###################################################################################################\n",
    "    mapping = {'LinearReg':blah.linear_regression_model,\n",
    "                'svr':blah.svr_model,\n",
    "                'MLP':blah.mlp_model,\n",
    "                'LSTM':blah.lstm_model}\n",
    "\n",
    "    # store evaulation results for different models\n",
    "    model_results = []\n",
    "    inverted_results = []\n",
    "    model_pred_results = {'Original Values':None,\n",
    "                'LinearReg':None,\n",
    "                'svr':None,\n",
    "                'MLP':None,\n",
    "                'LSTM':None,\n",
    "                }\n",
    "\n",
    "    # apply walkforward for all models\n",
    "    for model_name in mapping.keys():\n",
    "\n",
    "        # retrieve model\n",
    "        model = mapping[model_name]\n",
    "\n",
    "        # apply walk forward and save results\n",
    "        train_len = 225 # 48 for Airplane\n",
    "        test_len = 25   # 12 for Airplane\n",
    "        df_walk_forward, df_hit_rate, mse,mae,mape,accuracy = walk_forward_val(model_name,model,\n",
    "                                                                                    original_series = scaled_input_data,\n",
    "                                                                                    time_series_dates=df['Date'].iloc[-2000:],\n",
    "                                                                                    lag_window_length=window_length,\n",
    "                                                                                    train_len=train_len,\n",
    "                                                                                    test_len=test_len,\n",
    "                                                                                    train_frequency=10\n",
    "                                                                                    )\n",
    "        # wrangle results\n",
    "        \n",
    "        # plots\n",
    "        df_walk_forward['error'] = abs((df_walk_forward['real_value'] - df_walk_forward['prediction']))# / df_walk_forward['real_value'])\n",
    "        \n",
    "        fig, ax = plt.subplots(2,1, figsize=(10,8),sharex=True)\n",
    "        ax[0].plot(df_walk_forward['date'],df_walk_forward['real_value'])\n",
    "        ax[0].set_ylabel('Close')\n",
    "\n",
    "        ax[1].plot(df_walk_forward['date'],df_walk_forward['error'],color='tab:orange')\n",
    "        ax[1].set_title('Walk forward error through time')\n",
    "        ax[1].set_xlabel('Dates')\n",
    "        ax[1].legend()\n",
    "\n",
    "        max = df_walk_forward.shape[0]\n",
    "        ax[1].set_xticks([df_walk_forward['date'].iloc[x] for x in range(0,max,150)])\n",
    "        ax[1].tick_params(rotation=30)\n",
    "        ax[1].set_ylabel('Error')\n",
    "        ax[1].set_xlabel('Date')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_{model_name}_wf.png',facecolor='w')\n",
    "        plt.close()\n",
    "\n",
    "        # tables \n",
    "        model_results.append({'model':model_name,'mse':mse,'mae':mae,'mape':mape,'accuracy':accuracy})\n",
    "\n",
    "        # invert results for different models\n",
    "\n",
    "        # invert scaling\n",
    "        inverted_predictions, inverted_testing_data = invert_scaling(scaler,scaled_input_data[train_len:],df_walk_forward['prediction'].to_numpy())\n",
    "        \n",
    "        # invert differencing for different models\n",
    "        inverted_preds = invert_first_difference_2(\n",
    "                                first_value=df[f'{column_to_predict}'].iloc[train_len],\n",
    "                                predictions=inverted_predictions,\n",
    "                                original=df[f'{column_to_predict}'].iloc[train_len:],\n",
    "                                dates=df['Date'].iloc[train_len:]               \n",
    "                                        )\n",
    "\n",
    "        invert_mse = np.sqrt(mean_squared_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_preds['invert_pred_value']))\n",
    "        invert_mae = mean_absolute_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_preds['invert_pred_value'])\n",
    "        invert_mape = mean_absolute_percentage_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_preds['invert_pred_value'])\n",
    "        df_hit_rate, invert_accuracy = hit_rate(dates=df['Date'].iloc[train_len:],\n",
    "                                        original_values=df[f'{column_to_predict}'].iloc[train_len:],\n",
    "                                        predictions=inverted_preds['invert_pred_value'])\n",
    "\n",
    "        inverted_results.append({'model':model_name,'mse':invert_mse,'mae':invert_mae,'mape':invert_mape,'accuracy':invert_accuracy})\n",
    "\n",
    "\n",
    "        # save prediction so we can view inverted walk forward results too\n",
    "        model_pred_results['Original Values'] = inverted_preds['value'].to_numpy()\n",
    "        model_pred_results[model_name] = inverted_preds['invert_pred_value'].to_numpy()\n",
    "        \n",
    "    # place wf results into df, save to csv and latex table\n",
    "    df_conclusion_wf = pd.DataFrame.from_records(model_results)\n",
    "    df_conclusion_wf.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_wf.csv')\n",
    "    \n",
    "    df_conclusion_wf_inverted = pd.DataFrame.from_records(inverted_results)\n",
    "    df_conclusion_wf_inverted.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_inverted_wf.csv')\n",
    "    \n",
    "    \n",
    "    latex_table = tabulate(df_conclusion_wf, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    latex_table = tabulate(df_conclusion_wf_inverted, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_inverted_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    # plot wf prediction results through time\n",
    "    for model in model_pred_results.keys():\n",
    "        model_pred_results[model] = model_pred_results[model].astype(float)\n",
    "\n",
    "    model_pred_results['Date'] = df['Date'].iloc[train_len:]\n",
    "    df_wf_results = pd.DataFrame.from_dict(model_pred_results)\n",
    "    ax = df_wf_results.plot(figsize=(10,4), x='Date',fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(labelsize=12,rotation=30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_wf_results_inverted.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Differencing and log transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_assets = ['CrudeOil']#['S&P500','Apple','EurUsd']#,'CrudeOil'] # ['AirPassengers']#\n",
    "feat_engineering = 'log_difference'\n",
    "column_to_predict = 'Close' #'#Passengers' \n",
    "\n",
    "for financial_asset in financial_assets:\n",
    "    ###################################################################################################\n",
    "    # import some data\n",
    "    ###################################################################################################\n",
    "    if financial_asset != 'AirPassengers':\n",
    "        df = pd.read_csv(f'./test_data/{financial_asset}_yfinance.csv') # sp_500 = GSPC.csv, # airplaine = AirPassengers.csv\n",
    "        df = df.iloc[-2000:,:].reset_index(drop=True) # only look at last 2000 days\n",
    "    else:\n",
    "        df = pd.read_csv(f'./test_data/{financial_asset}.csv')\n",
    "        df['Date'] = df['Month'] # for the airplane dataset\n",
    "\n",
    "    df.plot(x='Date',y=f'{column_to_predict}',figsize=(10,5),legend=True,xlabel='Month',subplots=True)\n",
    "    plt.tight_layout()\n",
    "    display(df)\n",
    "\n",
    "    ###################################################################################################\n",
    "    # feature engineer data\n",
    "    ###################################################################################################\n",
    "    df['log'] = df[f'{column_to_predict}'].apply(lambda x: np.log(x))\n",
    "    df['log_diff'] = df['log'].diff(periods=1)\n",
    "    df['log_diff'].iloc[0] = 0\n",
    "\n",
    "    ###################################################################################################\n",
    "    # single out of sample validation results\n",
    "    ###################################################################################################\n",
    "\n",
    "    # some forecasting parameters\n",
    "    window_length = 10\n",
    "    split = 500 # 44 for AirPlane\n",
    "\n",
    "    # input data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_training_data = scaler.fit_transform(df['log_diff'][0:-split].to_numpy().reshape(-1,1)).flatten()\n",
    "    scaled_test_data = scaler.transform(df['log_diff'][-split:].to_numpy().reshape(-1,1)).flatten()\n",
    "    scaled_input_data = np.append(scaled_training_data,scaled_test_data)\n",
    "\n",
    "    # initialize class object\n",
    "    blah = time_series_prediction(financial_asset,feat_engineering,df['Date'],scaled_input_data,window_length,1)#time_series_prediction(sp_500['Date'][-4000:],sp_500['Volume'][-4000:]/1e9,5,1) # pass: ime series dates, univariate time series, lag window length, a number of steps ahead to predict\n",
    "    blah.sliding_window_1(verbose=0) # time series to supervised ML problem\n",
    "    blah.train_test_split(split=split) # testing and training dataset split\n",
    "    blah.test_train_plot(ylabel='Differenced Close price')    # visualize training split\n",
    "\n",
    "    # perform some prediction tasks\n",
    "    blah.linear_regression()\n",
    "    blah.support_vector_machine(model_tunning=False,C= 0.1, kernel= 'linear',epsilon=0.1)\n",
    "    blah.neural_net_mlp(model_tunning=False,\n",
    "                        activation= 'relu', \n",
    "                        hidden_layer_sizes= (100, 100, 100), \n",
    "                        learning_rate= 'invscaling', \n",
    "                        learning_rate_init= 0.001,\n",
    "                        solver='adam')\n",
    "    blah.lstm(model_tunning=False,n_batch=12)\n",
    "    blah.naive_model()\n",
    "\n",
    "    # tabulate results nicely\n",
    "    blah.collect_results()\n",
    "\n",
    "    # visualize results\n",
    "    blah.vis_results_time_series(ylabel='Log-Differenced Close price',second_plot='error')\n",
    "\n",
    "    # view final results\n",
    "    blah.conclusion()\n",
    "\n",
    "    ###################################################################################################\n",
    "    # invert feature engineering (if possible)\n",
    "    ###################################################################################################\n",
    "\n",
    "    # invert scaling\n",
    "    inverted_predictions_linear, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.linear_reg_predictions)\n",
    "    inverted_predictions_svm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.svm_predictions)\n",
    "    inverted_predictions_nn, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.neural_net_predictions)\n",
    "    inverted_predictions_lstm, inverted_testing_data = invert_scaling(scaler,scaled_input_data[-split:],blah.lstm_predictions)\n",
    "\n",
    "    # invert differencing for different models\n",
    "    inverted_lin = invert_first_difference_with_log_2(df[f'log'].iloc[-split],inverted_predictions_linear,df[f'{column_to_predict}'].iloc[-split:], df['Date'].iloc[-split:])\n",
    "    inverted_svm = invert_first_difference_with_log_2(df[f'log'].iloc[-split],inverted_predictions_svm,df[f'{column_to_predict}'].iloc[-split:],df['Date'].iloc[-split:])\n",
    "    inverted_nn = invert_first_difference_with_log_2(df[f'log'].iloc[-split],inverted_predictions_nn,df[f'{column_to_predict}'].iloc[-split:],df['Date'].iloc[-split:])\n",
    "    inverted_lstm = invert_first_difference_with_log_2(df[f'log'].iloc[-split],inverted_predictions_lstm,df[f'{column_to_predict}'].iloc[-split:],df['Date'].iloc[-split:])\n",
    "\n",
    "    # collect inverted results\n",
    "\n",
    "    df_inverted_results = pd.DataFrame(columns=['Date','Value','Linear','SVM','NN','LSTM'])\n",
    "    df_inverted_results['Date'] = df['Date']\n",
    "    df_inverted_results['Value'] = df[f'{column_to_predict}']\n",
    "    df_inverted_results['Linear'].iloc[-split:] = inverted_lin['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['SVM'].iloc[-split:] = inverted_svm['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['NN'].iloc[-split:] =  inverted_nn['invert_pred_value'].astype(float)\n",
    "    df_inverted_results['LSTM'].iloc[-split:] = inverted_lstm['invert_pred_value'].astype(float)\n",
    "\n",
    "    # plot invert results\n",
    "    ax = df_inverted_results.plot(figsize=(10,4), x='Date', fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(rotation=30, labelsize=12)    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_inverted.png')\n",
    "\n",
    "    # store results\n",
    "    inverted_conclusion(dates=df['Date'].iloc[-split:],\n",
    "                        original_values=df[f'{column_to_predict}'].iloc[-split:], \n",
    "                        linear_preds=inverted_lin['invert_pred_value'], \n",
    "                        svm_pred=inverted_svm['invert_pred_value'], \n",
    "                        nn_preds=inverted_nn['invert_pred_value'], \n",
    "                        lstm_preds=inverted_lstm['invert_pred_value'],\n",
    "                        financial_asset=financial_asset,\n",
    "                        feat_engineer=feat_engineering)\n",
    "\n",
    "\n",
    "    ###################################################################################################\n",
    "    # walk forward validation results\n",
    "    ###################################################################################################\n",
    "    mapping = {'LinearReg':blah.linear_regression_model,\n",
    "                'svr':blah.svr_model,\n",
    "                'MLP':blah.mlp_model,\n",
    "                'LSTM':blah.lstm_model}\n",
    "\n",
    "    # store evaulation results for different models\n",
    "    model_results = []\n",
    "    inverted_results = []\n",
    "    model_pred_results = {'Original Values':None,\n",
    "                'LinearReg':None,\n",
    "                'svr':None,\n",
    "                'MLP':None,\n",
    "                'LSTM':None,\n",
    "                }\n",
    "\n",
    "    # apply walkforward for all models\n",
    "    for model_name in mapping.keys():\n",
    "\n",
    "        # retrieve model\n",
    "        model = mapping[model_name]\n",
    "\n",
    "        # apply walk forward and save results\n",
    "        train_len = 225 # 48 for Airplane otherwise 225\n",
    "        test_len = 25   # 12 for Airplane otherwise 25\n",
    "        df_walk_forward, df_hit_rate, mse,mae,mape,accuracy = walk_forward_val(model_name,model,\n",
    "                                                                                    original_series = scaled_input_data,\n",
    "                                                                                    time_series_dates=df['Date'].iloc[-2000:],\n",
    "                                                                                    lag_window_length=window_length,\n",
    "                                                                                    train_len=train_len,\n",
    "                                                                                    test_len=test_len,\n",
    "                                                                                    train_frequency=10\n",
    "                                                                                    )\n",
    "        # wrangle results\n",
    "        \n",
    "        # plots\n",
    "        df_walk_forward['error'] = abs((df_walk_forward['real_value'] - df_walk_forward['prediction']))# / df_walk_forward['real_value'])\n",
    "        \n",
    "        fig, ax = plt.subplots(2,1, figsize=(10,8),sharex=True)\n",
    "        ax[0].plot(df_walk_forward['date'],df_walk_forward['real_value'])\n",
    "        ax[0].set_ylabel('Close')\n",
    "\n",
    "        ax[1].plot(df_walk_forward['date'],df_walk_forward['error'],color='tab:orange')\n",
    "        ax[1].set_title('Walk forward error through time')\n",
    "        ax[1].set_xlabel('Dates')\n",
    "        ax[1].legend()\n",
    "\n",
    "        max = df_walk_forward.shape[0]\n",
    "        ax[1].set_xticks([df_walk_forward['date'].iloc[x] for x in range(0,max,150)])\n",
    "        ax[1].tick_params(rotation=30)\n",
    "        ax[1].set_ylabel('Error')\n",
    "        ax[1].set_xlabel('Date')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_{model_name}_wf.png',facecolor='w')\n",
    "        plt.close()\n",
    "\n",
    "        # tables \n",
    "        model_results.append({'model':model_name,'mse':mse,'mae':mae,'mape':mape,'accuracy':accuracy})\n",
    "\n",
    "        # invert results for different models\n",
    "\n",
    "        # invert scaling\n",
    "        inverted_predictions, inverted_testing_data = invert_scaling(scaler,scaled_input_data[train_len:],df_walk_forward['prediction'].to_numpy())\n",
    "        \n",
    "        # invert differencing for different models\n",
    "        inverted_preds = invert_first_difference_with_log_2(\n",
    "                                first_value=df[f'log'].iloc[train_len],\n",
    "                                predictions=inverted_predictions,\n",
    "                                original=df[f'{column_to_predict}'].iloc[train_len:],\n",
    "                                dates=df['Date'].iloc[train_len:]               \n",
    "                                        )\n",
    "\n",
    "        invert_mse = np.sqrt(mean_squared_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_preds['invert_pred_value']))\n",
    "        invert_mae = mean_absolute_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_preds['invert_pred_value'])\n",
    "        invert_mape = mean_absolute_percentage_error(df[f'{column_to_predict}'].iloc[train_len:],inverted_preds['invert_pred_value'])\n",
    "        df_hit_rate, invert_accuracy = hit_rate(dates=df['Date'].iloc[train_len:],\n",
    "                                        original_values=df[f'{column_to_predict}'].iloc[train_len:],\n",
    "                                        predictions=inverted_preds['invert_pred_value'])\n",
    "\n",
    "        inverted_results.append({'model':model_name,'mse':invert_mse,'mae':invert_mae,'mape':invert_mape,'accuracy':invert_accuracy})\n",
    "\n",
    "\n",
    "        # save prediction so we can view inverted walk forward results too\n",
    "        model_pred_results['Original Values'] = inverted_preds['value'].to_numpy()\n",
    "        model_pred_results[model_name] = inverted_preds['invert_pred_value'].to_numpy()\n",
    "        \n",
    "    # place wf results into df, save to csv and latex table\n",
    "    df_conclusion_wf = pd.DataFrame.from_records(model_results)\n",
    "    df_conclusion_wf.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_wf.csv')\n",
    "    \n",
    "    df_conclusion_wf_inverted = pd.DataFrame.from_records(inverted_results)\n",
    "    df_conclusion_wf_inverted.to_csv(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_results_summary_inverted_wf.csv')\n",
    "    \n",
    "    \n",
    "    latex_table = tabulate(df_conclusion_wf, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    latex_table = tabulate(df_conclusion_wf_inverted, headers='keys', tablefmt=\"latex_longtable\")\n",
    "    with open(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_latex_table_inverted_wf.txt',\"w\") as my_latex_table:\n",
    "        my_latex_table.write(latex_table)\n",
    "\n",
    "    # plot wf prediction results through time\n",
    "    for model in model_pred_results.keys():\n",
    "        model_pred_results[model] = model_pred_results[model].astype(float)\n",
    "\n",
    "    model_pred_results['Date'] = df['Date'].iloc[train_len:]\n",
    "    df_wf_results = pd.DataFrame.from_dict(model_pred_results)\n",
    "    ax = df_wf_results.plot(figsize=(10,4), x='Date',fontsize=15)\n",
    "    ax.set_ylabel(ylabel=f'{column_to_predict}',fontsize=15)\n",
    "    ax.set_xlabel(xlabel='Date',fontsize=15)\n",
    "    ax.tick_params(labelsize=12,rotation=30)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./results/univariate_single_step_ahead/{feat_engineering}/{financial_asset}_wf_results_inverted.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['log_diff']].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes:\n",
    "- the models perform horibly on the Crude Oil dataset. Their predictions out of sample are many orders of magnitude off. I belive this is because normalisation is fit to the training data, and then used to transform the testing data. But becauses durring 2020 there were so many anomaly events, ie crude dropped to zero, this value and its log-returns are so out of the scope of the models that their predictions on it are massively wrong. \n",
    "- we cannot predict what it hasnt been seen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08b5fb967e39b85ed312f435313aa6146aa74881f34f4caa25b9abbeb84a46f5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('meng-data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
